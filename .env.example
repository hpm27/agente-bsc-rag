# ==============================================================================
# AGENTE BSC RAG - Configuracao Atualizada (2025)
# ==============================================================================

# ------------------------------------------------------------------------------
# APIs de IA (OBRIGATORIO)
# ------------------------------------------------------------------------------

# OpenAI API Key (OBRIGATORIO - usado para embeddings e pode ser usado para LLM)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Cohere API Key (OBRIGATORIO - usado para re-ranking)
COHERE_API_KEY=your_cohere_api_key_here

# Anthropic API Key (OPCIONAL - necessaria se usar modelos Claude)
# Se usar Claude como LLM principal, esta chave e OBRIGATORIA
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# ------------------------------------------------------------------------------
# Modelo LLM Padrao
# ------------------------------------------------------------------------------
# Pode ser 'gpt-*' (OpenAI) ou 'claude-*' (Anthropic)
# Sistema detecta automaticamente o provider pelo prefixo
DEFAULT_LLM_MODEL=claude-sonnet-4-5-20250929
# Alternativas:
# DEFAULT_LLM_MODEL=gpt-4-turbo-preview
# DEFAULT_LLM_MODEL=gpt-5-2025-08-07

# ------------------------------------------------------------------------------
# Vector Store Configuration
# ------------------------------------------------------------------------------
# Tipo de vector store: 'qdrant', 'weaviate' ou 'redis'
VECTOR_STORE_TYPE=qdrant
VECTOR_STORE_INDEX=bsc_documents

# Qdrant (recomendado para producao)
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Weaviate (alternativa)
WEAVIATE_HOST=localhost
WEAVIATE_PORT=8080

# Redis (mantido para compatibilidade)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_INDEX_NAME=bsc_knowledge

# ------------------------------------------------------------------------------
# RAG Configuration
# ------------------------------------------------------------------------------
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RETRIEVAL=10
TOP_N_RERANK=5
HYBRID_SEARCH_WEIGHT_SEMANTIC=0.7
HYBRID_SEARCH_WEIGHT_BM25=0.3

# ------------------------------------------------------------------------------
# Contextual Retrieval (Anthropic ou OpenAI GPT-5)
# ------------------------------------------------------------------------------
ENABLE_CONTEXTUAL_RETRIEVAL=True
CONTEXTUAL_MODEL=claude-sonnet-4-5-20250929
CONTEXTUAL_CACHE_ENABLED=True
CONTEXTUAL_PROVIDER=openai
# Opcoes: 'openai' ou 'anthropic'

# GPT-5 Configuration (se usar GPT-5 para contextual retrieval)
GPT5_MODEL=gpt-5-2025-08-07
GPT5_MAX_COMPLETION_TOKENS=2048
GPT5_REASONING_EFFORT=minimal
# Opcoes: 'minimal', 'low', 'medium', 'high'

# ------------------------------------------------------------------------------
# Embedding Cache Configuration
# ------------------------------------------------------------------------------
EMBEDDING_CACHE_ENABLED=True
EMBEDDING_CACHE_DIR=.cache/embeddings
EMBEDDING_CACHE_TTL_DAYS=30
EMBEDDING_CACHE_MAX_SIZE_GB=5

# ------------------------------------------------------------------------------
# Agent Configuration
# ------------------------------------------------------------------------------
MAX_ITERATIONS=10
TEMPERATURE=0.0
MAX_TOKENS=2000
AGENT_MAX_WORKERS=4
# Numero de agentes que podem processar em paralelo

# ------------------------------------------------------------------------------
# Embedding Fine-tuning (OPCIONAL)
# ------------------------------------------------------------------------------
USE_FINETUNED_EMBEDDINGS=False
FINETUNED_MODEL_PATH=./models/bsc-embeddings

# ------------------------------------------------------------------------------
# Human-in-the-loop
# ------------------------------------------------------------------------------
REQUIRE_APPROVAL_FOR_CRITICAL=True

# ------------------------------------------------------------------------------
# Monitoring
# ------------------------------------------------------------------------------
ENABLE_METRICS=True
METRICS_PORT=9090

# ------------------------------------------------------------------------------
# Application Configuration
# ------------------------------------------------------------------------------
APP_NAME=Agente BSC
APP_VERSION=1.0.0
DEBUG=False
LOG_LEVEL=INFO

# ------------------------------------------------------------------------------
# Paths
# ------------------------------------------------------------------------------
DATA_DIR=./data
LITERATURE_DIR=./data/bsc_literature
MODELS_DIR=./models
LOGS_DIR=./logs

# ==============================================================================
# INSTRUCOES DE USO
# ==============================================================================
#
# 1. CHAVES OBRIGATORIAS:
#    - OPENAI_API_KEY: Sempre necessaria (embeddings)
#    - COHERE_API_KEY: Sempre necessaria (re-ranking)
#    - ANTHROPIC_API_KEY: Necessaria apenas se DEFAULT_LLM_MODEL for 'claude-*'
#
# 2. ESCOLHA DO MODELO LLM:
#    - Para Claude: DEFAULT_LLM_MODEL=claude-sonnet-4-5-20250929
#      (requer ANTHROPIC_API_KEY)
#    - Para GPT-4: DEFAULT_LLM_MODEL=gpt-4-turbo-preview
#      (requer OPENAI_API_KEY)
#    - Para GPT-5: DEFAULT_LLM_MODEL=gpt-5-2025-08-07
#      (requer OPENAI_API_KEY)
#
# 3. VECTOR STORE:
#    - Qdrant (recomendado): docker-compose up -d
#    - Weaviate (alternativa): ajustar docker-compose.yml
#    - Redis (compatibilidade): usar Redis Stack
#
# 4. CONTEXTUAL RETRIEVAL:
#    - Se CONTEXTUAL_PROVIDER=openai, usar GPT-5
#    - Se CONTEXTUAL_PROVIDER=anthropic, usar Claude
#
# 5. CACHE DE EMBEDDINGS:
#    - Melhora drasticamente performance em queries repetidas
#    - Recomendado manter EMBEDDING_CACHE_ENABLED=True
#
# ==============================================================================
