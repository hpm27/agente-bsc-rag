

# Benchmark Fase 2A - DocumentaÃ§Ã£o Completa

**Objetivo:** Avaliar ROI das tÃ©cnicas RAG avanÃ§adas implementadas na Fase 2A.

---

## ğŸ“‹ Estrutura

```
tests/benchmark_fase2a/
â”œâ”€â”€ run_benchmark.py          # Script principal de execuÃ§Ã£o
â”œâ”€â”€ analyze_results.py        # Script de anÃ¡lise e visualizaÃ§Ã£o
â”œâ”€â”€ results/                   # Resultados gerados
â”‚   â”œâ”€â”€ baseline_results.json
â”‚   â”œâ”€â”€ fase2a_results.json
â”‚   â”œâ”€â”€ baseline_ragas_metrics.json
â”‚   â”œâ”€â”€ fase2a_ragas_metrics.json
â”‚   â”œâ”€â”€ comparative_report.md
â”‚   â”œâ”€â”€ executive_report.md
â”‚   â”œâ”€â”€ latency_boxplot.png
â”‚   â”œâ”€â”€ latency_by_category.png
â”‚   â””â”€â”€ ragas_metrics.png
â””â”€â”€ README.md                  # Este arquivo
```

---

## ğŸš€ Como Executar

### 1. Benchmark Completo (50 queries)

```bash
cd "D:\Users\OneDrive - engelar.eng.br\Documentos\Hugo\ENGELAR\agente-bsc-rag"
.\venv\Scripts\python.exe tests\benchmark_fase2a\run_benchmark.py
```

**Tempo:** ~2.5-3 horas  
**Custo:** ~$1.60 USD

### 2. Teste Piloto (5 queries)

```bash
.\venv\Scripts\python.exe tests\benchmark_fase2a\run_benchmark.py --pilot
```

**Tempo:** ~10-15 minutos  
**Custo:** ~$0.16 USD

### 3. Customizado (N queries)

```bash
.\venv\Scripts\python.exe tests\benchmark_fase2a\run_benchmark.py --limit 20
```

---

## ğŸ“Š AnÃ¡lise de Resultados

ApÃ³s o benchmark terminar:

```bash
.\venv\Scripts\python.exe tests\benchmark_fase2a\analyze_results.py
```

**Gera:**
- `executive_report.md` - RelatÃ³rio executivo
- `latency_boxplot.png` - ComparaÃ§Ã£o de latÃªncias
- `latency_by_category.png` - LatÃªncias por tipo de query
- `ragas_metrics.png` - MÃ©tricas de qualidade RAGAS

---

## ğŸ¯ O Que Ã© Avaliado

### Baseline (Sem OtimizaÃ§Ãµes)
- âŒ Query Decomposition desabilitada
- âŒ Adaptive Re-ranking desabilitado
- âŒ Router Inteligente desabilitado

### Fase 2A (Com OtimizaÃ§Ãµes)
- âœ… Query Decomposition ativa
- âœ… Adaptive Re-ranking ativo
- âœ… Router Inteligente ativo

---

## ğŸ“ˆ MÃ©tricas Coletadas

### 1. LatÃªncia
- Mean, Median (P50)
- P95, P99
- Por categoria de query

### 2. RAGAS (Qualidade)
- **Context Precision** - PrecisÃ£o dos contextos recuperados
- **Answer Relevancy** - RelevÃ¢ncia da resposta
- **Faithfulness** - Fidelidade aos documentos

### 3. Taxa de Sucesso
- Queries bem-sucedidas vs falhadas

---

## ğŸ“š Dataset de Queries

**Arquivo:** `tests/benchmark_queries.json`

**DistribuiÃ§Ã£o:**
- 15 queries **simples** (factuais diretas)
- 20 queries **moderadas** (conceituais, comparativas)
- 15 queries **complexas** (multi-hop, relacionais)

**Total:** 50 queries BSC variadas

---

## ğŸ” Troubleshooting

### Problema: Benchmark falha com erro de import

**SoluÃ§Ã£o:** Verificar que todas dependÃªncias estÃ£o instaladas:
```bash
pip install ragas datasets matplotlib seaborn pandas numpy
```

### Problema: RAGAS nÃ£o gera mÃ©tricas

**Causa:** Queries sem `answer` ou `contexts` vazios.  
**SoluÃ§Ã£o:** Verificar que workflow retorna `final_response` e `agent_responses`.

### Problema: LatÃªncias muito altas (>300s)

**Causa:** Muitas queries complexas ativando 4 agentes.  
**AÃ§Ã£o:** Isso Ã© esperado. Queries complexas podem levar 3-5 min.

---

## ğŸ“– InterpretaÃ§Ã£o de Resultados

### LatÃªncia

- **Melhoria positiva** (+X%): Fase 2A mais rÃ¡pida (bom!)
- **Trade-off negativo** (-X%): Fase 2A mais lenta (esperado com features adicionais)

**AceitÃ¡vel:** -10% a -20% mais lento com melhorias significativas em qualidade.

### RAGAS Metrics

- **Context Precision > 0.7**: Boa precisÃ£o de retrieval
- **Answer Relevancy > 0.8**: Respostas muito relevantes
- **Faithfulness > 0.85**: Alta fidelidade aos documentos

**Target Fase 2A:**
- Context Precision: +10-15% vs baseline
- Answer Relevancy: +20-30% vs baseline
- Faithfulness: +15-25% vs baseline

---

## ğŸ“ LiÃ§Ãµes Aprendidas

### 1. Query Decomposition

**Quando funciona bem:**
- Queries complexas multi-parte
- MÃºltiplas perspectivas BSC
- Relacionais ("Como X impacta Y?")

**ROI Esperado:** +30-50% answer quality

### 2. Adaptive Re-ranking

**Quando funciona bem:**
- Diversidade de fontes importante
- Evitar docs repetidos
- Metadata boosting

**ROI Esperado:** +15-25% precision

### 3. Router Inteligente

**Quando funciona bem:**
- Mix de queries simples e complexas
- OtimizaÃ§Ã£o de latÃªncia por tipo

**ROI Esperado:** -20% latÃªncia mÃ©dia (queries simples muito mais rÃ¡pidas)

---

## ğŸ“ PrÃ³ximos Passos

ApÃ³s anÃ¡lise dos resultados:

1. âœ… Validar que targets foram atingidos
2. ğŸ“Š Documentar liÃ§Ãµes em `docs/lessons/`
3. ğŸ“š Atualizar `docs/techniques/` com dados reais
4. ğŸ¯ Decidir: Fase 2B (Self-RAG, CRAG) ou ajustes

---

## ğŸ”— ReferÃªncias

- **RAGAS Framework:** https://docs.ragas.io/
- **Plano Fase 2:** `.cursor/plans/fase-2-rag-avancado.plan.md`
- **Router Central:** `.cursor/rules/rag-bsc-core.mdc`

---

**Ãšltima AtualizaÃ§Ã£o:** 2025-10-14  
**Status:** âœ… Pronto para uso

