---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## HEADERS

## TECH STACK

### Test Methodology (Validado Out/2025 - ROI: 32-60 min economizados por implementação)

**ANTES de escrever QUALQUER teste (unitário ou E2E), aplicar [[memory:9969868]] - CHECKLIST OBRIGATÓRIO de 12 pontos**:

**PONTOS 1-8: Testes Unitários** (validado FASE 2.5)

1. **Ler assinatura completa**: `grep "def method_name" src/file.py -A 10` (NUNCA assumir)
2. **Verificar tipo retorno**: Objeto Pydantic ou built-in? Campos obrigatórios?
3. **Contar parâmetros**: Quantos params (não contar `self`)?
4. **Validações pré-flight**: Validações no código + Pydantic (min_length, Literal, validators)
5. **Entender decorators**: @retry com `reraise=True` relança exceção original (NÃO RetryError)
6. **Fixtures Pydantic**: NUNCA passar `None` para `default_factory`. Incluir campos obrigatórios.
7. **Dados válidos em mocks**: Usar MARGEM DE SEGURANÇA (ex: min_length=20 → usar 50+ chars)
8. **Verificar método correto**: Confirmar nome exato via grep (ex: `invoke()` não `process_query()`)

**PONTOS 9-12: E2E Workflow Tests** (validado FASE 2.6) - Ver seção "E2E Workflow Tests" below for details

**Debugging pytest (Validado [[memory:9969628]])**:
*   **SEMPRE** usar `--tb=long` (traceback completo, NUNCA --tb=short)
*   **NUNCA** usar filtros (`Select-Object`, `Select-String`) - oculta informação crítica
*   Comando correto: `pytest tests/file.py -v --tb=long 2>&1`

**pytest em paralelo** (performance):
*   `-n <num_workers>`: Workers paralelos
*   `-v`: Verbose output
*   `--tb=long`: Traceback completo
*   `--dist=loadscope`: Distribui por fixture scope (mais seguro)
*   `--dist=loadfile`: Distribui por arquivo (fixtures function-scoped)

**Lições Detalhadas**:
- `docs/lessons/lesson-test-debugging-methodology-2025-10-15.md` (FASE 2.4, 5 erros)
- `docs/lessons/lesson-diagnostic-agent-test-methodology-2025-10-16.md` (FASE 2.5, 7 erros, 1.100+ linhas)
- `docs/lessons/lesson-onboarding-state-e2e-tests-2025-10-16.md` (FASE 2.6, 4 problemas E2E, 11.900+ linhas)

**ROI Comprovado**: Aplicar checklist ANTES economiza 38 minutos de debugging por implementação (validado FASE 2.5 unitário, FASE 2.6 E2E).

#### E2E Workflow Tests (Validado FASE 2.6 - Out/2025)

**Context**: Testes E2E de workflows LangGraph multi-turn stateless requerem 4 considerações adicionais ao checklist base.

**4 Pontos Adicionais (Checklist expandido: 8 → 12 pontos)**:

**9. Verificar property/método existe**:
*   **SEMPRE** usar `grep "@property\|def method_name" src/file.py` antes de usar em código
*   **Exemplo validado (2025-10-16)**: Assumiu `client_profile_agent` property existia → `AttributeError`
*   **Prevenção**: 
    ```bash
    grep "@property" src/graph/workflow.py | grep "client_profile_agent"
    # Se não retornar nada, property não existe - criar ou usar alternativa
    ```
*   **ROI**: 5-8 min economizados

**10. Considerar persistência de state**:
*   **SEMPRE** perguntar: "Como state persiste entre múltiplos `run()` calls?"
*   **Exemplo validado (2025-10-16)**: Workflow stateless, `onboarding_progress` perdido entre calls
*   **Solução padrão**: In-memory sessions dict
    ```python
    class BSCWorkflow:
        def __init__(self):
            self._onboarding_sessions: dict[str, dict[str, Any]] = {}
        
        def handler(self, state):
            user_id = state.user_id
            # Load session
            session = self._onboarding_sessions.get(user_id, {})
            # Process...
            # Save session
            self._onboarding_sessions[user_id] = updated_session
            # Cleanup (se completo)
            if is_complete:
                del self._onboarding_sessions[user_id]
    ```
*   **ROI**: 20-30 min economizados (pattern reutilizável)

**11. Fixtures Pydantic com ID customizado**:
*   **SEMPRE** criar profile inline quando teste precisa `client_id` específico
*   **Exemplo validado (2025-10-16)**: Fixture `client_id='fixture'`, teste esperava `'test_005'` → assertion falhou
*   **Template**:
    ```python
    test_profile = ClientProfile(
        client_id="test_cliente_specific_id",  # Match user_id do teste
        company=valid_client_profile.company,  # Reutilizar outros campos
        context=valid_client_profile.context,
        # ... demais campos do fixture original
    )
    ```
*   **ROI**: 8-12 min economizados

**12. Teste de regressão crítico OBRIGATÓRIO**:
*   **SEMPRE** incluir 1 teste validando que funcionalidade existente NÃO quebrou
*   **Exemplo validado (2025-10-16)**: `test_rag_workflow_cliente_existente_nao_quebrado`
    *   Validou que cliente existente (phase=DISCOVERY) usa RAG tradicional
    *   Routing correto, workflow completo, zero breaking changes
*   **Template**:
    ```python
    def test_existing_functionality_not_broken():
        """CRÍTICO: Validar que funcionalidade X não quebrou com nova feature Y.
        
        Este teste previne REGRESSÃO!
        """
        # Setup: Cliente/estado existente (não novo)
        mock_existing_state()
        
        # Action: Executar workflow tradicional
        result = workflow.run_traditional_flow(...)
        
        # Assert: Comportamento mantido
        assert traditional_method.called
        assert not new_feature_method.called  # Nova feature NÃO interferiu
    ```
*   **ROI**: Crítico (previne breaking changes, economiza horas de rollback)

**13. Circular Imports Resolution (Validado FASE 2.7 - Out/2025)**
*   **SEMPRE** usar pattern oficial Python (PEP 484 + PEP 563) para resolver circular imports
*   **Exemplo validado (2025-10-16)**: Circular import entre client_profile_agent, onboarding_agent e workflow
*   **Pattern**:
    ```python
    # arquivo.py
    from __future__ import annotations  # PEP 563: Postponed annotations
    
    from typing import TYPE_CHECKING
    
    # TYPE_CHECKING = True durante type checking (mypy/pyright)
    # TYPE_CHECKING = False em runtime (evita circular import!)
    if TYPE_CHECKING:
        from outro_modulo import OutraClasse
    
    class MinhaClasse:
        def metodo(self, param: OutraClasse):  # Type hint funciona!
            # Import local em runtime quando necessário
            from outro_modulo import OutraClasse
            ...
    ```
*   **ROI**: 40-60 min economizados vs tentativa e erro manual
*   **Lição Detalhada**: `docs/lessons/lesson-discovery-state-circular-import-2025-10-16.md`

**ROI Total E2E**: 32-60 min economizados por implementação (4 erros × 8-15 min/erro)

**Lição Detalhada**: `docs/lessons/lesson-onboarding-state-e2e-tests-2025-10-16.md` (11.900+ linhas)

### Circular Imports Resolution (Validado FASE 2.7 - Out/2025)

**Pattern Oficial Python**: PEP 484 (TYPE_CHECKING) + PEP 563 (postponed annotations) resolvem circular imports mantendo type hints completos.

**Quando Usar**:
- Módulos interdependentes (A importa B, B importa A)
- Type hints causando `ImportError: cannot import name 'X' from partially initialized module`
- IDE perde autocomplete por circular dependency

**Solução Completa** (validado Stack Overflow 587 upvotes, DataCamp 2025):

```python
# arquivo1.py
from __future__ import annotations  # PEP 563: Postponed annotations (CRÍTICO!)

from typing import TYPE_CHECKING

# TYPE_CHECKING = True durante type checking (mypy/pyright)
# TYPE_CHECKING = False em runtime (evita circular import!)
if TYPE_CHECKING:
    from arquivo2 import ClasseB

class ClasseA:
    def metodo(self, param: ClasseB):  # Type hint funciona sem quotes!
        # Lazy import em runtime apenas quando necessário
        from arquivo2 import ClasseB
        ...
```

```python
# arquivo2.py
from __future__ import annotations  # CRÍTICO em AMBOS arquivos!

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from arquivo1 import ClasseA

class ClasseB:
    def outro_metodo(self, param: ClasseA):  # Type hint funciona!
        from arquivo1 import ClasseA  # Lazy import runtime
        ...
```

**Pattern para Properties** (lazy loading com cache):

```python
class MinhaClasse:
    def __init__(self):
        self._cached_agent = None
    
    @property
    def agent(self) -> Agent:  # Type hint funciona!
        """Lazy loading com cache (import UMA VEZ)."""
        if self._cached_agent is None:
            from outro_modulo import Agent  # Import apenas quando acessado
            self._cached_agent = Agent()
        return self._cached_agent
```

**Checklist Aplicação**:

- [ ] 1. Identificar ciclo: `módulo A → módulo B → módulo A`
- [ ] 2. Adicionar `from __future__ import annotations` em **AMBOS** arquivos (topo, antes de imports)
- [ ] 3. Adicionar `from typing import TYPE_CHECKING` em ambos
- [ ] 4. Mover imports problemáticos para dentro de `if TYPE_CHECKING:` block
- [ ] 5. Type hints funcionam normalmente (sem quotes)
- [ ] 6. Implementar lazy imports em runtime (dentro de métodos/properties)
- [ ] 7. Usar cache em properties (evitar re-import a cada acesso)
- [ ] 8. Validar: `pytest tests/` deve passar sem `ImportError`
- [ ] 9. Validar: `mypy src/` ou `pyright src/` sem erros de tipo

**Ferramentas de Diagnóstico**:

```bash
# Detectar circular imports
python -c "import sys; import module_name"  # Se falhar = circular import

# Visualizar ordem de imports
python -v -c "import module_name" 2>&1 | grep "import"

# Verificar type hints funcionando
mypy src/module.py --show-error-codes
pyright src/module.py
```

**Antipadrões a Evitar**:

❌ **String annotations manuais** (trabalhoso):
```python
def metodo(self, param: "OutraClasse"):  # Funciona mas é verboso
```

✅ **Postponed annotations** (automático):
```python
from __future__ import annotations
def metodo(self, param: OutraClasse):  # Limpo e type-safe!
```

❌ **Lazy import sem cache** (performance):
```python
def metodo(self):
    from modulo import funcao  # ❌ Import em TODA chamada!
    funcao()
```

✅ **Lazy import com cache** (eficiente):
```python
@property
def agent(self):
    if self._agent is None:  # ✅ Import UMA VEZ
        from modulo import Agent
        self._agent = Agent()
    return self._agent
```

**ROI Validado**:
- ⏱️ **40-60 min economizados** vs tentativa e erro manual
- 🎯 Type hints completos (IDE autocomplete + mypy)
- ⚡ Performance (lazy loading)
- 📚 Pattern reutilizável (qualquer projeto Python)

**Quando Buscar Ajuda Comunidade**:

Se stuck >10 min, usar Brightdata/web search:
```
Query: "Python circular import best practices TYPE_CHECKING lazy import solutions 2024 2025"
```

**Referências**:
- [PEP 484 - Type Hints](https://www.python.org/dev/peps/pep-0484/)
- [PEP 563 - Postponed Evaluation of Annotations](https://www.python.org/dev/peps/pep-0563/)
- [Stack Overflow Q39740632](https://stackoverflow.com/questions/39740632/python-type-hinting-without-cyclic-imports) (587 upvotes)
- [DataCamp - Python Circular Import (2025)](https://www.datacamp.com/tutorial/python-circular-import)

**Lição Detalhada**: `docs/lessons/lesson-discovery-state-circular-import-2025-10-16.md` (1.200+ linhas, ROI 2.5-4x)

**Memória**: [[memory:9980685]] - Pattern TYPE_CHECKING + Lazy Imports validado FASE 2.7

Regarding `.cursorignore` files:

*   Cursor IDE uses `.cursorignore` files to control which files Cursor can access. This is for security and performance.
*   `.env` files are ignored by default.
*   To unignore a file, place an exclamation mark `!` in front of the ignore glob pattern in the `.cursorignore` file. For example: `!.env`.
*   You can edit the global ignore list in Cursor's settings. Go to `File > Preferences > VS code settings` and search for "Global Cursor Ignore List". You can remove patterns from the list there.
*   If you don't have a `.cursorignore` file, but `.env` files are still ignored, check the global ignore list.
*   Global cursorignore negations do not override `.gitignore` rules unless specific syntax is used.

### How to Liberate .env from the Global Cursor Ignore

Based on collected information, Cursor ignores `.env` files by default through global configuration. Here are three ways to liberate the file:

#### Method 1: Modify Global Ignore List (Recommended)

1.  **Open Cursor Settings:**
    *   Press `Ctrl + ,` (Windows) or `Cmd + ,` (Mac)
    *   Or go to: `File > Preferences > Settings`
2.  **Search for "Global Cursor Ignore":**
    *   Type in the search bar: `cursor ignore`
    *   Locate: **"Cursor > General: Global Cursor Ignore List"**
3.  **Remove or Comment the `.env` Entry:**
    *   You will see a list with patterns like:

    ```
    **/node_modules/**
    **/.git/**
    **/.env
    ```
    *   **Delete** the line `**/.env` or patterns related to `.env*`
    *   Click **"OK"** or save the settings.

#### Method 2: Use `.cursorignore` to "Unignore" (Local Override)

Create or edit the `.cursorignore` file in the **root of your project**:

```bash
# .cursorignore

# Unignore .env files (overrides the global ignore)
!.env
!.env.local
!.env.development

# You can also be more specific
!**/.env
```

**Important:** The `!` (exclamation) prefix **reverses** the ignore, allowing the file.

#### Method 3: Via Cursor Interface (Quick Shortcut)

1.  **Access Indexing Settings:**
    *   Go to: `Settings > Cursor > Indexing and Docs`
    *   Or search for: `cursor indexing`
2.  **Edit .cursorignore:**
    *   Click **"Edit .cursorignore"**
    *   Add the line: `!.env`
3.  **Reload the Index:**
    *   Press `Ctrl + Shift + P` (Windows) or `Cmd + Shift + P` (Mac)
    *   Type: `Cursor: Reindex Codebase`
    *   Execute the command

**IMPORTANT: Security Considerations**

Brightdata's research revealed important community discussions:

> **"Cursor ignores env files by default. Although risky, you can remove env files from the ignore list..."**

**Why does Cursor ignore `.env` by default?**

1.  **Credential Protection:** `.env` files contain API keys, passwords, and sensitive tokens.
2.  **Leakage Prevention:** Prevents information from being inadvertently sent to AI servers.
3.  **Context Security:** Prevents information from being inadvertently sent to AI servers.
4.  **Context Security:** Prevents credentials from appearing in chat/completions context.

**If you REALLY need to liberate `.env`:**

✅ **Best Practice:**

*   Use `.env.example` or `.env.template` with dummy values.
*   Liberate **only** these template files in the ignore.
*   Keep the real `.env` ignored.

❌ **Avoid:**

*   Liberating `.env` in public/shared projects.
*   Exposing real credentials in the AI context.
*   Removing protection in repositories with multiple collaborators.

**Test if it Worked**

1.  **Check the File Icon:**

    *   In the Cursor Explorer, ignored files show a 🚫 icon.
    *   After liberating, the icon should disappear.
2.  **Test in Chat:**

    *   Open Cursor Chat.
    *   Type: `@.env` (mention the file).
    *   If it works, the file has been successfully liberated.
3.  **Verify Indexing:**

    *   `Ctrl + P` → Type `.env`
    *   The file should appear in the results.

**Complete Example: `.cursorignore`**

```bash
# .cursorignore - Complete Example

# Keep ignored (security)
**/.env
**/.env.local
**/.env.production

# Liberate templates (safe)
!.env.example
!.env.template

# Other useful ignores
**/node_modules/**
**/.git/**
**/dist/**
**/build/**
**/__pycache/**
**/.pytest_cache/**
**/.venv/**
**/venv/**
```

**Sources (2025)**

*   [Cursor Docs - Ignore Files](https://cursor.com/docs/context/ignore/files)
*   [Cursor Forum - You can unignore files in .cursorignore](https://forum.cursor.com/t/you-can-unignore-files-in-cursorignore/38074)
*   [GitHub Issue #3101 - .env files ignored by default](https://github.com/cursor/cursor/issues/3101)
*   [Reddit r/cursor - How to disable .env from .cursorignore](https://www.reddit.com/r/cursor/comments/1ki08ww/)

### Language Detection Improvements

When the language detector in `src/rag/query_translator.py` is unable to determine the language of a query, it defaults to PT-BR. To improve language detection accuracy:

*   The `_detect_language` function has been enhanced with a regular expression to identify Portuguese suffixes (ção, ões, ário, ários, eira, eiras, eiro, eiros).
*   Word boundaries are used in keyword searches to prevent substring matches (e.g., "financial" in "financeiros").
*   The logging message has been updated to provide more context when the language is ambiguous.
*   Expand the list of keywords to include common BSC terms to improve language detection for technical queries.
*   When no keywords are detected, the system defaults to PT-BR, assuming a Brazilian context.

#### Code Snippets:

*   **Detecting Portuguese Suffixes:**

    ```python
    has_pt_suffixes = bool(re.search(r'\b\w*(ção|ões|ário|ários|eira|eiras|eiro|eiros)\b', text_lower))
    ```

*   **Keyword Search with Word Boundaries:**

    ```python
    pt_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    en_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    ```

### Dependency Management

*   When updating dependencies, especially `ruff`, ensure the version specified in `requirements.txt` is compatible with the project's other dependencies. Aim to use the latest stable version, but specify a version range to allow for minor updates without breaking changes. For example: `ruff>=0.7.0,<1.0.0`.
*   After updating dependencies in `requirements.txt`, run `pip install --upgrade -r requirements.txt` to update the environment.
*   When adding `mem0ai` ensure it is added in the Utilities section

### Pydantic Version Handling

*   When working with LangChain projects, be aware of Pydantic version compatibility. LangChain v0.3+ uses Pydantic V2 internally and recommends migrating imports from `langchain_core.pydantic_v1` to `pydantic` directly.
*   Avoid using the `pydantic.v1` compatibility namespace; import directly from Pydantic V2.
*   When using `BaseSettings` from `pydantic_settings`, use `SettingsConfigDict` instead of `ConfigDict` for configuration.

### New Rule: Python Circular Imports Resolution

When encountering circular import errors in Python, especially when using type hints, adhere to the following best practices:

- **Use `TYPE_CHECKING` for Conditional Imports**: Import modules or classes conditionally using the `typing.TYPE_CHECKING` flag. This ensures that the imports are only used during type-checking and not at runtime, which prevents circular import errors.
- **Leverage Lazy Imports**: Implement lazy imports within functions or methods. This defers the import statement until the function or method is called, avoiding circular dependencies during module loading.
- **Employ Forward References**: Use forward references as string literals for type hints. This allows you to refer to classes that are not yet defined. However, this approach should be combined with `from __future__ import annotations` for cleaner code.
- **Ensure Code Layering**: Refactor the code to ensure that the circular dependencies are not a result of poorly layered architecture. Consider using abstract classes or interfaces to define dependencies.
- **Apply Best Practices**: Follow community-endorsed best practices for circular import resolution.

### Rclone OneDrive Configuration and Usage

*   When using rclone with OneDrive, be aware of potential throttling issues, especially when transferring large files. To mitigate this, use the `--tpslimit` flag to limit transactions per second and the `--bwlimit` flag to limit bandwidth usage.
*   When encountering "404 page not found" errors during rclone OneDrive configuration, ensure that the client ID and secret are correctly set up.
*   When using rclone, if the browser doesn't open automatically for authentication, manually go to the provided link and authorize rclone for access.
*   If you encounter "No code returned by remote server" errors during rclone OneDrive authentication, recreate the client ID and secret carefully.
*   When assisting with rclone and OneDrive, it is generally **NOT RECOMMENDED** to run rclone and the native OneDrive client simultaneously due to potential conflicts, throttling issues, and unpredictable behavior. The best practice is to pause the OneDrive client while rclone is running.
*   If the native OneDrive client is necessary, rclone can be configured to exclude large files and limit bandwidth to minimize conflicts.
*   When using rclone for OneDrive, be aware of potential conflicts if the cloud file provider is not running. Ensure that the OneDrive service is active before using rclone.

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

### Architectural Considerations for the BSC Consulting Agent (v2.0)

The following architectural considerations should guide the development of the BSC Consulting Agent v2.0:

#### 1. Technology Stack Consolidation:

*   Prioritize integration with Mem0 for persistent memory, leveraging its LangGraph compatibility and validated performance metrics.
*   Incorporate MCPs for productivity, initially focusing on Google Calendar and Asana.

#### 2. Memory Implementation:

*   Utilize Mem0's platform API or consider a self-hosted alternative (PostgreSQL + pgvector) for storing client profiles and engagement progress.

#### 3. Workflow Orchestration:

*   Expand the LangGraph state machine to include a ConsultingEngagementState, with new states for onboarding, discovery, diagnostic, solution design, (optional) implementation, and monitoring.

#### 4. Agent Layer:

*   Augment existing BSC knowledge agents with new consulting agents: ClientProfileAgent, WorkshopFacilitatorAgent, and DiagnosticAnalystAgent.

#### 5. Tool/MCP Layer:

*   Integrate the Brightdata MCP (for external context), interactive tools (SWOT builder, strategy map designer, KPI definer, issue tree analyzer), and productivity MCPs (Google Calendar, Asana).

#### 6. Roadmap and Prioritization:

*   Follow a phased implementation, starting with a foundational MVP (Mem0 integration, onboarding, workflow, basic tools) and expanding to enterprise features (Brightdata, additional tools, productivity MCPs).

#### 7. Data Structuring for Mem0:

*   Adopt a well-defined schema for the ClientProfile in Mem0:

```json
{
  "user_id": "cliente_123",
  "company": {
    "name": "Empresa X",
    "industry": "Healthcare",
    "size": "200-500 employees",
    "maturity": "Growth stage"
  },
  "strategic_context": {
    "main_challenge": "Crescimento orgânico sem perder qualidade",
    "objectives": ["Aumentar EBITDA 20%", "Melhorar NPS 30pts"],
    "stakeholders": ["CEO Maria", "CFO João", "COO Ana"]
  },
  "engagement": {
    "mode": "Advisor",  // ou "Full Consultant"
    "current_phase": "DISCOVERY",
    "completed_activities": ["onboarding", "swot_analysis"],
    "pending_deliverables": ["diagnostic_report", "strategy_map"]
  },
  "preferences": {
    "communication_style": "Direto, dados-driven",
    "meeting_frequency": "Semanal",
    "tools": ["Google Calendar", "Asana"]
  },
  "history": [
    {"date": "2025-10-15", "activity": "Onboarding", "key_insights": "..."},
    {"date": "2025-10-18", "activity": "SWOT Workshop", "outputs": "..."}
  ]
}
```

#### 8. Memory Solution Evaluation

*   Mem0 (mem0.ai) is the preferred choice, offering native LangGraph integration, a validated research track record, and an available MCP.

#### 9. Productivity MCP Prioritization

*   Integrate Google Calendar and Asana MCPs to facilitate scheduling and project tracking.

#### 10. Implementation Roadmap

*   Prioritize a phased rollout, beginning with Mem0 integration and a basic workflow, followed by the addition of productivity MCPs.

### Next Step: FASE 2.5 - DiagnosticAgent

The following specifications, objectives, and checklist should be considered.

#### Specification

| Item           | Detail                               |
| ----- | --- |
| **ID**         | FASE 2.5                             |
| **Task**       | DiagnosticAgent                      |
| **Estimated Duration** | 2-3h                                 |
| **File**       | `src/agents/diagnostic_agent.py`     |

#### Objectives

1.  **Implement BSC diagnostic analysis** across the 4 perspectives:
    *   Financial
    *   Customers
    *   Internal Processes
    *   Learning and Growth
2.  **Integration with ClientProfile**:
    *   Consume company context (CompanyInfo)
    *   Analyze identified challenges
    *   Consider strategic objectives
3.  **Structured Output**:
    *   Diagnosis by perspective
    *   Identified gaps
    *   Improvement opportunities
    *   BSC-aligned recommendations
4.  **Quality**:
    *   15+ unit tests
    *   Coverage > 80%
    *   Complete type hints

#### Expected Outcome

*   📊 Phase 2 Progress: 50% (5/10 tasks)
*   🎯 DiagnosticAgent ready for FASE 2.6 (ONBOARDING State integration)

#### Pre-Implementation Checklist

*   ✅ ClientProfileAgent available (complete extraction)
*   ✅ OnboardingAgent available (conversational workflow)
*   ✅ BSCState v2.0 with consulting fields
*   ✅ 4 BSC expert agents (Financial, Customer, Process, Learning)
*   ✅ Functional RAG retriever (BSC literature)
*   ✅ Validated system prompts (`client_profile_prompts.py` as reference)

### To Consider:
*   [https://github.com/humanlayer/12-factor-agents](https://github.com/humanlayer/12-factor-agents)
*   [https://www.anthropic.com/engineering/building-effective-agents](https://www.anthropic.com/engineering/building-effective-agents)
*   [https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf)

## TEST CONFIGURATION

*   The test `test_parallel_agent_execution` now has a threshold of 200 seconds.
*   The test `test_latency_percentiles` now has a P95 threshold of 240 seconds (4 minutes).
*   Queries for testing are now stored in `tests/benchmark_queries.json`, which contains 50 varied BSC queries.
*   Consider using the RAGAS framework for automated evaluation. Key metrics include context relevancy (now context precision), answer relevancy, and faithfulness.
*   Ground truth data can be generated automatically by pre-trained models and validated manually by experts, focusing on a subset of the data (10-15%).
*   To ensure pytest discovers tests and handles imports correctly, add the following to `pyproject.toml` under `[tool.pytest.ini_options]`:

```toml
pythonpath = ["."]
# Usar importlib para resolver conflitos com __init__.py (Issue #11960 pytest-dev)
addopts = [
    "--import-mode=importlib",
]
```

### Test Debugging Methodology (Validated 2025-10-15)

**CRITICAL: When debugging failing tests, ALWAYS use this methodology:**

#### 1. Traceback Completo (OBRIGATÓRIO)

```bash
# ✅ CORRETO: Traceback completo SEM filtro
pytest tests/test_file.py -v --tb=long 2>&1

# ❌ NUNCA fazer: oculta informações críticas
pytest tests/test_file.py -v --tb=short 2>&1
pytest tests/test_file.py -v --tb=long 2>&1 | Select-Object -Last 50
pytest tests/test_file.py -v --tb=long 2>&1 | Select-String "ERROR"
```

**Por quê:** Filtros (Select-Object, Select-String, grep) ocultam linhas críticas do traceback que revelam a causa raiz do erro.

**Memória:** [[memory:9969628]] - Validado: economiza 8 min/erro evitado

#### 2. Sequential Thinking ANTES de Corrigir

Use sequential thinking para analisar erro ANTES de implementar correção:

1. **Thought 1**: Qual o erro exato? (ler traceback completo)
2. **Thought 2**: Qual a linha que falha? (identificar no código)
3. **Thought 3**: Qual a causa raiz? (não apenas o sintoma)
4. **Thought 4**: Qual a correção necessária? (mínima e cirúrgica)
5. **Thought 5**: Como validar a correção? (executar teste individual)

#### 3. Resolver UM Erro por Vez

```bash
# ✅ CORRETO: Focar em um teste falhando
pytest tests/test_file.py::test_specific_failing_test -v --tb=long 2>&1

# ❌ ERRADO: Tentar corrigir múltiplos erros simultaneamente
# (gera confusão e correções incorretas)
```

#### 4. Checklist ANTES de Escrever Testes

**Memória:** [[memory:9969868]] - Previne 80% dos erros comuns

- [ ] 1. **Ler assinatura completa** do método: `grep "def method_name" src/file.py -A 10`
- [ ] 2. **Verificar tipo de retorno** exato (list vs Pydantic object)
- [ ] 3. **Contar parâmetros** que o método aceita (não assumir)
- [ ] 4. **Verificar validações pré-flight** (if checks no início)
- [ ] 5. **Entender decorators** (@retry lança RetryError após N tentativas)
- [ ] 6. **Fixtures Pydantic**: NUNCA passar None para campos com default_factory
- [ ] 7. **Dados válidos em mocks**: Criar objetos Pydantic apenas com dados válidos

**ROI:** 8 min economizados por erro evitado

**Fonte:** `docs/lessons/lesson-test-debugging-methodology-2025-10-15.md` (428 linhas)

## BENCHMARKING

*   To run a full Fase 2A benchmark, use the command: `python tests/benchmark_fase2a/run_benchmark.py`.
*   To run a pilot benchmark with