---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## HEADERS

## TECH STACK

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

When running pytest in parallel, use the following flags:

*   `-n <num_workers>`: Specifies the number of workers for parallel execution.
*   `-v`: Enables verbose output.
*   `--tb=short`: Uses a short traceback format.
*   `--dist=loadscope`: Distributes tests by fixture scope (safer than `loadscope`).
*   `--dist=loadfile`: Distributes tests by file (use if fixtures are function-scoped).

Regarding `.cursorignore` files:

*   Cursor IDE uses `.cursorignore` files to control which files Cursor can access. This is for security and performance.
*   `.env` files are ignored by default.
*   To unignore a file, place an exclamation mark `!` in front of the ignore glob pattern in the `.cursorignore` file. For example: `!.env`.
*   You can edit the global ignore list in Cursor's settings. Go to `File > Preferences > VS code settings` and search for "Global Cursor Ignore List". You can remove patterns from the list there.
*   If you don't have a `.cursorignore` file, but `.env` files are still ignored, check the global ignore list.
*   Global cursorignore negations do not override `.gitignore` rules unless specific syntax is used.

### How to Liberate .env from the Global Cursor Ignore

Based on collected information, Cursor ignores `.env` files by default through global configuration. Here are three ways to liberate the file:

#### Method 1: Modify Global Ignore List (Recommended)

1.  **Open Cursor Settings:**
    *   Press `Ctrl + ,` (Windows) or `Cmd + ,` (Mac)
    *   Or go to: `File > Preferences > Settings`
2.  **Search for "Global Cursor Ignore":**
    *   Type in the search bar: `cursor ignore`
    *   Locate: **"Cursor > General: Global Cursor Ignore List"**
3.  **Remove or Comment the `.env` Entry:**
    *   You will see a list with patterns like:

    ```
    **/node_modules/**
    **/.git/**
    **/.env
    ```
    *   **Delete** the line `**/.env` or patterns related to `.env*`
    *   Click **"OK"** or save the settings.

#### Method 2: Use `.cursorignore` to "Unignore" (Local Override)

Create or edit the `.cursorignore` file in the **root of your project**:

```bash
# .cursorignore

# Unignore .env files (overrides the global ignore)
!.env
!.env.local
!.env.development

# You can also be more specific
!**/.env
```

**Important:** The `!` (exclamation) prefix **reverses** the ignore, allowing the file.

#### Method 3: Via Cursor Interface (Quick Shortcut)

1.  **Access Indexing Settings:**
    *   Go to: `Settings > Cursor > Indexing and Docs`
    *   Or search for: `cursor indexing`
2.  **Edit .cursorignore:**
    *   Click **"Edit .cursorignore"**
    *   Add the line: `!.env`
3.  **Reload the Index:**
    *   Press `Ctrl + Shift + P` (Windows) or `Cmd + Shift + P` (Mac)
    *   Type: `Cursor: Reindex Codebase`
    *   Execute the command

**IMPORTANT: Security Considerations**

Brightdata's research revealed important community discussions:

> **"Cursor ignores env files by default. Although risky, you can remove env files from the ignore list..."**

**Why does Cursor ignore `.env` by default?**

1.  **Credential Protection:** `.env` files contain API keys, passwords, and sensitive tokens.
2.  **Leakage Prevention:** Prevents information from being inadvertently sent to AI servers.
3.  **Context Security:** Prevents credentials from appearing in chat/completions context.

**If you REALLY need to liberate `.env`:**

✅ **Best Practice:**

*   Use `.env.example` or `.env.template` with dummy values.
*   Liberate **only** these template files in the ignore.
*   Keep the real `.env` ignored.

❌ **Avoid:**

*   Liberating `.env` in public/shared projects.
*   Exposing real credentials in the AI context.
*   Removing protection in repositories with multiple collaborators.

**Test if it Worked**

1.  **Check the File Icon:**

    *   In the Cursor Explorer, ignored files show a 🚫 icon.
    *   After liberating, the icon should disappear.
2.  **Test in Chat:**

    *   Open Cursor Chat.
    *   Type: `@.env` (mention the file).
    *   If it works, the file has been successfully liberated.
3.  **Verify Indexing:**

    *   `Ctrl + P` → Type `.env`
    *   The file should appear in the results.

**Complete Example: `.cursorignore`**

```bash
# .cursorignore - Complete Example

# Keep ignored (security)
**/.env
**/.env.local
**/.env.production

# Liberate templates (safe)
!.env.example
!.env.template

# Other useful ignores
**/node_modules/**
**/.git/**
**/dist/**
**/build/**
**/__pycache/**
**/.pytest_cache/**
**/.venv/**
**/venv/**
```

**Sources (2025)**

*   [Cursor Docs - Ignore Files](https://cursor.com/docs/context/ignore-files)
*   [Cursor Forum - You can unignore files in .cursorignore](https://forum.cursor.com/t/you-can-unignore-files-in-cursorignore/38074)
*   [GitHub Issue #3101 - .env files ignored by default](https://github.com/cursor/cursor/issues/3101)
*   [Reddit r/cursor - How to disable .env from .cursorignore](https://www.reddit.com/r/cursor/comments/1ki08ww/)

### Language Detection Improvements

When the language detector in `src/rag/query_translator.py` is unable to determine the language of a query, it defaults to PT-BR. To improve language detection accuracy:

*   The `_detect_language` function has been enhanced with a regular expression to identify Portuguese suffixes (ção, ões, ário, ários, eira, eiras, eiro, eiros).
*   Word boundaries are used in keyword searches to prevent substring matches (e.g., "financial" in "financeiros").
*   The logging message has been updated to provide more context when the language is ambiguous.
*   Expand the list of keywords to include common BSC terms to improve language detection for technical queries.
*   When no keywords are detected, the system defaults to PT-BR, assuming a Brazilian context.

#### Code Snippets:

*   **Detecting Portuguese Suffixes:**

    ```python
    has_pt_suffixes = bool(re.search(r'\b\w*(ção|ões|ário|ários|eira|eiras|eiro|eiros)\b', text_lower))
    ```

*   **Keyword Search with Word Boundaries:**

    ```python
    pt_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    en_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    ```

### Dependency Management

*   When updating dependencies, especially `ruff`, ensure the version specified in `requirements.txt` is compatible with the project's other dependencies. Aim to use the latest stable version, but specify a version range to allow for minor updates without breaking changes. For example: `ruff>=0.7.0,<1.0.0`.
*   After updating dependencies in `requirements.txt`, run `pip install --upgrade -r requirements.txt` to update the environment.
*   When adding `mem0ai` ensure it is added in the Utilities section

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

### Architectural Considerations for the BSC Consulting Agent (v2.0)

The following architectural considerations should guide the development of the BSC Consulting Agent v2.0:

#### 1. Technology Stack Consolidation:

*   Prioritize integration with Mem0 for persistent memory, leveraging its LangGraph compatibility and validated performance metrics.
*   Incorporate MCPs for productivity, initially focusing on Google Calendar and Asana.

#### 2. Memory Implementation:

*   Utilize Mem0's platform API or consider a self-hosted alternative (PostgreSQL + pgvector) for storing client profiles and engagement progress.

#### 3. Workflow Orchestration:

*   Expand the LangGraph state machine to include a ConsultingEngagementState, with new states for onboarding, discovery, diagnostic, solution design, (optional) implementation, and monitoring.

#### 4. Agent Layer:

*   Augment existing BSC knowledge agents with new consulting agents: ClientProfileAgent, WorkshopFacilitatorAgent, and DiagnosticAnalystAgent.

#### 5. Tool/MCP Layer:

*   Integrate the Brightdata MCP (for external context), interactive tools (SWOT builder, strategy map designer, KPI definer, issue tree analyzer), and productivity MCPs (Google Calendar, Asana).

#### 6. Roadmap and Prioritization:

*   Follow a phased implementation, starting with a foundational MVP (Mem0 integration, onboarding, workflow, basic tools) and expanding to enterprise features (Brightdata, additional tools, productivity MCPs).

#### 7. Data Structuring for Mem0:

*   Adopt a well-defined schema for the ClientProfile in Mem0:

```json
{
  "user_id": "cliente_123",
  "company": {
    "name": "Empresa X",
    "industry": "Healthcare",
    "size": "200-500 employees",
    "maturity": "Growth stage"
  },
  "strategic_context": {
    "main_challenge": "Crescimento orgânico sem perder qualidade",
    "objectives": ["Aumentar EBITDA 20%", "Melhorar NPS 30pts"],
    "stakeholders": ["CEO Maria", "CFO João", "COO Ana"]
  },
  "engagement": {
    "mode": "Advisor",  // ou "Full Consultant"
    "current_phase": "DISCOVERY",
    "completed_activities": ["onboarding", "swot_analysis"],
    "pending_deliverables": ["diagnostic_report", "strategy_map"]
  },
  "preferences": {
    "communication_style": "Direto, dados-driven",
    "meeting_frequency": "Semanal",
    "tools": ["Google Calendar", "Asana"]
  },
  "history": [
    {"date": "2025-10-15", "activity": "Onboarding", "key_insights": "..."},
    {"date": "2025-10-18", "activity": "SWOT Workshop", "outputs": "..."}
  ]
}
```

#### 8. Memory Solution Evaluation

*   Mem0 (mem0.ai) is the preferred choice, offering native LangGraph integration, a validated research track record, and an available MCP.

#### 9. Productivity MCP Prioritization

*   Integrate Google Calendar and Asana MCPs to facilitate scheduling and project tracking.

#### 10. Implementation Roadmap

*   Prioritize a phased rollout, beginning with Mem0 integration and a basic workflow, followed by the addition of productivity MCPs.

### To Consider:
*   [https://github.com/humanlayer/12-factor-agents](https://github.com/humanlayer/12-factor-agents)
*   [https://www.anthropic.com/engineering/building-effective-agents](https://www.anthropic.com/engineering/building-effective-agents)
*   [https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf)

## TEST CONFIGURATION

*   The test `test_parallel_agent_execution` now has a threshold of 200 seconds.
*   The test `test_latency_percentiles` now has a P95 threshold of 240 seconds (4 minutes).
*   Queries for testing are now stored in `tests/benchmark_queries.json`, which contains 50 varied BSC queries.
*   Consider using the RAGAS framework for automated evaluation. Key metrics include context relevancy (now context precision), answer relevancy, and faithfulness.
*   Ground truth data can be generated automatically by pre-trained models and validated manually by experts, focusing on a subset of the data (10-15%).
*   To ensure pytest discovers tests and handles imports correctly, add the following to `pyproject.toml` under `[tool.pytest.ini_options]`:

```toml
pythonpath = ["."]
# Usar importlib para resolver conflitos com __init__.py (Issue #11960 pytest-dev)
addopts = [
    "--import-mode=importlib",
]
```

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

When running pytest in parallel, use the following flags:

*   `-n <num_workers>`: Specifies the number of workers for parallel execution.
*   `-v`: Enables verbose output.
*   `--tb=short`: Uses a short traceback format.
*   `--dist=loadscope`: Distributes tests by fixture scope (safer than `loadscope`).
*   `--dist=loadfile`: Distributes tests by file (use if fixtures are function-scoped).

## BENCHMARKING

*   To run a full Fase 2A benchmark, use the command: `python tests/benchmark_fase2a/run_benchmark.py`.
*   To run a pilot benchmark with 5 queries, use the command: `python tests/benchmark_fase2a/run_benchmark.py --pilot`.
*   The benchmark compares BASELINE (without optimizations) against FASE 2A (with Query Decomposition, Adaptive Re-ranking, Router).
*   The benchmark should be executed in the background and its progress monitored.
*   Upon completion, a comparative report with all RAGAS metrics should be generated.
*   Estimated runtime: 2.5-3 hours.
*   Estimated cost: ~$1.60 USD.
*   The test `test_parallel_agent_execution` now has a threshold of 200 seconds.
*   The test `test_latency_percentiles` now has a P95 threshold of 240 seconds (4 minutes).
*   Queries for testing are now stored in `tests/benchmark_queries.json`, which contains 50 varied BSC queries.
*   Consider using the RAGAS framework for automated evaluation. Key metrics include context relevancy (now context precision), answer relevancy, and faithfulness.
*   Ground truth data can be generated automatically by pre-trained models and validated manually by experts, focusing on a subset of the data (10-15%).

## GIT WORKFLOW & SECURITY

### Handling Secrets and GitHub Push Protection

When working with Git, especially on projects involving API keys or sensitive information, it's crucial to follow secure practices to prevent accidental exposure of secrets. GitHub provides a feature called Push Protection that scans commits for known secrets and blocks the push if any are found. Here's how to handle such situations:

**1. Ensure `.env` and similar files are in `.gitignore`:**

*   Always include `.env`, `.env.local`, and similar environment configuration files in your `.gitignore` to prevent them from being accidentally committed to the repository.

**2. GitHub Push Protection Bypass (Use with Caution):**

*   If you accidentally commit secrets and GitHub blocks the push, it provides URLs to "Allow secret." This option should be used with extreme caution and only in private repositories where you trust all collaborators.

**3. Disabling Push Protection (Not Recommended):**

*   It is possible to disable Push Protection in your repository settings (`Code security > Secret scanning > Push protection`). However, this is generally **not recommended** as it reduces the security of your repository. Only disable it if you fully understand the risks.

**4. Best Practice: Removing Secrets from Git History**

*   The most secure approach is to remove the secrets from the Git history. This can be done using tools like `git filter-branch` or `BFG Repo Cleaner`. This process rewrites the commit history, so it should be done carefully and coordinated with all collaborators.

**5. .env Templates**

*   Use `.env.example` or `.env.template` files with placeholder values instead of committing the actual `.env` file.

**Example .gitignore:**

```
# Environment variables
.env
.env.local
.env.*.local
```

**Steps to recover from accidentally committing secrets:**

1.  **Immediately add `.env` to `.gitignore`**.
2.  **Remove the `.env` file from the repository:**

    ```bash
    git rm --cached .env
    git commit -m "Remove .env file"
    ```
3.  **Rewrite Git history (Advanced):** Use `git filter-branch` or BFG Repo Cleaner` to remove the file from all past commits. This is the most secure option but requires caution.
4.  **Inform Collaborators:** If others have pulled the commit, they need to rebase their work after the history is rewritten.

### Handling Accidental Commits of Secrets

If you accidentally commit secrets (like API keys) to a Git repository, especially a public one, follow these steps immediately to mitigate the risk:

1.  **Immediately add the secrets file (e.g., `.env`) to `.gitignore`**. This prevents future accidental commits.
2.  **Remove the secrets file from the repository's history.** This is crucial to prevent unauthorized access to the secrets. Use tools like `git filter-branch` or `BFG Repo Cleaner` for this purpose.

    ```bash
    # Example using git filter-branch (use with caution!)
    git filter-branch --force --index-filter \
    'git rm --cached --ignore-unmatch path/to/your/secrets_file' \
    --prune-empty --tag-name-filter cat -- --all
    git push origin --force --all
    git push origin --force --tags
    ```

    *   **Important:** Rewriting Git history can be complex and affect collaborators. Communicate with your team before performing these steps.
3.  **Reset the compromised secrets.** Generate new API keys, passwords, or tokens to invalidate the old ones.
4.  **Inform collaborators.** If others have pulled the commit, they need to rebase their work after the history is rewritten.
5.  **Enable GitHub Push Protection.** This feature helps prevent accidental commits of known secrets. Find it in your repository settings under `Code security > Secret scanning > Push protection`.
6.  **Consider using `.env.example` or `.env.template`:** Include these files with placeholder values instead of committing the actual `.env` file.

**GitHub Push Protection Bypass (Use with Caution):**

*   If you accidentally commit secrets and GitHub blocks the push, it provides URLs to "Allow secret." This option should be used with extreme caution and only in private repositories where you trust all collaborators.

**Disabling Push Protection (Not Recommended):**

*   It is possible to disable Push Protection in your repository settings (`Code security > Secret scanning > Push protection`). However, this is generally **not recommended** as it reduces the security of your repository. Only disable it if you fully understand the risks.

**Recovering from Committing Secrets (Comprehensive Guide):**

If secrets are accidentally committed, the following steps must be taken to fully resolve the problem:

1.  **Add the secrets file to `.gitignore`**: Ensure that `.env`, `.env.local`, and similar files are included in `.gitignore` to prevent future commits.
2.  **Remove the secrets file from the repository:**

    ```bash
    git rm --cached .env
    git commit -m "Remove .env file"
    ```
3.  **Rewrite Git history (Crucial):** Use `git filter-branch` or, preferably, `git filter-repo` (if available) to remove the file from all past commits. This is the most secure option:

    ```bash
    git filter-branch --force --index-filter "git rm --cached --ignore-unmatch .env" --prune-empty --tag-name-filter cat -- --all
    ```

    Or, using `git filter-repo` (requires installation):

   First, install git-filter-repo:

    ```bash
    pip install git-filter-repo
    ```

   Then, run the filter:

    ```bash
    git filter-repo --invert-blob-contents --path .env
    ```

    *   **Important:** Rewriting Git history can be complex and may affect collaborators. Communicate with your team before performing these steps.
4.  **Force Push:** After rewriting history, force push the changes:

    ```bash
    git push origin master --force
    ```
5.  **Stash Changes (If Necessary):** If there are unstaged changes, stash them before rebasing or filtering:

    ```bash
    git stash
    ```

    And pop them after the history rewrite:

    ```bash
    git stash pop
    ```
6.  **Verify `.env` is ignored:**

    ```bash
    git check-ignore -v .env
    ```

    This command should confirm that `.env` is now ignored by Git.
7.  **Inform Collaborators:** If others have pulled the commit, they need to rebase their work after the history is rewritten.

### .gitignore Rules
Always add the following to `.gitignore`:
*   `.cursor/progress/` to prevent accidental commits of temporary Cursor files that may contain secrets.

## DEBUGGING

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

When running pytest in parallel, use the following flags:

*   `-n <num_workers>`: Specifies the number of workers for parallel execution.
*   `-v`: Enables verbose output.
*   `--tb=short`: Uses a short traceback format.
*   `--tb=short`: Uses a short traceback format.
*   `--dist=loadscope`: Distributes tests by fixture scope (safer than `loadscope`).
*   `--dist=loadfile`: Distributes tests by file (safer than `loadscope`).
*   `--dist=loadfile`: Distributes tests by file (use if fixtures are function-scoped).

When the test `test_parallel_agent_execution` fails, the problem may be the threshold.
*   Check the tests and see if the threshold is too restrictive.
*   Consider the fact that the workflow includes routing, agents, synthesis and judge, and the threshold must account for those steps.

### Diagnosing Windows Clipboard Issues

If `Ctrl+C` and `Ctrl+V` are not working correctly on a Windows machine, follow these steps to diagnose and resolve the problem:

1.  **Test Globally:**
    *   Check if the issue is specific to Cursor IDE or a system-wide problem. Test in Notepad and a web browser.

2.  **Cursor-Specific Solutions:**
    *   **Verify Keyboard Shortcuts:**
        *   In Cursor, press `Ctrl + Shift + P` to open the Command Palette.
        *   Type "Preferences: Open Keyboard Shortcuts".
        *   Search for "copy" and "paste" to ensure they are mapped to `Ctrl+C` and `Ctrl+V`.
        *   Confirm that:
            * Copy → Ctrl+C with when: editorTextFocus && !editorReadonly
            * Paste → Ctrl+V with when: editorTextFocus && !editorReadonly
        *   If there is another entry with the same shortcut and a more specific "when", remove/Reset Keybinding.
    *   **Force Keyboard Dispatch Mode:**
        *   Open User Settings (JSON): `Ctrl + Shift + P` then type "Preferences: Open User Settings (JSON)".
        *   Add/adjust the following line:
            ```json
            "keyboard.dispatch": "code"
            ```
            Note: “code” resolves keycode conflicts in some layouts on Windows.
    *   **Reset Custom Keybindings:**
        *   Open User Settings (JSON): `Ctrl + Shift + P` then type "Preferences: Open User Settings (JSON)".
        *   Look for any custom keybinding configurations that might override `Ctrl+C` and `Ctrl+V`. Remove any conflicting settings.

3.  **Windows-Wide Solutions:**
    *   **Restart Clipboard Service:**
        *   Run the following command in PowerShell:
            ```powershell
            Stop-Process -Name "rdpclip" -Force -ErrorAction SilentlyContinue; Start-Sleep -Seconds 2; echo "[CHECK] Processo clipboard reiniciado (se existia)"
            ```
    *   **Verify Windows Accessibility Settings:**
        *   Press `Win + I` (Settings).
        *   Go to: **Accessibility** → **Keyboard**.
        *   Ensure that **"Sticky Keys"** is **DISABLED**.
        *   Ensure that **"Filter Keys"** is **DISABLED**.
    *   **Check for Intercepting Programs:**
        *   Some programs may intercept `Ctrl+C`/`Ctrl+V`. Check for the following processes: AutoHotkey, PowerToys, Ditto, ClipX, TeamViewer, AnyDesk, Discord, Slack, Skype, Zoom.
    *   **Test with Another Windows User:**
        *   Create a temporary Windows user account.
        *   Log in with that user.
        *   Test `Ctrl+C`/`Ctrl+V`. If it works, the issue is in your current user's settings.

4.  **If you use the Vim/Neovim extension:**
    *   In Settings (JSON), let VS Code/Cursor handle Ctrl+C/V:
        ```json
        "vim.useCtrlKeys": true,
        "vim.handleKeys": {
          "<C-c>": false,
          "<C-v>": false
        }
        ```
    *   Restart the window: Ctrl+Shift+P → “Developer: Reload Window”.

5.  **If the problem is only in the Integrated Terminal:**
    *   Adjust these parameters to avoid Ctrl+C becoming "SIGINT" and standardize pasting:
        ```json
        "terminal.integrated.copyOnSelection": false,
        "terminal.integrated.commandsToSkipShell": [
          "workbench.action.terminal.copySelection",
          "workbench.action.terminal.paste",
          "editor.action.clipboardCopyAction",
          "editor.action.clipboardPasteAction"
        ]
        ```
    *   In Keybindings, check:
        *   workbench.action.terminal.copySelection → Ctrl+C (when: terminalFocus && terminalHasSelection)
        *   workbench.action.terminal.paste → Ctrl+V (when: terminalFocus)

6.  **Other Useful Flags:**
    *   Copy line when no selection exists (optional):
        ```json
        "editor.emptySelectionClipboard": true
        ```

7.  **Safe Mode (Disable Extensions Temporarily):**
    *   Close Cursor.
    *   Open PowerShell.
    *   Execute:
        ```powershell
        cursor --disable-extensions
        ```
    *   Test if `Ctrl+C`/`Ctrl+Ctrl+v` works without extensions. If it works, re-enable extensions one by one to identify the culprit.

8.  **Last Resort (Extreme):**
    *   If nothing works, the issue might be:
        *   Corrupted keyboard driver.
        *   Third-party software intercepting shortcuts (AutoHotkey, etc.).
        *   Hardware issue with the keyboard.
    *   **Test with another keyboard** (USB or Bluetooth) to rule out hardware issues.

## WORKFLOW & RELEASE RULES

When debugging, especially for E2E tests, consider running tests in parallel to speed up the process. For example, use sequential thinking to organize your actions.

When running pytest in parallel, use the following flags:

*   `-n <num_workers>`: Specifies the number of workers for parallel execution.
*   `-v`: Enables verbose output.
*   `--tb=short`: Uses a short traceback format.
*   `--dist=loadscope`: Distributes tests by fixture scope (safer than `loadscope`).
*   `--dist=loadfile`: Distributes tests by file (use if fixtures are function-scoped).

### Installing rclone on Windows

To install rclone on Windows, Chocolatey is the recommended method. Ensure Chocolatey is installed, then run the following command in the terminal:

```bash
choco install rclone -y
```

If Chocolatey fails due to permission issues, try installing with Winget:

```bash
winget install Rclone.Rclone
```

### Configuring rclone for OneDrive

Use this simplified step-by-step guide to configure and use rclone with OneDrive, based on the [official rclone documentation](https://rclone.org/onedrive/):

#### Step 1: Configure OneDrive

Execute this command and follow the instructions:

```powershell
rclone config
```

**During the configuration:**

1.  **Type `n`** to create a new remote
2.  **Name**: Enter `onedrive` (or any name you prefer)
3.  **Type of storage**: Enter `onedrive` or the corresponding number
4.  **Client ID**: Press Enter (leave blank to use the default)
5.  **Client Secret**: Press Enter (leave blank to use the default)
6.  **Advanced config**: Enter `n` (no)
7.  **Auto authenticate**: Enter `y` (yes)
    *   Your browser will open automatically
    *   Log in to your Microsoft/OneDrive account
    *   Authorize rclone
8.  **Type of OneDrive**: Enter `1` for OneDrive Personal or Business
9.  **Choose the drive**: Enter `0` (or the number of your drive)
10. **Confirmation**: Enter `y` to confirm

#### Step 2: Test the Connection

```powershell
# List directories in OneDrive
rclone lsd onedrive:

# List all files
rclone ls onedrive:
```

#### Step 3: Synchronize OneDrive → D:\

**Option A: Sync (mirroring - deletes files that do not exist in the source)**

```powershell
rclone sync onedrive: D:\OneDrive-Backup -P -v
```

**Option B: Copy (copies without deleting destination files)**

```powershell
rclone copy onedrive: D:\OneDrive-Backup -P -v
```

**Useful flags:**

*   `-P` or `--progress`: Shows real-time progress
*   `-v` or `--verbose`: Shows more details
*   `--dry-run`: Simulates without making changes (recommended first!)
*   `--exclude "*.tmp"`: Excludes temporary files

#### Step 4: Bidirectional Synchronization (D:\ ↔ OneDrive)

For synchronization in both directions, use `bisync`:

```powershell
# First time (creates baseline)
rclone bisync onedrive: D:\OneDrive-Backup --resync -P -v

# Subsequent synchronizations
rclone bisync onedrive: D:\OneDrive-Backup -P -v
```

#### Step 5: Automation (Optional)

Create a file `sync-onedrive.ps1`:

```powershell
# sync-onedrive.ps1
Write-Host "[INICIO] Sincronizando OneDrive..." -ForegroundColor Cyan

rclone sync onedrive: D:\OneDrive-Backup `
    --progress `
    --verbose `
    --log-file="D:\rclone-sync.log" `
    --exclude "*.tmp" `
    --exclude ".git/**"

Write-Host "[FIM] Sincronização concluída!" -ForegroundColor Green
```

Execute with:

```powershell
.\sync-onedrive.ps1
```

#### Useful Commands

```powershell
# View current configuration
rclone config show

# Total size of OneDrive
rclone size onedrive:

# Compare source and destination
rclone check onedrive: D:\OneDrive-Backup

# Mount OneDrive as a virtual drive (Z:)
rclone mount onedrive: Z: --vfs-cache-mode writes
```

### Troubleshooting rclone OneDrive Configuration

**Problem:** 404 Page Not Found or "No code returned by remote server" during OneDrive configuration.

**Causes:**

*   Incorrect Client ID/Secret.
*   Firewall blocking localhost.
*   Incorrect Redirect URL.

**Solutions:**

1.  **Verify Client ID/Secret:**

    *   Double-check the Client ID and Client Secret in the Azure portal and in the rclone configuration.

2.  **Check Redirect URL:**

    *   Ensure the Redirect URL in the Azure portal is set to `http://localhost:53682/`.
3.  **Run Command Prompt as Admin**
4.  **Disable Firewall Temporarily:**

    *   Temporarily disable the Windows Firewall or create an exception for rclone to allow connections to localhost.

5.  **Alternative Authentication Method:**

    *   If the above steps don't work, try using an alternative authentication method, such as generating your own token (more complex).

6. **Manual Configuration (If Browser Authentication Fails):**

   *If browser authentication fails, you can try manual configuration:*

   1.  Run `rclone config`
   2.  Choose `n` for New remote.
   3.  Enter a name (e.g., `onedrive`).
   4.  Choose `onedrive` as the type.
   5.  When prompted for `client_id` and `client_secret`, leave them blank (press Enter).
   6.  When asked "Use web browser to automatically authenticate rclone with remote?", choose `n` (No).
   7.  Follow the instructions to generate a verification code manually.

### Resolving rclone Processes Stuck in Background

**Problem:** rclone processes are stuck in the background, consuming resources.

**Solution:**

1.  **Identify Running Processes:**

    *   Use the following PowerShell command to list rclone processes:
        ```powershell
        Get-Process | Where-Object {$_.ProcessName -like "*rclone*"} | Format-Table ProcessName, Id, CPU, PM -AutoSize
        ```

2.  **Terminate Processes:**

    *   Use the following PowerShell command to terminate all rclone processes:
        ```powershell
        Get-Process rclone | Stop-Process -Force
        ```

### Verifying rclone Configuration

**Problem:** Need to check or verify the current rclone OneDrive configuration.

**Solution:**

1.  **Show Configuration:**

    *   Use the following command to display the current rclone configuration for OneDrive:
        ```bash
        rclone config show onedrive
        ```

### Recommendations for OneDrive Synchronization

Given the challenges encountered with rclone and OneDrive, the following recommendations are made for efficiently synchronizing OneDrive data:

1.  **Prioritize the Native OneDrive Client:**
    *   Utilize the native OneDrive client provided by Microsoft for primary synchronization tasks. It is designed to handle OneDrive's specific requirements and limitations effectively.
    *   Configure the OneDrive client to download all files to ensure local availability.

2.  **Avoid rclone for Large-Scale OneDrive Synchronization:**
    *   Do not use rclone

## DEBUGGING

When debugging, especially for E2E tests, consider running tests