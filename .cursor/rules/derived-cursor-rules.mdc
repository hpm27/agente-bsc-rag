---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## HEADERS

## TECH STACK

### Test Methodology (Validado Out/2025 - ROI: 32-60 min economizados por implementação)

**ANTES de escrever QUALQUER teste (unitário ou E2E), aplicar [[memory:9969868]] - CHECKLIST OBRIGATÓRIO de 12 pontos**:

**PONTOS 1-8: Testes Unitários** (validado FASE 2.5)

1. **Ler assinatura completa**: `grep "def method_name" src/file.py -A 10` (NUNCA assumir)
2. **Verificar tipo retorno**: Objeto Pydantic ou built-in? Campos obrigatórios?
3. **Contar parâmetros**: Quantos params (não contar `self`)?
4. **Validações pré-flight**: Validações no código + Pydantic (min_length, Literal, validators)
5. **Entender decorators**: @retry com `reraise=True` relança exceção original (NÃO RetryError)
6. **Fixtures Pydantic**: NUNCA passar `None` para `default_factory`. Incluir campos obrigatórios.
7. **Dados válidos em mocks**: Usar MARGEM DE SEGURANÇA (ex: min_length=20 → usar 50+ chars)
8. **Verificar método correto**: Confirmar nome exato via grep (ex: `invoke()` não `process_query()`)

**PONTOS 9-12: E2E Workflow Tests** (validado FASE 2.6) - Ver seção "E2E Workflow Tests" below for details

**Debugging pytest (Validado [[memory:9969628]] e [[memory:10012853]])**:
*   **SEMPRE** usar `--tb=long` (traceback completo, NUNCA --tb=short)
*   **NUNCA** usar filtros (`Select-Object`, `Select-String`) - oculta informação crítica
*   Comando correto: `pytest tests/test_file.py -v --tb=long 2>&1`

**pytest em paralelo** (performance):
*   `-n <num_workers>`: Workers paralelos
*   `-v`: Verbose output
*   `--tb=long`: Traceback completo
*   `--dist=loadscope`: Distribui por fixture scope (mais seguro)
*   `--dist=loadfile`: Distribui por arquivo (fixtures function-scoped)

**Lições Detalhadas**:
- `docs/lessons/lesson-test-debugging-methodology-2025-10-15.md` (FASE 2.4, 5 erros)
- `docs/lessons/lesson-diagnostic-agent-test-methodology-2025-10-16.md` (FASE 2.5, 7 erros, 1.100+ linhas)
- `docs/lessons/lesson-onboarding-state-e2e-tests-2025-10-16.md` (FASE 2.6, 4 problemas E2E, 11.900+ linhas)

**ROI Comprovado**: Aplicar checklist ANTES economiza 38 minutos de debugging por implementação (validado FASE 2.5 unitário, FASE 2.6 E2E).

#### E2E Workflow Tests (Validado FASE 2.6 - Out/2025)

**Context**: Testes E2E de workflows LangGraph multi-turn stateless requerem 4 considerações adicionais ao checklist base.

**4 Pontos Adicionais (Checklist expandido: 8 → 12 pontos)**:

**9. Verificar property/método existe**:
*   **SEMPRE** usar `grep "@property\|def method_name" src/file.py` antes de usar em código
*   **Exemplo validado (2025-10-16)**: Assumiu `client_profile_agent` property existia → `AttributeError`
*   **Prevenção**: 
    ```bash
    grep "@property" src/graph/workflow.py | grep "client_profile_agent"
    # Se não retornar nada, property não existe - criar ou usar alternativa
    ```
*   **ROI**: 5-8 min economizados

**10. Considerar persistência de state**:
*   **SEMPRE** perguntar: "Como state persiste entre múltiplos `run()` calls?"
*   **Exemplo validado (2025-10-16)**: Workflow stateless, `onboarding_progress` perdido entre calls
*   **Solução padrão**: In-memory sessions dict
    ```python
    class BSCWorkflow:
        def __init__(self):
            self._onboarding_sessions: dict[str, dict[str, Any]] = {}
        
        def handler(self, state):
            user_id = state.user_id
            # Load session
            session = self._onboarding_sessions.get(user_id, {})
            # Process...
            # Save session
            self._onboarding_sessions[user_id] = updated_session
            # Cleanup (se completo)
            if is_complete:
                del self._onboarding_sessions[user_id]
    ```
*   **ROI**: 20-30 min economizados (pattern reutilizável)

**11. Fixtures Pydantic com ID customizado**:
*   **SEMPRE** criar profile inline quando teste precisa `client_id` específico
*   **Exemplo validado (2025-10-16)**: Fixture `client_id='fixture'`, teste esperava `'test_005'` → assertion falhou
*   **Template**:
    ```python
    test_profile = ClientProfile(
        client_id="test_cliente_specific_id",  # Match user_id do teste
        company=valid_client_profile.company,  # Reutilizar outros campos
        context=valid_client_profile.context,
        # ... demais campos do fixture original
    )
    ```
*   **ROI**: 8-12 min economizados

**12. Teste de regressão crítico OBRIGATÓRIO**:
*   **SEMPRE** incluir 1 teste validando que funcionalidade existente NÃO quebrou
*   **Exemplo validado (2025-10-16)**: `test_rag_workflow_cliente_existente_nao_quebrado`
    *   Validou que cliente existente (phase=DISCOVERY) usa RAG tradicional
    *   Routing correto, workflow completo, zero breaking changes
*   **Template**:
    ```python
    def test_existing_functionality_not_broken():
        """CRÍTICO: Validar que funcionalidade X não quebrou com nova feature Y.
        
        Este teste previne REGRESSÃO!
        """
        # Setup: Cliente/estado existente (não novo)
        mock_existing_state()
        
        # Action: Executar workflow tradicional
        result = workflow.run_traditional_flow(...)
        
        # Assert: Comportamento mantido
        assert traditional_method.called
        assert not new_feature_method.called  # Nova feature NÃO interferiu
    ```
*   **ROI**: Crítico (previne breaking changes, economiza horas de rollback)

**13. Circular Imports Resolution (Validado FASE 2.7 - Out/2025)**
*   **SEMPRE** usar pattern oficial Python (PEP 484 + PEP 563) para resolver circular imports
*   **Exemplo validado (2025-10-16)**: Circular import entre client_profile_agent, onboarding_agent e workflow
*   **Pattern**:
    ```python
    # arquivo.py
    from __future__ import annotations  # PEP 563: Postponed annotations
    
    from typing import TYPE_CHECKING
    
    # TYPE_CHECKING = True durante type checking (mypy/pyright)
    # TYPE_CHECKING = False em runtime (evita circular import!)
    if TYPE_CHECKING:
        from outro_modulo import OutraClasse
    
    class MinhaClasse:
        def metodo(self, param: OutraClasse):  # Type hint funciona!
            # Import local em runtime quando necessário
            from outro_modulo import OutraClasse
            ...
    ```
*   **ROI**: 40-60 min economizados vs tentativa e erro manual
*   **Lição Detalhada**: `docs/lessons/lesson-discovery-state-circular-import-2025-10-16.md`

**ROI Total E2E**: 32-60 min economizados por implementação (4 erros × 8-15 min/erro)

**Lição Detalhada**: `docs/lessons/lesson-onboarding-state-e2e-tests-2025-10-16.md` (11.900+ linhas)

### Regression Prevention Strategy (Validado FASE 2.10 - Out/2025)

**Context**: Durante FASE 2 (10 tarefas), validamos incrementalmente apenas testes NOVOS de cada etapa. Resultado: 10 regressões silenciosas detectadas apenas na regression suite final (60% causadas por schema changes). Aplicamos SFL + 5 Whys para corrigir (1.5h vs 4-6h estimado, ROI 2.5-4x).

**3 Estratégias Obrigatórias**:

#### 1. Smoke Tests (5-10 min por etapa)

**Quando**: Após completar CADA etapa (ex: FASE 3.2 SWOT Tool → smoke test)

**Comando**:
```bash
pytest -k "smoke" -v --tb=short
# Executa ~5 testes representativos (1 por módulo core)
# Tempo: 10-15s
```

**Se falha**: PARAR e investigar imediatamente (não acumular dívida técnica)

**ROI**: 5-10 min investidos, 1-2h debugging evitado por regressão detectada cedo

#### 2. Regression Suite Semanal (1h por semana)

**Quando**: Fim de semana (sexta-feira) ou antes de Checkpoint formal

**Comando**:
```bash
pytest -n 8 --dist=loadfile -v --tb=long
# Executa TODOS 350+ testes em paralelo
# Tempo: 45-60 min
```

**Análise**:
- 0-2 fails: OK (corrigir pontualmente)
- 3-10 fails: ALERTA (dedicar sessão correções)
- 10+ fails: CRÍTICO (pausar features, estabilizar)

**Checkpoint formal** (antes desbloquear próxima fase):
- FASE N 100% → Regression suite → 0 fails → FASE N+1 desbloqueada

**ROI**: 1h investida/semana, 4-6h debugging evitado (correções antecipadas)

#### 3. Contract Testing - Schemas Pydantic (10-15 min por mudança)

**Quando**: Ao modificar schema Pydantic core (CompanyInfo, ClientProfile, BSCState, SearchResult, DiagnosticResult, etc)

**Processo**:

1. **Identificar dependentes** (ANTES de mudar):
   ```bash
   grep -r "SchemaName" src/ tests/
   # Contar arquivos/testes impactados
   ```

2. **Baseline** (testes passando antes):
   ```bash
   pytest -k "schema_name" -v > before.txt
   ```

3. **Fazer mudança** (incremental, 1 campo por vez)

4. **Validar impactados** (após mudança):
   ```bash
   pytest -k "schema_name" -v > after.txt
   diff before.txt after.txt
   ```

5. **Se regressões**: Corrigir fixtures, validators, dependentes

6. **Se OK**: Commit

**ROI**: 20-25 min economizados vs full suite (10-15 min targeted vs 45-60 min full)

**Checklist 8 Pontos ANTES de Mudar Schema** [[memory:10020812]]:

- [ ] 1. Identificar dependentes: `grep -r "SchemaName" src/ tests/`
- [ ] 2. Executar baseline: `pytest -k "schema_name" -v > before.txt`
- [ ] 3. Mudança incremental (1 campo por vez)
- [ ] 4. Atualizar fixtures (min_length, Literal, defaults)
- [ ] 5. Validar impactados: `pytest -k "schema_name" -v > after.txt`
- [ ] 6. Smoke test: `pytest -k "smoke" --tb=short`
- [ ] 7. Read lints (warnings Pydantic V2)
- [ ] 8. Documentar breaking change (CHANGELOG ou migration guide)

**Schemas Core** (alto impacto, validação obrigatória):
- `CompanyInfo`: ~32 testes dependentes
- `ClientProfile`: ~45 testes dependentes
- `BSCState`: ~60 testes dependentes
- `SearchResult`: ~25 testes dependentes
- `DiagnosticResult`: ~16 testes dependentes
- `CompleteDiagnostic`: ~20 testes dependentes

**Impact Analysis Rápida**:

| Mudança Schema | Risco | Validação Mínima |
|---|---|---|
| Adicionar campo opcional | BAIXO | pytest -k "schema_name" (10-15 testes) |
| Mudar tipo campo (Literal → str) | MÉDIO | pytest -k "SchemaName" (30+ testes) |
| Adicionar validator | MÉDIO | pytest -k "schema_name or validate" (20-25 testes) |
| Remover campo obrigatório | ALTO | pytest -k "SchemaName" + manual review (50+ testes) |
| Mudar nome campo | CRÍTICO | grep -r "old_name" + pytest completo (100+ testes) |

**Antipadrão Evitar** [[memory:10020812]]:
❌ Mudar schema → commit direto sem pytest targeted
✅ Mudar schema → grep dependentes → pytest -k → validar → commit

**Lição Detalhada**: `docs/lessons/lesson-regression-prevention-methodology-2025-10-17.md` (1.550 linhas)

**ROI Comprovado**: Sessão 14 FASE 2: 10 regressões (60% schema changes), corrigidas em 1.5h com SFL + Contract Testing vs 4-6h tentativa-erro

#### Settings Singleton Pattern [[memory:10020824]]

**Regra Crítica**: `config.settings.Settings` é singleton; NUNCA recriar durante execução.

❌ **ANTI-PATTERN**:
```python
def validate_config():
    settings = Settings(_env_file=".env")  # Nova instância, ignora monkeypatch!
```

✅ **PATTERN CORRETO**:
```python
from config.settings import settings  # Import singleton global

def validate_config():
    current_settings = settings  # Usa global, respeita env vars
```

**Por quê**: Pydantic precedência quando `_env_file` explícito: .env > env vars. Testes monkeypatch quebram.

**ROI**: Previne falhas testes config validação (2 testes corrigidos Sessão 14)

### Circular Imports Resolution (Validado FASE 2.7 - Out/2025)

**Pattern Oficial Python**: PEP 484 (TYPE_CHECKING) + PEP 563 (postponed annotations) resolvem circular imports mantendo type hints completos.

**Quando Usar**:
- Módulos interdependentes (A importa B, B importa A)
- Type hints causando `ImportError: cannot import name 'X' from partially initialized module`
- IDE perde autocomplete por circular dependency

**Solução Completa** (validado Stack Overflow 587 upvotes, DataCamp 2025):

```python
# arquivo1.py
from __future__ import annotations  # PEP 563: Postponed annotations (CRÍTICO!)

from typing import TYPE_CHECKING

# TYPE_CHECKING = True durante type checking (mypy/pyright)
# TYPE_CHECKING = False em runtime (evita circular import!)
if TYPE_CHECKING:
    from arquivo2 import ClasseB

class ClasseA:
    def metodo(self, param: ClasseB):  # Type hint funciona sem quotes!
        # Lazy import em runtime apenas quando necessário
        from arquivo2 import ClasseB
        ...
```

```python
# arquivo2.py
from __future__ import annotations  # CRÍTICO em AMBOS arquivos!

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from arquivo1 import ClasseA

class ClasseB:
    def outro_metodo(self, param: ClasseA):  # Type hint funciona!
        from arquivo1 import ClasseA  # Lazy import runtime
        ...
```

**Pattern para Properties** (lazy loading com cache):

```python
class MinhaClasse:
    def __init__(self):
        self._cached_agent = None
    
    @property
    def agent(self) -> Agent:  # Type hint funciona!
        """Lazy loading com cache (import UMA VEZ)."""
        if self._cached_agent is None:
            from outro_modulo import Agent  # Import apenas quando acessado
            self._cached_agent = Agent()
        return self._cached_agent
```

**Checklist Aplicação**:

- [ ] 1. Identificar ciclo: `módulo A → módulo B → módulo A`
- [ ] 2. Adicionar `from __future__ import annotations` em **AMBOS** arquivos (topo, antes de imports)
- [ ] 3. Adicionar `from typing import TYPE_CHECKING` em ambos
- [ ] 4. Mover imports problemáticos para dentro de `if TYPE_CHECKING:` block
- [ ] 5. Type hints funcionam normalmente (sem quotes)
- [ ] 6. Implementar lazy imports em runtime (dentro de métodos/properties)
- [ ] 7. Usar cache em properties (evitar re-import a cada acesso)
- [ ] 8. Validar: `pytest tests/` deve passar sem `ImportError`
- [ ] 9. Validar: `mypy src/` ou `pyright src/` sem erros de tipo

**Ferramentas de Diagnóstico**:

```bash
# Detectar circular imports
python -c "import sys; import module_name"  # Se falhar = circular import

# Visualizar ordem de imports
python -v -c "import module_name" 2>&1 | grep "import"

# Verificar type hints funcionando
mypy src/module.py --show-error-codes
pyright src/module.py
```

**Antipadrões a Evitar**:

❌ **String annotations manuais** (trabalhoso):
```python
def metodo(self, param: "OutraClasse"):  # Funciona mas é verboso
```

✅ **Postponed annotations** (automático):
```python
from __future__ import annotations
def metodo(self, param: OutraClasse):  # Limpo e type-safe!
```

❌ **Lazy import sem cache** (performance):
```python
def metodo(self):
    from modulo import funcao  # ❌ Import em TODA chamada!
    funcao()
```

✅ **Lazy import com cache** (eficiente):
```python
@property
def agent(self):
    if self._agent is None:  # ✅ Import UMA VEZ
        from modulo import Agent
        self._agent = Agent()
    return self._agent
```

**ROI Validado**:
- ⏱️ **40-60 min economizados** vs tentativa e erro manual
- 🎯 Type hints completos (IDE autocomplete + mypy)
- ⚡ Performance (lazy loading)
- 📚 Pattern reutilizável (qualquer projeto Python)

**Quando Buscar Ajuda Comunidade**:

Se stuck >10 min, usar Brightdata/web search:
```
Query: "Python circular import best practices TYPE_CHECKING lazy import solutions 2024 2025"
```

**Referências**:
- [PEP 484 - Type Hints](https://www.python.org/dev/peps/pep-0484/)
- [PEP 563 - Postponed Evaluation of Annotations](https://www.python.org/dev/peps/pep-0563/)
- [Stack Overflow Q39740632](https://stackoverflow.com/questions/39740632/python-type-hinting-without-cyclic-imports) (587 upvotes)
- [DataCamp - Python Circular Import (2025)](https://www.datacamp.com/tutorial/python-circular-import)

**Lição Detalhada**: `docs/lessons/lesson-discovery-state-circular-import-2025-10-16.md` (1.200+ linhas, ROI 2.5-4x)

**Memória**: [[memory:9980685]] - Pattern TYPE_CHECKING + Lazy Imports validado FASE 2.7
[[memory:10012853]] - Pytest SEMPRE --tb=long SEM filtros (economia 50% tempo debugging)

Regarding `.cursorignore` files:

*   Cursor IDE uses `.cursorignore` files to control which files Cursor can access. This is for security and performance. This is for security and performance.
*   `.env` files are ignored by default.
*   To unignore a file, place an exclamation mark `!` in front of the ignore glob pattern in the `.cursorignore` file. For example: `!.env`.
*   You can edit the global ignore list in Cursor's settings. Go to `File > Preferences > VS code settings` and search for "Global Cursor Ignore List". You can remove patterns from the list there.
*   If you don't have a `.cursorignore` file, but `.env` files are still ignored, check the global ignore list.
*   Global cursorignore negations do not override `.gitignore` rules unless specific syntax is used.

### How to Liberate .env from the Global Cursor Ignore

Based on collected information, Cursor ignores `.env` files by default through global configuration. Here are three ways to liberate the file:

#### Method 1: Modify Global Ignore List (Recommended)

1.  **Open Cursor Settings:**
    *   Press `Ctrl + ,` (Windows) or `Cmd + ,` (Mac)
    *   Or go to: `File > Preferences > Settings`
2.  **Search for "Global Cursor Ignore":**
    *   Type in the search bar: `cursor ignore`
    *   Locate: **"Cursor > General: Global Cursor Ignore List"**
3.  **Remove or Comment the `.env` Entry:**
    *   You will see a list with patterns like:

    ```
    **/node_modules/**
    **/.git/**
    **/.env
    ```
    *   **Delete** the line `**/.env` or patterns related to `.env*`
    *   Click **"OK"** or save the settings.

#### Method 2: Use `.cursorignore` to "Unignore" (Local Override)

Create or edit the `.cursorignore` file in the **root of your project**:

```bash
# .cursorignore

# Unignore .env files (overrides the global ignore)
!.env
!.env.local
!.env.development

# You can also be more specific
!**/.env
```

**Important:** The `!` (exclamation) prefix **reverses** the ignore, allowing the file.

#### Method 3: Via Cursor Interface (Quick Shortcut)

1.  **Access Indexing Settings:**
    *   Go to: `Settings > Cursor > Indexing and Docs`
    *   Or search for: `cursor indexing`
2.  **Edit .cursorignore:**
    *   Click **"Edit .cursorignore"**
    *   Add the line: `!.env`
3.  **Reload the Index:**
    *   Press `Ctrl + Shift + P` (Windows) or `Cmd + Shift + P` (Mac)
    *   Type: `Cursor: Reindex Codebase`
    *   Execute the command

**IMPORTANT: Security Considerations**

Brightdata's research revealed important community discussions:

> **"Cursor ignores env files by default. Although risky, you can remove env files from the ignore list..."**

**Why does Cursor ignore `.env` by default?**

1.  **Credential Protection:** `.env` files contain API keys, passwords, and sensitive tokens.
2.  **Leakage Prevention:** Prevents information from being inadvertently sent to AI servers.
3.  **Context Security:** Prevents information from being inadvertently sent to AI servers.
4.  **Context Security:** Prevents credentials from appearing in chat/completions context.

**If you REALLY need to liberate `.env`:**

✅ **Best Practice:**

*   Use `.env.example` or `.env.template` with dummy values.
*   Liberate **only** these template files in the ignore.
*   Keep the real `.env` ignored.

❌ **Avoid:**

*   Liberating `.env` in public/shared projects.
*   Exposing real credentials in the AI context.
*   Removing protection in repositories with multiple collaborators.

**Test if it Worked**

1.  **Check the File Icon:**

    *   In the Cursor Explorer, ignored files show a 🚫 icon.
    *   After liberating, the icon should disappear.
2.  **Test in Chat:**

    *   Open Cursor Chat.
    *   Type: `@.env` (mention the file).
    *   If it works, the file has been successfully liberated.
3.  **Verify Indexing:**

    *   `Ctrl + P` → Type `.env`
    *   The file should appear in the results.

**Complete Example: `.cursorignore`**

```bash
# .cursorignore - Complete Example

# Keep ignored (security)
**/.env
**/.env.local
**/.env.production

# Liberate templates (safe)
!.env.example
!.env.template

# Other useful ignores
**/node_modules/**
**/.git/**
**/dist/**
**/build/**
**/__pycache/**
**/.pytest_cache/**
**/.venv/**
**/venv/**
```

**Sources (2025)**

*   [Cursor Docs - Ignore Files](https://cursor.com/docs/context/ignore/files)
*   [Cursor Forum - You can unignore files in .cursorignore](https://forum.cursor.com/t/you-can-unignore-files-in-cursorignore/38074)
*   [GitHub Issue #3101 - .env files ignored by default](https://github.com/cursor/cursor/issues/3101)
*   [Reddit r/cursor - How to disable .cursorignore from .cursorignore](https://www.reddit.com/r/cursor/comments/1ki08ww/)

### Language Detection Improvements

When the language detector in `src/rag/query_translator.py` is unable to determine the language of a query, it defaults to PT-BR. To improve language detection accuracy:

*   The `_detect_language` function has been enhanced with a regular expression to identify Portuguese suffixes (ção, ões, ário, ários, eira, eiras, eiro, eiros).
*   Word boundaries are used in keyword searches to prevent substring matches (e.g., "financial" in "financeiros").
*   The logging message has been updated to provide more context when the language is ambiguous.
*   Expand the list of keywords to include common BSC terms to improve language detection for technical queries.
*   When no keywords are detected, the system defaults to PT-BR, assuming a Brazilian context.

#### Code Snippets:

*   **Detecting Portuguese Suffixes:**

    ```python
    has_pt_suffixes = bool(re.search(r'\b\w*(ção|ões|ário|ários|eira|eiras|eiro|eiros)\b', text_lower))
    ```

*   **Keyword Search with Word Boundaries:**

    ```python
    pt_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    en_count = sum(1 for kw in pt_keywords if re.search(r'\b' + re.escape(kw) + r'\b', text_lower))
    ```

### Dependency Management

*   When updating dependencies, especially `ruff`, ensure the version specified in `requirements.txt` is compatible with the project's other dependencies. Aim to use the latest stable version, but specify a version range to allow for minor updates without breaking changes. For example: `ruff>=0.7.0,<1.0.0`.
*   After updating dependencies in `requirements.txt`, run `pip install --upgrade -r requirements.txt` to update the environment.
*   When adding `mem0ai` ensure it is added in the Utilities section

### Pydantic Version Handling

*   When working with LangChain projects, be aware of Pydantic version compatibility. LangChain v0.3+ uses Pydantic V2 internally and recommends migrating imports from `langchain_core.pydantic_v1` to `pydantic` directly.
*   Avoid using the `pydantic.v1` compatibility namespace; import directly from Pydantic V2.
*   When using `BaseSettings` from `pydantic_settings`, use `SettingsConfigDict` instead of `ConfigDict` for configuration.
*   **Pydantic Config Migration**: Replace `class Config:` with `model_config = ConfigDict(...)` in Pydantic models to avoid deprecation warnings.

### New Rule: Python Circular Imports Resolution

When encountering circular import errors in Python, especially when using type hints, adhere to the following best practices:

- **Use `TYPE_CHECKING` for Conditional Imports**: Import modules or classes conditionally using the `typing.TYPE_CHECKING` flag. This ensures that the imports are only used during type-checking and not at runtime, which prevents circular import errors.
- **Leverage Lazy Imports**: Implement lazy imports within functions or methods. This defers the import statement until the function or method is called, avoiding circular dependencies during module loading.
- **Employ Forward References**: Use forward references as string literals for type hints. This allows you to refer to classes that are not yet defined. However, this approach should be combined with `from __future__ import annotations` for cleaner code.
- **Ensure Code Layering**: Refactor the code to ensure that the circular dependencies are not a result of poorly layered architecture. Consider using abstract classes or interfaces to define dependencies.
- **Apply Best Practices**: Follow community-endorsed best practices for circular import resolution.

### Rclone OneDrive Configuration and Usage

*   When using rclone with OneDrive, be aware of potential throttling issues, especially when transferring large files. To mitigate this, use the `--tpslimit` flag to limit transactions per second and the `--bwlimit` flag to limit bandwidth usage.
*   When encountering "404 page not found" errors during rclone OneDrive configuration, ensure that the client ID and secret are correctly set up.
*   When using rclone, if the browser doesn't open automatically for authentication, manually go to the provided link and authorize rclone for access.
*   If you encounter "No code returned by remote server" errors during rclone OneDrive authentication, recreate the client ID and secret carefully.
*   When assisting with rclone and OneDrive, it is generally **NOT RECOMMENDED** to run rclone and the native OneDrive client simultaneously due to potential conflicts, throttling issues, and unpredictable behavior. The best practice is to pause the OneDrive client while rclone is running.
*   If the native OneDrive client is necessary, rclone can be configured to exclude large files and limit bandwidth to minimize conflicts.
*   When using rclone for OneDrive, be aware of potential conflicts if the cloud file provider is not running. Ensure that the OneDrive service is active before using rclone.

### Diagnosing Windows Clipboard Issues

When troubleshooting issues with Ctrl+C and Ctrl+V (copy/paste) functionality in Windows, especially when copying between applications like Microsoft Word and Cursor, consider the following:

*   **Clipboard Service (rdpclip):**
    *   Restart the clipboard service using PowerShell:
    ```powershell
    Stop-Process -Name "rdpclip" -Force -ErrorAction SilentlyContinue; Start-Sleep -Seconds 2; Write-Host "[CHECK] Processo clipboard reiniciado"
    ```

*   **.NET Clipboard Reset:**
    *   Clear the clipboard using .NET:
    ```powershell
    Add-Type -AssemblyName System.Windows.Forms; [System.Windows.Forms.Clipboard]::Clear(); Write-Host "[OK] Clipboard limpo via .NET"
    ```

*   **Win32 API Clipboard Reset:**
    *   Reset the clipboard at a lower level using the Win32 API:
    ```powershell
    $cbdll = Add-Type -MemberDefinition '[DllImport("user32.dll")] public static extern bool OpenClipboard(IntPtr hWndNewOwner); [DllImport("user32.dll")] public static extern bool EmptyClipboard(); [DllImport("user32.dll")] public static extern bool CloseClipboard();' -Name Clipboard -Namespace Win32 -PassThru; $cbdll::OpenClipboard([IntPtr]::Zero); $cbdll::EmptyClipboard(); $cbdll::CloseClipboard(); Write-Host "[OK] Clipboard resetado a nível Win32 API"
    ```

*   **Potential Conflicts with Other Processes:**
    *   Check for processes known to intercept clipboard functions:
    ```powershell
    $procs = @("AutoHotkey", "Ditto", "ClipX", "PowerToys", "TeamViewer", "AnyDesk"); $found = Get-Process | Where-Object {$procs -contains $_.ProcessName}; if($found) { $found | Format-Table ProcessName, Id -AutoSize } else { Write-Host "[INFO] Nenhum processo conhecido interceptando clipboard detectado" }
    ```

*   **Cursor-Specific Keybindings:**
    *   Verify that "copy" and "paste" are correctly mapped to `Ctrl+C` and `Ctrl+V` in Cursor's keyboard shortcuts (`Preferences: Open Keyboard Shortcuts`). Ensure the condition `editorTextFocus` is present. If conflicts exist, reset the keybindings.

*   **Windows Clipboard Functionality Test:**
    *   Test the global Windows clipboard using PowerShell:
    ```powershell
    echo "Teste Clipboard" | Set-Clipboard; $result = Get-Clipboard; if($result -eq "Teste Clipboard") { Write-Host "[OK] Clipboard do Windows funcionando corretamente via PowerShell" } else { Write-Host "[ERRO] Clipboard do Windows com problemas" }
    ```

*   **Application Privilege Levels:**
    *   Differences in privilege levels between applications (e.g., Word running as administrator while Cursor does not) can cause issues.

*   **Clipboard Format Incompatibility:**
    *   Incompatibility in clipboard formats between applications may prevent copying and pasting.

*   **Forcing Clipboard Synchronization:**
    *   Attempt to force synchronization of the clipboard:
    ```powershell
    Add-Type -AssemblyName System.Windows.Forms; [System.Windows.Forms.Clipboard]::Clear(); Start-Sleep -Milliseconds 500; [System.Windows.Forms.Clipboard]::SetText("CURSOR_WORD_SYNC_