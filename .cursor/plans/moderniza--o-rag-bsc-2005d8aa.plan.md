<!-- 2005d8aa-1b1e-4371-b931-540c026d8825 2956b390-5d29-4fa5-8a7d-98638a32730f -->
# Plano de Desenvolvimento - Agente BSC RAG 2025 (MVP-First)

## üéØ Vis√£o Geral

**IMPORTANTE**: Este projeto est√° em fase INICIAL (sem dados no database). O plano foi ajustado para abordagem **MVP-First**: criar sistema funcional end-to-end PRIMEIRO, validar com dados reais, DEPOIS adicionar features avan√ßadas.

**Estrat√©gia**:

- **FASE 1 (3-4 semanas)**: MVP completo funcional com arquitetura moderna
- **FASE 2 (4-6 semanas)**: Features avan√ßadas baseadas em necessidade real validada

---

## ‚úÖ J√Å IMPLEMENTADO

### üìÖ Resumo de Progresso Recente (09/10/2025)

**Fase 0B - Setup de Ambiente**: COMPLETA ‚úÖ

- Ambiente Python configurado com todas as depend√™ncias
- Docker Compose rodando (Qdrant, Weaviate, Redis)
- Scripts de automa√ß√£o e valida√ß√£o criados
- Documenta√ß√£o completa de setup

**Fase 1A - Pipeline RAG**: COMPLETA ‚úÖ

- Embeddings OpenAI implementado
- Retriever com Hybrid Search funcional
- Re-ranker Cohere integrado
- Pipeline de ingest√£o completo

**Fase 1B - Sistema Multi-Agente**: COMPLETA ‚úÖ

- 4 Agentes Especialistas BSC implementados
- Judge Agent para valida√ß√£o de respostas
- Orchestrator para coordena√ß√£o
- Ferramentas RAG integradas

**Pr√≥ximo**: Fase 1C - LangGraph Workflow + Interface Streamlit

---

### 0.1 Vector Store Moderno ‚úÖ

- Interface `BaseVectorStore` abstrata
- `QdrantVectorStore` (recomendado 2025)
- `WeaviateVectorStore` (alternativa com hybrid search nativo)
- `RedisVectorStore` (legacy/compatibilidade)
- Factory pattern para f√°cil troca
- Docker configurado com Qdrant, Weaviate e Redis
- Benchmark script completo

### 0.2 Contextual Retrieval (Anthropic) ‚úÖ

- `ContextualChunker` com Claude 3.5 Sonnet
- Prompt Caching para reduzir custos
- Cache local de contextos
- Redu√ß√£o esperada: 35-49% em falhas de retrieval
- Prompts especializados para BSC

### 0.3 Chunking ‚úÖ

- `SemanticChunker` (respeita limites sem√¢nticos)
- `TableAwareChunker` (preserva tabelas intactas)
- Configura√ß√£o flex√≠vel (chunk_size, overlap)

### 0.4 Setup de Ambiente ‚úÖ

- Ambiente virtual Python criado (`venv/`)
- Todas as depend√™ncias instaladas via `requirements.txt`
- Docker Compose configurado e containers iniciados:
  - Qdrant (localhost:6333)
  - Weaviate (localhost:8080)
  - Redis (localhost:6379)
- Arquivo `.env` criado com templates de configura√ß√£o
- Scripts de automa√ß√£o:
  - `setup.ps1` - Setup automatizado completo
  - `scripts/validate_setup.py` - Valida√ß√£o de ambiente
- Documenta√ß√£o de setup:
  - `SETUP.md` - Guia passo a passo detalhado
  - `PROGRESS.md` - Acompanhamento de progresso
- Estrutura de diret√≥rios criada (data/, models/, logs/)
- Mem√≥ria criada: Nunca usar emojis em c√≥digo (ID: 9592459)

---

## FASE 1: MVP FUNCIONAL (3-4 semanas)

### üì¶ FASE 1A - Pipeline RAG Completo (Semana 1)

#### 1.1 Implementar Embeddings ‚úÖ CONCLU√çDO

**Objetivo**: M√≥dulo de embeddings com OpenAI text-embedding-3-large

**A√ß√µes**:

- Criar `src/rag/embeddings.py`
- Implementar `EmbeddingGenerator` com OpenAI
- Suporte a batch processing para performance
- Cache opcional de embeddings
- Tratamento de rate limiting
- Integra√ß√£o com settings

**Arquivos**:

- `src/rag/embeddings.py` (novo)
- `tests/test_embeddings.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.2 Implementar Retriever com Hybrid Search ‚úÖ CONCLU√çDO

**Objetivo**: Retriever que usa vector store com hybrid search (70% sem√¢ntica + 30% BM25)

**A√ß√µes**:

- Criar `src/rag/retriever.py`
- Implementar `HybridRetriever`
- Integrar com vector store (via factory)
- Suporte a filtros de metadados
- Implementar RRF (Reciprocal Rank Fusion)
- Logging detalhado de retrieval
- M√©tricas de performance

**Arquivos**:

- `src/rag/retriever.py` (novo ou atualizar existente)
- `tests/test_retriever.py` (novo)

**Tempo estimado**: 2 dias

---

#### 1.3 Implementar Re-ranker ‚úÖ CONCLU√çDO

**Objetivo**: Re-ranking com Cohere Rerank Multilingual v3.0

**A√ß√µes**:

- Criar/atualizar `src/rag/reranker.py`
- Implementar `CohereReranker`
- Fallback para scoring local se API falhar
- Integra√ß√£o com retriever
- Configura√ß√£o de top_n
- Cache de re-rankings

**Arquivos**:

- `src/rag/reranker.py` (novo ou atualizar)
- `tests/test_reranker.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.4 Pipeline de Ingest√£o ‚úÖ CONCLU√çDO

**Objetivo**: Script para indexar documentos BSC no vector store

**A√ß√µes**:

- Criar/atualizar `scripts/build_knowledge_base.py`
- Integrar: Chunking ‚Üí Contextual Retrieval ‚Üí Embeddings ‚Üí Vector Store
- Suporte a m√∫ltiplos formatos (PDF, DOCX, TXT)
- Progress bar e logging
- Estat√≠sticas de ingest√£o
- Configura√ß√£o via CLI args

**Arquivos**:

- `scripts/build_knowledge_base.py` (novo ou atualizar)
- `scripts/ingest_utils.py` (novo - utilit√°rios)

**Tempo estimado**: 2 dias

---

### ü§ñ FASE 1B - Sistema Multi-Agente (Semana 2-3)

#### 1.5 Ferramentas RAG para Agentes ‚úÖ CONCLU√çDO

**Objetivo**: Ferramentas que agentes usar√£o para buscar informa√ß√µes

**A√ß√µes**:

- Criar `src/tools/rag_tools.py`
- Implementar `SearchTool` (busca h√≠brida)
- Implementar `DetailedSearchTool` (busca com contexto expandido)
- Implementar `FilteredSearchTool` (busca com filtros)
- Integra√ß√£o com Retriever + Re-ranker
- Formata√ß√£o de resultados para agentes

**Arquivos**:

- `src/tools/__init__.py` (atualizar)
- `src/tools/rag_tools.py` (novo)
- `tests/test_rag_tools.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.6 Agentes Especialistas BSC (4 agentes) ‚úÖ CONCLU√çDO

**Objetivo**: Criar os 4 agentes especialistas (Financeira, Clientes, Processos, Aprendizado)

**A√ß√µes**:

- Criar `src/agents/financial_agent.py` - Perspectiva Financeira
- Criar `src/agents/customer_agent.py` - Perspectiva de Clientes
- Criar `src/agents/process_agent.py` - Perspectiva de Processos Internos
- Criar `src/agents/learning_agent.py` - Perspectiva de Aprendizado e Crescimento
- Cada agente com:
  - Prompt especializado (usar prompts j√° existentes)
  - Acesso √†s ferramentas RAG
  - L√≥gica de racioc√≠nio espec√≠fica da perspectiva
  - Capacidade de pedir mais informa√ß√µes
- Integra√ß√£o com LangChain/LangGraph

**Arquivos**:

- `src/agents/financial_agent.py` (novo)
- `src/agents/customer_agent.py` (novo)
- `src/agents/process_agent.py` (novo)
- `src/agents/learning_agent.py` (novo)
- `src/agents/base_agent.py` (novo - classe base comum)
- `tests/test_agents.py` (novo)

**Tempo estimado**: 3 dias (1 agente por dia + base)

---

#### 1.7 Judge Agent (LLM as Judge) ‚úÖ CONCLU√çDO

**Objetivo**: Agente que valida e julga respostas dos especialistas

**A√ß√µes**:

- Criar `src/agents/judge_agent.py`
- Implementar valida√ß√£o de:
  - Completude da resposta
  - Relev√¢ncia para a query
  - Coer√™ncia entre perspectivas
  - Detec√ß√£o de alucina√ß√µes
- Usar prompt judge j√° existente
- Score de confian√ßa (0-1)
- Sugest√µes de melhorias

**Arquivos**:

- `src/agents/judge_agent.py` (novo)
- `tests/test_judge_agent.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.8 Orchestrator ‚úÖ CONCLU√çDO

**Objetivo**: Orquestrador que coordena os 4 especialistas + judge

**A√ß√µes**:

- Criar `src/agents/orchestrator.py`
- L√≥gica de orquestra√ß√£o:
  1. Recebe query do usu√°rio
  2. Decide quais perspectivas BSC s√£o relevantes
  3. Dispara agentes relevantes em paralelo
  4. Agrega respostas
  5. Envia para Judge validar
  6. Consolida resposta final
- Usar prompt orchestrator j√° existente
- Tratamento de conflitos entre agentes
- Logging detalhado do fluxo

**Arquivos**:

- `src/agents/orchestrator.py` (novo)
- `tests/test_orchestrator.py` (novo)

**Tempo estimado**: 2 dias

---

### üîó FASE 1C - Orquestra√ß√£o e Interface (Semana 3-4)

#### 1.9 LangGraph Workflow

**Objetivo**: Grafo de execu√ß√£o com LangGraph para orquestra√ß√£o

**A√ß√µes**:

- Criar `src/graph/workflow.py`
- Definir n√≥s do grafo:
  - `start` ‚Üí `analyze_query` ‚Üí `route_agents` ‚Üí `execute_agents` ‚Üí `aggregate` ‚Üí `judge` ‚Üí `finalize` ‚Üí `end`
- Implementar estados do grafo
- Suporte a ciclos (se judge reprovar, refinar)
- Visualiza√ß√£o do grafo (opcional)
- Integra√ß√£o com Orchestrator

**Arquivos**:

- `src/graph/__init__.py` (novo)
- `src/graph/workflow.py` (novo)
- `src/graph/states.py` (novo - defini√ß√£o de estados)
- `tests/test_workflow.py` (novo)

**Tempo estimado**: 2 dias

---

#### 1.10 Dataset BSC de Exemplo

**Objetivo**: Criar dataset de documentos BSC para teste

**A√ß√µes**:

- Coletar/criar 10-20 documentos BSC:
  - Papers acad√™micos sobre BSC
  - Estudos de caso
  - Guias de implementa√ß√£o
  - Exemplos de KPIs por perspectiva
- Organizar em `data/bsc_literature/`
- Criar metadados (autor, ano, perspectiva, etc)
- Documentar fontes

**Arquivos**:

- `data/bsc_literature/*.pdf` (documentos)
- `data/bsc_literature/index.json` (metadados)
- `data/README.md` (documenta√ß√£o)

**Tempo estimado**: 1 dia (coleta) + indexa√ß√£o usando pipeline

---

#### 1.11 Interface Streamlit

**Objetivo**: Interface web simples para interagir com o agente

**A√ß√µes**:

- Criar `app/main.py`
- Componentes:
  - Input de query
  - Visualiza√ß√£o de resposta final
  - Expandible: respostas de cada perspectiva
  - Documentos recuperados (com scores)
  - Avalia√ß√£o do Judge
  - Hist√≥rico de conversa√ß√£o
  - Configura√ß√µes (ex: quais perspectivas ativar)
- Design limpo e responsivo
- Chat-like interface

**Arquivos**:

- `app/__init__.py` (novo)
- `app/main.py` (novo)
- `app/components/` (componentes Streamlit)
- `app/utils.py` (utilit√°rios)

**Tempo estimado**: 2 dias

---

### ‚úÖ FASE 1D - Valida√ß√£o e Testes (Semana 4)

#### 1.12 Testes End-to-End

**Objetivo**: Validar sistema completo funcionando

**A√ß√µes**:

- Criar suite de testes E2E
- Testar fluxo completo:
  1. Indexar documentos
  2. Fazer queries BSC
  3. Validar respostas
- Queries de teste:
  - "Quais s√£o os principais KPIs da perspectiva financeira?"
  - "Como implementar BSC em uma empresa?"
  - "Qual a rela√ß√£o entre satisfa√ß√£o de clientes e lucratividade?"
- Medir m√©tricas:
  - Lat√™ncia P50, P95, P99
  - Qualidade de resposta (manual)
  - Coverage (% de docs relevantes recuperados)

**Arquivos**:

- `tests/integration/test_e2e.py` (novo)
- `tests/integration/test_queries.json` (queries de teste)
- `docs/TESTING_GUIDE.md` (novo)

**Tempo estimado**: 2 dias

---

#### 1.13 Documenta√ß√£o MVP

**Objetivo**: Documentar sistema MVP para uso

**A√ß√µes**:

- Atualizar `README.md` com arquitetura MVP
- Criar `docs/QUICKSTART.md`
- Criar `docs/API_REFERENCE.md`
- Documentar configura√ß√µes `.env`
- Tutorial de uso passo-a-passo
- Exemplos de queries

**Arquivos**:

- `README.md` (atualizar)
- `docs/QUICKSTART.md` (novo)
- `docs/API_REFERENCE.md` (novo)
- `docs/ARCHITECTURE_MVP.md` (novo)

**Tempo estimado**: 1 dia

---

## üéØ FASE 1 - ENTREG√ÅVEIS

Ao final da Fase 1, teremos:

‚úÖ Sistema RAG completo e funcional
‚úÖ 4 agentes especialistas BSC
‚úÖ Orquestra√ß√£o com LangGraph
‚úÖ Interface Streamlit
‚úÖ Dataset BSC indexado
‚úÖ Testes E2E
‚úÖ Documenta√ß√£o completa

**M√©trica de Sucesso**:

- Sistema responde queries BSC com lat√™ncia < 3s
- Respostas cobrem m√∫ltiplas perspectivas relevantes
- Interface funcional e intuitiva
- C√≥digo testado e documentado

---

## FASE 2: FEATURES AVAN√áADAS (4-6 semanas)

> **IMPORTANTE**: Implementar APENAS ap√≥s validar MVP com dados reais e identificar necessidades espec√≠ficas

### üìà FASE 2A - Query Enhancement (Semanas 5-6)

#### 2.1 Query Decomposition

**Quando implementar**: Se queries reais forem muito complexas e retrieval b√°sico falhar

**Objetivo**: Quebrar queries complexas em sub-queries

**A√ß√µes**:

- Criar `src/rag/query_enhancement.py`
- Implementar `QueryDecomposer`
- Prompts especializados para BSC
- Agregar resultados de sub-queries com RRF
- Integrar com Retriever

**Tempo estimado**: 2 dias

---

#### 2.2 HyDE (Hypothetical Document Embeddings)

**Quando implementar**: Se retrieval direto tiver baixo recall

**Objetivo**: Gerar documento hipot√©tico para melhorar busca

**A√ß√µes**:

- Adicionar `HyDERetriever` em query_enhancement.py
- Prompt para documento hipot√©tico
- Pipeline: query ‚Üí doc hipot√©tico ‚Üí embedding ‚Üí search
- Combinar com retrieval tradicional

**Tempo estimado**: 2 dias

---

### üé® FASE 2B - Retrieval Avan√ßado (Semanas 7-8)

#### 2.3 Adaptive Retrieval

**Quando implementar**: Se houver padr√µes claros de tipos de query

**Objetivo**: Ajustar estrat√©gia dinamicamente

**A√ß√µes**:

- Classificador de queries (simples/complexa, factual/conceitual)
- Roteamento inteligente
- Ajuste de pesos h√≠bridos por tipo de query

**Tempo estimado**: 3 dias

---

#### 2.4 Iterative Retrieval

**Quando implementar**: Se respostas frequentemente precisarem de mais contexto

**Objetivo**: Refinar retrieval iterativamente

**A√ß√µes**:

- Loop: retrieve ‚Üí generate ‚Üí avaliar ‚Üí retrieve novamente
- Limite de 3 itera√ß√µes
- Crit√©rios de parada

**Tempo estimado**: 3 dias

---

#### 2.5 Melhorias no Re-ranking

**Objetivo**: Otimizar qualidade de re-ranking

**A√ß√µes**:

- Diversity re-ranking (evitar docs similares)
- Temporal re-ranking (priorizar recentes quando relevante)
- Cross-encoder local como fallback
- Ensemble de re-rankers

**Tempo estimado**: 2 dias

---

### üöÄ FASE 2C - Otimiza√ß√µes (Semanas 9-10)

#### 2.6 Fine-tuning de Embeddings (Opcional)

**Quando implementar**: Se houver dataset suficiente de (query, doc relevante) do dom√≠nio BSC

**Objetivo**: Embeddings especializados para BSC

**A√ß√µes**:

- Coletar dataset de pares
- Fine-tune com Sentence-Transformers
- Validar melhorias
- Implementar fallback

**Tempo estimado**: 1 semana

---

#### 2.7 Avalia√ß√£o de RAPTOR (Opcional)

**Quando implementar**: Se documentos BSC forem muito longos e estruturados

**Objetivo**: Retrieval hier√°rquico multi-n√≠vel

**A√ß√µes**:

- Estudar casos de uso
- POC com documentos BSC
- Implementar se ROI positivo

**Tempo estimado**: 3-5 dias (avalia√ß√£o) ou 2 semanas (implementa√ß√£o completa)

---

#### 2.8 Avalia√ß√£o de Graph RAG (Opcional)

**Quando implementar**: Se rela√ß√µes entre conceitos BSC forem cr√≠ticas

**Objetivo**: Knowledge graph para rela√ß√µes BSC

**A√ß√µes**:

- Avaliar benef√≠cios para BSC
- Extra√ß√£o de entidades e rela√ß√µes
- Neo4j integration
- Hybrid retrieval: vector + graph

**Tempo estimado**: 3-5 dias (avalia√ß√£o) ou 2-3 semanas (implementa√ß√£o completa)

---

## üìä M√©tricas de Sucesso

### Fase 1 (MVP)

- ‚úÖ Sistema funciona end-to-end
- ‚úÖ Lat√™ncia < 3s (P95)
- ‚úÖ Respostas cobrem perspectivas relevantes
- ‚úÖ Interface utiliz√°vel

### Fase 2 (Otimizado)

- üìà Recall@10: +30-40% vs MVP
- üìà Precision@5: +25-35% vs MVP
- üìà Lat√™ncia P95: < 2s
- üìà Redu√ß√£o de Alucina√ß√µes: 40-50%
- üìà Satisfa√ß√£o de Usu√°rio: > 80%

---

## üéØ Pr√≥ximos Passos Imediatos

1. ‚úÖ Revisar e aprovar plano revisado
2. ‚úÖ Setup completo do ambiente (Fase 0B)
3. ‚úÖ Completar Pipeline RAG (Fase 1A: 1.1 ‚Üí 1.4)
4. ‚úÖ Implementar Sistema Multi-Agente (Fase 1B: 1.5 ‚Üí 1.8)
5. ‚è≥ **AGORA**: Criar Interface e Dataset (Fase 1C: 1.9 ‚Üí 1.11)
   - 1.9 LangGraph Workflow
   - 1.10 Dataset BSC de Exemplo
   - 1.11 Interface Streamlit
6. ‚è≥ Validar MVP completo (Fase 1D: 1.12 ‚Üí 1.13)
7. ‚è≥ **DEPOIS**: Decidir features Fase 2 baseado em resultados

---

## ‚úÖ To-dos Atualizados

### Fase 0B - Setup de Ambiente ‚úÖ

- [x] 0.4.1 Criar ambiente virtual Python
- [x] 0.4.2 Instalar todas as depend√™ncias
- [x] 0.4.3 Configurar Docker Compose e iniciar containers
- [x] 0.4.4 Criar arquivo .env com templates
- [x] 0.4.5 Criar scripts de automa√ß√£o (setup.ps1, validate_setup.py)
- [x] 0.4.6 Criar documenta√ß√£o de setup (SETUP.md, PROGRESS.md)
- [x] 0.4.7 Criar estrutura de diret√≥rios

### Fase 1A - Pipeline RAG (Semana 1) ‚úÖ

- [x] 1.1 Implementar Embeddings OpenAI
- [x] 1.2 Implementar Retriever com Hybrid Search
- [x] 1.3 Implementar Re-ranker Cohere
- [x] 1.4 Criar Pipeline de Ingest√£o

### Fase 1B - Multi-Agente (Semanas 2-3) ‚úÖ

- [x] 1.5 Criar Ferramentas RAG para Agentes
- [x] 1.6 Implementar 4 Agentes Especialistas BSC
- [x] 1.7 Implementar Judge Agent
- [x] 1.8 Implementar Orchestrator

### Fase 1C - Orquestra√ß√£o e Interface (Semanas 3-4)

- [ ] 1.9 Criar LangGraph Workflow
- [ ] 1.10 Criar Dataset BSC de Exemplo
- [ ] 1.11 Implementar Interface Streamlit

### Fase 1D - Valida√ß√£o (Semana 4)

- [ ] 1.12 Criar Testes End-to-End
- [ ] 1.13 Documentar MVP

### Fase 2 - Features Avan√ßadas (AP√ìS validar MVP)

- [ ] 2.1 Implementar Query Decomposition (se necess√°rio)
- [ ] 2.2 Implementar HyDE (se necess√°rio)
- [ ] 2.3 Implementar Adaptive Retrieval (se necess√°rio)
- [ ] 2.4 Implementar Iterative Retrieval (se necess√°rio)
- [ ] 2.5 Melhorar Re-ranking (se necess√°rio)
- [ ] 2.6 Fine-tune Embeddings (opcional)
- [ ] 2.7 Avaliar RAPTOR (opcional)
- [ ] 2.8 Avaliar Graph RAG (opcional)

---

## üìù Notas Importantes

**Por que MVP-First?**

1. ‚úÖ Sistema funcional rapidamente (3-4 semanas vs 6 meses)
2. ‚úÖ Valida arquitetura com dados reais cedo
3. ‚úÖ Features avan√ßadas baseadas em necessidade real (n√£o especula√ß√£o)
4. ‚úÖ Mais √°gil e menos risco de over-engineering
5. ‚úÖ Usu√°rio pode come√ßar a usar e dar feedback

**O que mudou do plano original?**

- Foco em completar pipeline b√°sico PRIMEIRO
- Sistema multi-agente ANTES de features avan√ßadas
- Valida√ß√£o com dados reais ANTES de otimizar
- Features avan√ßadas movidas para Fase 2 (ap√≥s valida√ß√£o)

**Componentes j√° implementados que ser√£o usados**:

- ‚úÖ Vector Store moderno (Qdrant/Weaviate)
- ‚úÖ Contextual Retrieval (Anthropic)
- ‚úÖ Chunking sem√¢ntico
- ‚úÖ Prompts especializados BSC

---

**√öltima atualiza√ß√£o**: 2025-10-09
**Status**: Fase 1A e 1B COMPLETAS ‚úÖ | Fase 1C EM ANDAMENTO ‚è≥
**Progresso MVP**: ~75% (8/13 tarefas conclu√≠das)
