<!-- 2005d8aa-1b1e-4371-b931-540c026d8825 2956b390-5d29-4fa5-8a7d-98638a32730f -->
# Plano de Desenvolvimento - Agente BSC RAG 2025 (MVP-First)

## üéØ Vis√£o Geral

**IMPORTANTE**: Este projeto est√° em fase INICIAL (sem dados no database). O plano foi ajustado para abordagem **MVP-First**: criar sistema funcional end-to-end PRIMEIRO, validar com dados reais, DEPOIS adicionar features avan√ßadas.

**Estrat√©gia**:

- **FASE 1 (3-4 semanas)**: MVP completo funcional com arquitetura moderna
- **FASE 2 (4-6 semanas)**: Features avan√ßadas baseadas em necessidade real validada

---

## ‚úÖ J√Å IMPLEMENTADO

### üìÖ Resumo de Progresso Recente (09/10/2025)

**Fase 0B - Setup de Ambiente**: COMPLETA ‚úÖ

- Ambiente Python configurado com todas as depend√™ncias
- Docker Compose rodando (Qdrant, Weaviate, Redis)
- Scripts de automa√ß√£o e valida√ß√£o criados
- Documenta√ß√£o completa de setup

**Fase 1A - Pipeline RAG**: COMPLETA ‚úÖ

- Embeddings OpenAI implementado
- Retriever com Hybrid Search funcional
- Re-ranker Cohere integrado
- Pipeline de ingest√£o completo

**Fase 1B - Sistema Multi-Agente**: COMPLETA ‚úÖ

- 4 Agentes Especialistas BSC implementados
- Judge Agent para valida√ß√£o de respostas
- Orchestrator para coordena√ß√£o
- Ferramentas RAG integradas

**Pr√≥ximo**: Fase 1C - LangGraph Workflow + Interface Streamlit

---

## üéØ **RESUMO EXECUTIVO - Avan√ßos 09-10/10/2025**

### ‚úÖ **Conquistas Principais**

1. **Dataset BSC Completo para MVP** üìö

- 2 livros fundamentais de Kaplan & Norton indexados
- 2.881 chunks contextualizados (+116% vs dia anterior)
- Base de conhecimento robusta pronta para valida√ß√£o

2. **Pipeline de Ingest√£o Otimizado** ‚ö°

- Processamento paralelo (10 workers simult√¢neos)
- Batch upload Qdrant (29 batches, 100 docs cada)
- Cache inteligente (0.4s para reprocessamento)
- API moderna (query_points do Qdrant)

3. **Qualidade de C√≥digo Aprimorada** üîß

- Emojis removidos (encoding UTF-8 Windows)
- Warnings Pydantic v1 suprimidos
- Logs profissionais com marcadores de texto
- Bugs corrigidos (VectorStoreStats)

### üìä **Status Atual do Projeto**

- **Progresso MVP**: 82% (17/20 tarefas)
- **Fase 1A-1B**: ‚úÖ 100% COMPLETAS
- **Fase 1C**: ‚è≥ 40% (Dataset ‚úÖ | Workflow ‚è≥ | Interface ‚è≥)
- **Pr√≥ximo**: LangGraph Workflow ‚Üí Interface Streamlit

---

### üìÖ Otimiza√ß√µes Implementadas (09/10/2025 - Tarde) ‚ö°

**Pipeline de Ingest√£o Otimizado**: COMPLETO ‚úÖ

**Contextual Retrieval com Processamento Paralelo**:

- ‚úÖ ThreadPoolExecutor com 10 workers simult√¢neos (20% do limite Tier 4 Anthropic)
- ‚úÖ Retry logic com exponential backoff para rate limits
- ‚úÖ Progress logging thread-safe (logs a cada 10 chunks ou 5 segundos)
- ‚úÖ Cache otimizado salvando 100% do tempo em re-execu√ß√µes

**Batch Upload para Qdrant**:

- ‚úÖ Sistema de batches (100 docs/batch) resolvendo limite de 32MB do Qdrant
- ‚úÖ Progress tracking por batch com percentual
- ‚úÖ 14 batches processados com sucesso (1332 documentos totais)

**Atualiza√ß√£o para API Moderna do Qdrant**:

- ‚úÖ Migra√ß√£o de `search()` (deprecado) para `query_points()` (API unificada 2025)
- ‚úÖ Sem warnings de deprecation
- ‚úÖ C√≥digo futureproof

**M√©tricas Alcan√ßadas** (atualizado 10/10/2025):

- üìä **2.881 chunks** contextualizados e indexados (2 documentos BSC)
- ‚ö° **0.4 segundos** para processar 2881 chunks (com cache ativo)
- üéØ **Score de retrieval: 0.66-0.67** (boa relev√¢ncia)
- üöÄ **Batch upload: 29 batches** de 100 documentos cada

**Arquivos Otimizados**:

- `src/rag/contextual_chunker.py` - Processamento paralelo + retry logic
- `scripts/build_knowledge_base.py` - Batch upload + progress tracking
- `src/rag/qdrant_vector_store.py` - API moderna query_points()

---

### üìÖ Avan√ßos Implementados (10/10/2025) üöÄ

**Dataset BSC Expandido**: COMPLETO ‚úÖ

- ‚úÖ **2 livros fundamentais de Kaplan & Norton indexados**:
- "The Balanced Scorecard: Translating Strategy into Action" (1996) - 8.978 linhas
- "The Strategy-Focused Organization" (2000) - 11.490 linhas
- ‚úÖ **2.881 chunks contextualizados** (vs 1.332 anterior) - crescimento de 116%
- ‚úÖ **29 batches processados** com sucesso (vs 14 anterior)
- ‚úÖ **Base de conhecimento BSC robusta** para MVP

**Corre√ß√µes T√©cnicas e Qualidade de C√≥digo**:

- ‚úÖ Remo√ß√£o de TODOS os emojis do c√≥digo (seguindo best practice Windows encoding)
- ‚úÖ Logs limpos com marcadores de texto: [OK], [ERRO], [WARN], [STATS], [INFO]
- ‚úÖ Supress√£o de DeprecationWarnings do Pydantic v1 (warnings de depend√™ncias, n√£o afetam funcionamento)
- ‚úÖ Corre√ß√£o de bug VectorStoreStats: `num_docs` ‚Üí `num_documents`
- ‚úÖ C√≥digo mais limpo e profissional, sem problemas de encoding UTF-8 no Windows

**Performance Mantida**:

- ‚ö° Cache funcionando perfeitamente (0.4s para reprocessamento de 2881 chunks)
- ‚ö° Processamento paralelo est√°vel (10 workers simult√¢neos)
- üéØ Score de retrieval consistente: 0.66-0.67

---

### 0.1 Vector Store Moderno ‚úÖ

- Interface `BaseVectorStore` abstrata
- `QdrantVectorStore` (recomendado 2025)
- `WeaviateVectorStore` (alternativa com hybrid search nativo)
- `RedisVectorStore` (legacy/compatibilidade)
- Factory pattern para f√°cil troca
- Docker configurado com Qdrant, Weaviate e Redis
- Benchmark script completo

### 0.2 Contextual Retrieval (Anthropic) ‚úÖ

- `ContextualChunker` com Claude Sonnet 4.5
- Prompt Caching para reduzir custos
- Cache local de contextos
- Redu√ß√£o esperada: 35-49% em falhas de retrieval
- Prompts especializados para BSC

### 0.3 Chunking ‚úÖ

- `SemanticChunker` (respeita limites sem√¢nticos)
- `TableAwareChunker` (preserva tabelas intactas)
- Configura√ß√£o flex√≠vel (chunk_size, overlap)

### 0.4 Setup de Ambiente ‚úÖ

- Ambiente virtual Python criado (`venv/`)
- Todas as depend√™ncias instaladas via `requirements.txt`
- Docker Compose configurado e containers iniciados:
- Qdrant (localhost:6333)
- Weaviate (localhost:8080)
- Redis (localhost:6379)
- Arquivo `.env` criado com templates de configura√ß√£o
- Scripts de automa√ß√£o:
- `setup.ps1` - Setup automatizado completo
- `scripts/validate_setup.py` - Valida√ß√£o de ambiente
- Documenta√ß√£o de setup:
- `SETUP.md` - Guia passo a passo detalhado
- `PROGRESS.md` - Acompanhamento de progresso
- Estrutura de diret√≥rios criada (data/, models/, logs/)
- Mem√≥ria criada: Nunca usar emojis em c√≥digo (ID: 9592459)

---

## FASE 1: MVP FUNCIONAL (3-4 semanas)

### üì¶ FASE 1A - Pipeline RAG Completo (Semana 1)

#### 1.1 Implementar Embeddings ‚úÖ CONCLU√çDO

**Objetivo**: M√≥dulo de embeddings com OpenAI text-embedding-3-large

**A√ß√µes**:

- Criar `src/rag/embeddings.py`
- Implementar `EmbeddingGenerator` com OpenAI
- Suporte a batch processing para performance
- Cache opcional de embeddings
- Tratamento de rate limiting
- Integra√ß√£o com settings

**Arquivos**:

- `src/rag/embeddings.py` (novo)
- `tests/test_embeddings.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.2 Implementar Retriever com Hybrid Search ‚úÖ CONCLU√çDO

**Objetivo**: Retriever que usa vector store com hybrid search (70% sem√¢ntica + 30% BM25)

**A√ß√µes**:

- Criar `src/rag/retriever.py`
- Implementar `HybridRetriever`
- Integrar com vector store (via factory)
- Suporte a filtros de metadados
- Implementar RRF (Reciprocal Rank Fusion)
- Logging detalhado de retrieval
- M√©tricas de performance

**Arquivos**:

- `src/rag/retriever.py` (novo ou atualizar existente)
- `tests/test_retriever.py` (novo)

**Tempo estimado**: 2 dias

---

#### 1.3 Implementar Re-ranker ‚úÖ CONCLU√çDO

**Objetivo**: Re-ranking com Cohere Rerank Multilingual v3.0

**A√ß√µes**:

- Criar/atualizar `src/rag/reranker.py`
- Implementar `CohereReranker`
- Fallback para scoring local se API falhar
- Integra√ß√£o com retriever
- Configura√ß√£o de top_n
- Cache de re-rankings

**Arquivos**:

- `src/rag/reranker.py` (novo ou atualizar)
- `tests/test_reranker.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.4 Pipeline de Ingest√£o ‚úÖ CONCLU√çDO + OTIMIZADO ‚ö°

**Objetivo**: Script para indexar documentos BSC no vector store

**A√ß√µes**:

- ‚úÖ Criar/atualizar `scripts/build_knowledge_base.py`
- ‚úÖ Integrar: Chunking ‚Üí Contextual Retrieval ‚Üí Embeddings ‚Üí Vector Store
- ‚úÖ Suporte a m√∫ltiplos formatos (PDF, DOCX, TXT, MD)
- ‚úÖ Progress bar e logging detalhado
- ‚úÖ Estat√≠sticas de ingest√£o
- ‚úÖ Configura√ß√£o via CLI args

**Otimiza√ß√µes Implementadas (09/10/2025)**:

- ‚ö° **Processamento Paralelo**: 10 workers simult√¢neos no Contextual Chunker (20% tier 4 Anthropic)
- ‚ö° **Retry Logic**: Exponential backoff para rate limits da API Anthropic
- ‚ö° **Progress Logging**: Thread-safe, logs a cada 10 chunks ou 5 segundos
- ‚ö° **Batch Upload**: 100 documentos por batch para Qdrant (resolveu limite 32MB)
- ‚ö° **Cache Otimizado**: Re-execu√ß√µes processam 1332 chunks em 0.4s
- ‚ö° **API Moderna**: Migra√ß√£o de `search()` para `query_points()`

**M√©tricas Alcan√ßadas**:

- üìä 1332 chunks indexados do documento BSC principal
- ‚ö° 0.4s para processar chunks com cache ativo
- üéØ Score de retrieval: 0.66-0.67 (boa relev√¢ncia)
- üöÄ 3.8s para upload de 1332 docs em 14 batches

**Arquivos**:

- `scripts/build_knowledge_base.py` ‚úÖ (otimizado)
- `src/rag/contextual_chunker.py` ‚úÖ (processamento paralelo)
- `src/rag/qdrant_vector_store.py` ‚úÖ (API moderna)

**Tempo estimado**: 2 dias (implementa√ß√£o) + 1 dia (otimiza√ß√µes)

---

### ü§ñ FASE 1B - Sistema Multi-Agente (Semana 2-3)

#### 1.5 Ferramentas RAG para Agentes ‚úÖ CONCLU√çDO

**Objetivo**: Ferramentas que agentes usar√£o para buscar informa√ß√µes

**A√ß√µes**:

- Criar `src/tools/rag_tools.py`
- Implementar `SearchTool` (busca h√≠brida)
- Implementar `DetailedSearchTool` (busca com contexto expandido)
- Implementar `FilteredSearchTool` (busca com filtros)
- Integra√ß√£o com Retriever + Re-ranker
- Formata√ß√£o de resultados para agentes

**Arquivos**:

- `src/tools/__init__.py` (atualizar)
- `src/tools/rag_tools.py` (novo)
- `tests/test_rag_tools.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.6 Agentes Especialistas BSC (4 agentes) ‚úÖ CONCLU√çDO

**Objetivo**: Criar os 4 agentes especialistas (Financeira, Clientes, Processos, Aprendizado)

**A√ß√µes**:

- Criar `src/agents/financial_agent.py` - Perspectiva Financeira
- Criar `src/agents/customer_agent.py` - Perspectiva de Clientes
- Criar `src/agents/process_agent.py` - Perspectiva de Processos Internos
- Criar `src/agents/learning_agent.py` - Perspectiva de Aprendizado e Crescimento
- Cada agente com:
- Prompt especializado (usar prompts j√° existentes)
- Acesso √†s ferramentas RAG
- L√≥gica de racioc√≠nio espec√≠fica da perspectiva
- Capacidade de pedir mais informa√ß√µes
- Integra√ß√£o com LangChain/LangGraph

**Arquivos**:

- `src/agents/financial_agent.py` (novo)
- `src/agents/customer_agent.py` (novo)
- `src/agents/process_agent.py` (novo)
- `src/agents/learning_agent.py` (novo)
- `src/agents/base_agent.py` (novo - classe base comum)
- `tests/test_agents.py` (novo)

**Tempo estimado**: 3 dias (1 agente por dia + base)

---

#### 1.7 Judge Agent (LLM as Judge) ‚úÖ CONCLU√çDO

**Objetivo**: Agente que valida e julga respostas dos especialistas

**A√ß√µes**:

- Criar `src/agents/judge_agent.py`
- Implementar valida√ß√£o de:
- Completude da resposta
- Relev√¢ncia para a query
- Coer√™ncia entre perspectivas
- Detec√ß√£o de alucina√ß√µes
- Usar prompt judge j√° existente
- Score de confian√ßa (0-1)
- Sugest√µes de melhorias

**Arquivos**:

- `src/agents/judge_agent.py` (novo)
- `tests/test_judge_agent.py` (novo)

**Tempo estimado**: 1 dia

---

#### 1.8 Orchestrator ‚úÖ CONCLU√çDO

**Objetivo**: Orquestrador que coordena os 4 especialistas + judge

**A√ß√µes**:

- Criar `src/agents/orchestrator.py`
- L√≥gica de orquestra√ß√£o:

1. Recebe query do usu√°rio
2. Decide quais perspectivas BSC s√£o relevantes
3. Dispara agentes relevantes em paralelo
4. Agrega respostas
5. Envia para Judge validar
6. Consolida resposta final

- Usar prompt orchestrator j√° existente
- Tratamento de conflitos entre agentes
- Logging detalhado do fluxo

**Arquivos**:

- `src/agents/orchestrator.py` (novo)
- `tests/test_orchestrator.py` (novo)

**Tempo estimado**: 2 dias

---

### üîó FASE 1C - Orquestra√ß√£o e Interface (Semana 3-4)

#### 1.9 LangGraph Workflow

**Objetivo**: Grafo de execu√ß√£o com LangGraph para orquestra√ß√£o

**A√ß√µes**:

- Criar `src/graph/workflow.py`
- Definir n√≥s do grafo:
- `start` ‚Üí `analyze_query` ‚Üí `route_agents` ‚Üí `execute_agents` ‚Üí `aggregate` ‚Üí `judge` ‚Üí `finalize` ‚Üí `end`
- Implementar estados do grafo
- Suporte a ciclos (se judge reprovar, refinar)
- Visualiza√ß√£o do grafo (opcional)
- Integra√ß√£o com Orchestrator

**Arquivos**:

- `src/graph/__init__.py` (novo)
- `src/graph/workflow.py` (novo)
- `src/graph/states.py` (novo - defini√ß√£o de estados)
- `tests/test_workflow.py` (novo)

**Tempo estimado**: 2 dias

---

#### 1.10 Dataset BSC de Exemplo ‚úÖ PARCIALMENTE CONCLU√çDO (Atualizado 10/10/2025)

**Objetivo**: Criar dataset de documentos BSC para teste

**Status Atual**:

- ‚úÖ **2 livros fundamentais de Kaplan & Norton indexados**:
- "The Balanced Scorecard: Translating Strategy into Action" (1996)
- "The Strategy-Focused Organization" (2000)
- ‚úÖ **2.881 chunks contextualizados** e prontos para uso
- ‚úÖ **Base robusta suficiente para MVP** - permite validar sistema completo
- ‚è∏Ô∏è **Expans√£o futura opcional**: Pode adicionar casos de uso, estudos espec√≠ficos se necess√°rio ap√≥s MVP

**A√ß√µes Completadas**:

- ‚úÖ Coletar literatura fundamental BSC (2 livros principais de Kaplan & Norton)
- ‚úÖ Organizar em `data/bsc_literature/`
- ‚úÖ Processar e indexar com pipeline completo (Contextual Retrieval + Embeddings + Qdrant)

**A√ß√µes Futuras (Opcional)**:

- Adicionar estudos de caso empresariais
- Guias de implementa√ß√£o pr√°ticos
- Exemplos de KPIs por perspectiva
- Criar metadados estruturados (autor, ano, perspectiva)
- Documentar fontes em `data/README.md`

**Arquivos**:

- ‚úÖ `data/bsc_literature/*.md` (2 documentos markdown)
- ‚è≥ `data/bsc_literature/index.json` (metadados) - futuro
- ‚è≥ `data/README.md` (documenta√ß√£o) - futuro

**Tempo estimado**: ‚úÖ COMPLETO para MVP (2 livros suficientes) | +1 dia opcional para expans√£o futura

---

#### 1.11 Interface Streamlit

**Objetivo**: Interface web simples para interagir com o agente

**A√ß√µes**:

- Criar `app/main.py`
- Componentes:
- Input de query
- Visualiza√ß√£o de resposta final
- Expandible: respostas de cada perspectiva
- Documentos recuperados (com scores)
- Avalia√ß√£o do Judge
- Hist√≥rico de conversa√ß√£o
- Configura√ß√µes (ex: quais perspectivas ativar)
- Design limpo e responsivo
- Chat-like interface

**Arquivos**:

- `app/__init__.py` (novo)
- `app/main.py` (novo)
- `app/components/` (componentes Streamlit)
- `app/utils.py` (utilit√°rios)

**Tempo estimado**: 2 dias

---

### ‚úÖ FASE 1D - Valida√ß√£o e Testes (Semana 4)

#### 1.12 Testes End-to-End

**Objetivo**: Validar sistema completo funcionando

**A√ß√µes**:

- Criar suite de testes E2E
- Testar fluxo completo:

1. Indexar documentos
2. Fazer queries BSC
3. Validar respostas

- Queries de teste:
- "Quais s√£o os principais KPIs da perspectiva financeira?"
- "Como implementar BSC em uma empresa?"
- "Qual a rela√ß√£o entre satisfa√ß√£o de clientes e lucratividade?"
- Medir m√©tricas:
- Lat√™ncia P50, P95, P99
- Qualidade de resposta (manual)
- Coverage (% de docs relevantes recuperados)

**Arquivos**:

- `tests/integration/test_e2e.py` (novo)
- `tests/integration/test_queries.json` (queries de teste)
- `docs/TESTING_GUIDE.md` (novo)

**Tempo estimado**: 2 dias

---

#### 1.13 Documenta√ß√£o MVP

**Objetivo**: Documentar sistema MVP para uso

**A√ß√µes**:

- Atualizar `README.md` com arquitetura MVP
- Criar `docs/QUICKSTART.md`
- Criar `docs/API_REFERENCE.md`
- Documentar configura√ß√µes `.env`
- Tutorial de uso passo-a-passo
- Exemplos de queries

**Arquivos**:

- `README.md` (atualizar)
- `docs/QUICKSTART.md` (novo)
- `docs/API_REFERENCE.md` (novo)
- `docs/ARCHITECTURE_MVP.md` (novo)

**Tempo estimado**: 1 dia

---

## üéØ FASE 1 - ENTREG√ÅVEIS

Ao final da Fase 1, teremos:

‚úÖ Sistema RAG completo e funcional
‚úÖ 4 agentes especialistas BSC
‚úÖ Orquestra√ß√£o com LangGraph
‚úÖ Interface Streamlit
‚úÖ Dataset BSC indexado
‚úÖ Testes E2E
‚úÖ Documenta√ß√£o completa

**M√©trica de Sucesso**:

- Sistema responde queries BSC com lat√™ncia < 3s
- Respostas cobrem m√∫ltiplas perspectivas relevantes
- Interface funcional e intuitiva
- C√≥digo testado e documentado

---

## FASE 2: FEATURES AVAN√áADAS (4-6 semanas)

> **IMPORTANTE**: Implementar APENAS ap√≥s validar MVP com dados reais e identificar necessidades espec√≠ficas

### üìà FASE 2A - Query Enhancement (Semanas 5-6)

#### 2.1 Query Decomposition

**Quando implementar**: Se queries reais forem muito complexas e retrieval b√°sico falhar

**Objetivo**: Quebrar queries complexas em sub-queries

**A√ß√µes**:

- Criar `src/rag/query_enhancement.py`
- Implementar `QueryDecomposer`
- Prompts especializados para BSC
- Agregar resultados de sub-queries com RRF
- Integrar com Retriever

**Tempo estimado**: 2 dias

---

#### 2.2 HyDE (Hypothetical Document Embeddings)

**Quando implementar**: Se retrieval direto tiver baixo recall

**Objetivo**: Gerar documento hipot√©tico para melhorar busca

**A√ß√µes**:

- Adicionar `HyDERetriever` em query_enhancement.py
- Prompt para documento hipot√©tico
- Pipeline: query ‚Üí doc hipot√©tico ‚Üí embedding ‚Üí search
- Combinar com retrieval tradicional

**Tempo estimado**: 2 dias

---

### üé® FASE 2B - Retrieval Avan√ßado (Semanas 7-8)

#### 2.3 Adaptive Retrieval

**Quando implementar**: Se houver padr√µes claros de tipos de query

**Objetivo**: Ajustar estrat√©gia dinamicamente

**A√ß√µes**:

- Classificador de queries (simples/complexa, factual/conceitual)
- Roteamento inteligente
- Ajuste de pesos h√≠bridos por tipo de query

**Tempo estimado**: 3 dias

---

#### 2.4 Iterative Retrieval

**Quando implementar**: Se respostas frequentemente precisarem de mais contexto

**Objetivo**: Refinar retrieval iterativamente

**A√ß√µes**:

- Loop: retrieve ‚Üí generate ‚Üí avaliar ‚Üí retrieve novamente
- Limite de 3 itera√ß√µes
- Crit√©rios de parada

**Tempo estimado**: 3 dias

---

#### 2.5 Melhorias no Re-ranking

**Objetivo**: Otimizar qualidade de re-ranking

**A√ß√µes**:

- Diversity re-ranking (evitar docs similares)
- Temporal re-ranking (priorizar recentes quando relevante)
- Cross-encoder local como fallback
- Ensemble de re-rankers

**Tempo estimado**: 2 dias

---

### üöÄ FASE 2C - Otimiza√ß√µes (Semanas 9-10)

#### 2.6 Fine-tuning de Embeddings (Opcional)

**Quando implementar**: Se houver dataset suficiente de (query, doc relevante) do dom√≠nio BSC

**Objetivo**: Embeddings especializados para BSC

**A√ß√µes**:

- Coletar dataset de pares
- Fine-tune com Sentence-Transformers
- Validar melhorias
- Implementar fallback

**Tempo estimado**: 1 semana

---

#### 2.7 Avalia√ß√£o de RAPTOR (Opcional)

**Quando implementar**: Se documentos BSC forem muito longos e estruturados

**Objetivo**: Retrieval hier√°rquico multi-n√≠vel

**A√ß√µes**:

- Estudar casos de uso
- POC com documentos BSC
- Implementar se ROI positivo

**Tempo estimado**: 3-5 dias (avalia√ß√£o) ou 2 semanas (implementa√ß√£o completa)

---

#### 2.8 Avalia√ß√£o de Graph RAG (Opcional)

**Quando implementar**: Se rela√ß√µes entre conceitos BSC forem cr√≠ticas

**Objetivo**: Knowledge graph para rela√ß√µes BSC e racioc√≠nio multi-hop

**Benchmarks e Crit√©rios de Decis√£o**:

**Quando GraphRAG supera Vector RAG** (baseado em pesquisas out/2025):

- Queries envolvem **l√≥gica de neg√≥cio** ou defini√ß√µes de m√©tricas (ex: "como KPI X impacta objetivo Y?")
- Respostas requerem **rela√ß√µes causa-efeito** entre perspectivas BSC
- **Racioc√≠nio multi-hop** necess√°rio (ex: "Aprendizado ‚Üí Processos ‚Üí Clientes ‚Üí Financeira")
- Dom√≠nios **relationship-intensive** com entidades fortemente conectadas
- Benchmarks: +35% precis√£o em queries relacionais (FalkorDB, 2025)

**Casos de Uso BSC Espec√≠ficos**:

- Mapear causa-efeito entre KPIs de diferentes perspectivas
- Responder "quais objetivos de aprendizado impactam a receita?"
- Navega√ß√£o por depend√™ncias: "mostre cadeia de valor do treinamento at√© lucro"
- An√°lise de impacto: "se melhorar satisfa√ß√£o cliente, qual efeito na perspectiva financeira?"
- Valida√ß√£o de mapas estrat√©gicos (consist√™ncia de rela√ß√µes)

**Quando N√ÉO usar GraphRAG**:

- ‚ùå Dataset atual (literatura conceitual BSC) - Vector RAG apropriado
- ‚ùå Apenas busca por similaridade sem√¢ntica
- ‚ùå Sem dados estruturados de BSCs reais com rela√ß√µes expl√≠citas
- ‚ùå ROI negativo (custo de construir knowledge graph > benef√≠cio)

**A√ß√µes**:

- **Fase 1 - Avalia√ß√£o (5-7 dias)**:
- Analisar dataset BSC para identificar entidades e rela√ß√µes
- POC com amostra: extrair entidades (Objetivos, KPIs, Iniciativas, Perspectivas)
- Modelar rela√ß√µes: causa-efeito, pertence-a, impacta, deriva-de
- Benchmark: comparar retrieval GraphRAG vs Vector RAG em queries relacionais
- Decis√£o GO/NO-GO baseada em m√©tricas

- **Fase 2 - Implementa√ß√£o (3-4 semanas se GO)**:
- Extra√ß√£o de entidades e rela√ß√µes (spaCy + LLM-based NER)
- Construir Knowledge Graph com Neo4j
- Implementar Cypher query generation para queries estruturadas
- Hybrid retrieval: Vector RAG (similaridade) + Graph RAG (rela√ß√µes)
- Integra√ß√£o com LangGraph workflow existente
- Re-ranking combinando scores vector + graph

**Stack Tecnol√≥gico**:

- Neo4j (graph database) ou ArangoDB (multi-model)
- LangChain Neo4jGraph integration
- spaCy + GPT-5 para extra√ß√£o de entidades BSC
- Cypher (query language para Neo4j)
- LlamaIndex KnowledgeGraphIndex (alternativa)

**ROI Esperado**:

- ‚úÖ **Alto ROI**: SE m√∫ltiplos BSCs empresariais com rela√ß√µes documentadas
- üü° **M√©dio ROI**: SE queries frequentemente envolvem causa-efeito
- ‚ùå **Baixo ROI**: Dataset atual (literatura conceitual, poucos relacionamentos estruturados)

**Tempo estimado**: 5-7 dias (avalia√ß√£o) ou 3-4 semanas (implementa√ß√£o completa)

---

#### 2.9 Avalia√ß√£o de Multi-modal RAG (Opcional)

**Quando implementar**: Se dataset incluir documentos BSC com elementos visuais relevantes

**Objetivo**: Processar e extrair informa√ß√µes de mapas estrat√©gicos, dashboards e diagramas BSC

**Justificativa para BSC**:

Documentos BSC s√£o **ricos em elementos visuais**:

- **Mapas Estrat√©gicos (Strategy Maps)**: Diagramas de causa-efeito entre objetivos
- **Dashboards BSC**: Gr√°ficos, KPI cards, gauges, sem√°foros de performance
- **Tabelas complexas**: KPIs, metas, iniciativas por perspectiva
- **Fluxogramas de Processos**: Perspectiva de Processos Internos
- **Apresenta√ß√µes executivas**: Slides com infogr√°ficos BSC

**Casos de Uso Concretos**:

1. **Extra√ß√£o de Strategy Maps**:

- Query: "Mostre o mapa estrat√©gico da perspectiva financeira"
- Processar PDF com diagrama e extrair objetivos + rela√ß√µes causa-efeito

2. **An√°lise de Dashboards**:

- Query: "Quais KPIs est√£o em zona vermelha no dashboard?"
- OCR + Vision LLM para extrair valores e status de KPIs

3. **Compara√ß√£o Visual**:

- Query: "Compare o BSC 2024 vs 2025 visualmente"
- Processar dois dashboards e identificar diferen√ßas

4. **Extra√ß√£o de Tabelas Complexas**:

- Tabelas com m√∫ltiplas colunas (KPI, Meta, Atual, Respons√°vel, Status)
- Table understanding com GPT-5 ou Claude Sonnet 4.5

5. **Interpreta√ß√£o de Processos**:

- Fluxogramas da perspectiva de Processos Internos
- Extrair etapas, gargalos, melhorias

**Quando N√ÉO usar Multi-modal RAG**:

- ‚ùå Dataset atual cont√©m apenas texto (markdown, PDFs textuais)
- ‚ùå Elementos visuais s√£o decorativos (n√£o agregam informa√ß√£o cr√≠tica)
- ‚ùå ROI negativo (custo de processamento multimodal > benef√≠cio)
- ‚ùå Queries dos usu√°rios n√£o referenciam elementos visuais

**A√ß√µes**:

- **Fase 1 - Avalia√ß√£o (1 semana)**:
- Audit do dataset: quantificar documentos com elementos visuais
- Identificar tipos de imagens (Strategy Maps, dashboards, tabelas, gr√°ficos)
- POC com 5-10 documentos visuais BSC
- Testar extra√ß√£o com GPT-5 Vision API
- M√©tricas: precis√£o de extra√ß√£o, tempo de processamento, custo
- Decis√£o GO/NO-GO baseada em ROI

- **Fase 2 - Implementa√ß√£o (2-3 semanas se GO)**:
- Integrar Unstructured.io para parsing de PDFs multimodais
- Configurar GPT-5 Vision / Claude Sonnet 4.5 para an√°lise de imagens
- Implementar extra√ß√£o de tabelas com table understanding
- CLIP embeddings para busca h√≠brida texto + imagem
- LangChain MultiModalRetriever integration
- Pipeline: PDF ‚Üí extract images ‚Üí Vision LLM ‚Üí structured data ‚Üí index

- **Fase 3 - Otimiza√ß√£o (+1 semana)**:
- Cache de an√°lise de imagens (evitar reprocessamento)
- Fallback: se Vision LLM falhar, usar OCR tradicional (Tesseract)
- Integra√ß√£o com agentes BSC (cada agente pode consultar imagens)
- Visualiza√ß√£o de fontes visuais na interface Streamlit

**Stack Tecnol√≥gico**:

- **Vision LLMs**: GPT-5 Vision API, Claude Sonnet 4.5, LLaVA (open-source)
- **Document Processing**: Unstructured.io, PyMuPDF (extra√ß√£o de imagens)
- **Table Understanding**: Microsoft Table Transformer, GPT-5
- **OCR Fallback**: Tesseract OCR, Azure Form Recognizer
- **Embeddings**: CLIP (OpenAI) para embeddings multimodais
- **Framework**: LangChain MultiModalRetriever, LlamaIndex ImageReader

**ROI Esperado**:

- ‚úÖ **Alto ROI**: SE 30%+ do dataset cont√©m Strategy Maps ou dashboards cr√≠ticos
- üü° **M√©dio ROI**: SE queries frequentemente referenciam elementos visuais
- üü° **M√©dio ROI**: SE apresenta√ß√µes executivas BSC s√£o fonte prim√°ria
- ‚ùå **Baixo ROI**: Dataset atual (texto puro, sem diagramas BSC relevantes)

**M√©tricas de Sucesso**:

- Precis√£o de extra√ß√£o de KPIs de dashboards: >90%
- Acur√°cia de rela√ß√µes causa-efeito em Strategy Maps: >85%
- Lat√™ncia de processamento multimodal: <10s por imagem
- Custo incremental: <30% vs pipeline text-only
- User satisfaction: +20% em queries visuais

**Tempo estimado**: 1 semana (avalia√ß√£o) ou 2-3 semanas (implementa√ß√£o) + 1 semana (otimiza√ß√£o)

---

## üìä M√©tricas de Sucesso

### Fase 1 (MVP)

- ‚úÖ Sistema funciona end-to-end
- ‚úÖ Lat√™ncia < 3s (P95)
- ‚úÖ Respostas cobrem perspectivas relevantes
- ‚úÖ Interface utiliz√°vel

### Fase 2 (Otimizado)

- üìà Recall@10: +30-40% vs MVP
- üìà Precision@5: +25-35% vs MVP
- üìà Lat√™ncia P95: < 2s
- üìà Redu√ß√£o de Alucina√ß√µes: 40-50%
- üìà Satisfa√ß√£o de Usu√°rio: > 80%

---

## üéØ Pr√≥ximos Passos Imediatos

1. ‚úÖ Revisar e aprovar plano revisado
2. ‚è≥ Iniciar Fase 1A.1: Implementar Embeddings
3. ‚è≥ Completar Pipeline RAG (1A.1 ‚Üí 1A.4)
4. ‚è≥ Implementar Sistema Multi-Agente (1B)
5. ‚è≥ Criar Interface e Dataset (1C)
6. ‚è≥ Validar MVP completo (1D)
7. ‚è≥ **DEPOIS**: Decidir features Fase 2 baseado em resultados

---

## ‚úÖ To-dos Atualizados

### Fase 1A - Pipeline RAG (Semana 1)

- [ ] 1.1 Implementar Embeddings OpenAI
- [ ] 1.2 Implementar Retriever com Hybrid Search
- [ ] 1.3 Implementar Re-ranker Cohere
- [ ] 1.4 Criar Pipeline de Ingest√£o

### Fase 1B - Multi-Agente (Semanas 2-3)

- [ ] 1.5 Criar Ferramentas RAG para Agentes
- [ ] 1.6 Implementar 4 Agentes Especialistas BSC
- [ ] 1.7 Implementar Judge Agent
- [ ] 1.8 Implementar Orchestrator

### Fase 1C - Orquestra√ß√£o e Interface (Semanas 3-4)

- [ ] 1.9 Criar LangGraph Workflow
- [ ] 1.10 Criar Dataset BSC de Exemplo
- [ ] 1.11 Implementar Interface Streamlit

### Fase 1D - Valida√ß√£o (Semana 4)

- [ ] 1.12 Criar Testes End-to-End
- [ ] 1.13 Documentar MVP

### Fase 2 - Features Avan√ßadas (AP√ìS validar MVP)

- [ ] 2.1 Implementar Query Decomposition (se necess√°rio)
- [ ] 2.2 Implementar HyDE (se necess√°rio)
- [ ] 2.3 Implementar Adaptive Retrieval (se necess√°rio)
- [ ] 2.4 Implementar Iterative Retrieval (se necess√°rio)
- [ ] 2.5 Melhorar Re-ranking (se necess√°rio)
- [ ] 2.6 Fine-tune Embeddings (opcional)
- [ ] 2.7 Avaliar RAPTOR (opcional)
- [ ] 2.8 Avaliar Graph RAG (opcional)
- [ ] 2.9 Avaliar Multi-modal RAG (opcional)

---

## üìù Notas Importantes

**Por que MVP-First?**

1. ‚úÖ Sistema funcional rapidamente (3-4 semanas vs 6 meses)
2. ‚úÖ Valida arquitetura com dados reais cedo
3. ‚úÖ Features avan√ßadas baseadas em necessidade real (n√£o especula√ß√£o)
4. ‚úÖ Mais √°gil e menos risco de over-engineering
5. ‚úÖ Usu√°rio pode come√ßar a usar e dar feedback

**O que mudou do plano original?**

- Foco em completar pipeline b√°sico PRIMEIRO
- Sistema multi-agente ANTES de features avan√ßadas
- Valida√ß√£o com dados reais ANTES de otimizar
- Features avan√ßadas movidas para Fase 2 (ap√≥s valida√ß√£o)

**Componentes j√° implementados que ser√£o usados**:

- ‚úÖ Vector Store moderno (Qdrant/Weaviate)
- ‚úÖ Contextual Retrieval (Anthropic)
- ‚úÖ Chunking sem√¢ntico
- ‚úÖ Prompts especializados BSC

---

## üéØ PR√ìXIMAS ETAPAS PRIORIT√ÅRIAS

### ‚ö° IMEDIATO (Pr√≥xima Sess√£o)

1. ‚úÖ ~~**Expandir Dataset BSC**~~ üìö **CONCLU√çDO**

- ‚úÖ 2 livros fundamentais de Kaplan & Norton indexados
- ‚úÖ 2.881 chunks contextualizados
- ‚úÖ Base robusta suficiente para MVP
- **Status**: COMPLETO - pode expandir futuramente se necess√°rio

2. **LangGraph Workflow** üîó (Fase 1C.9) - **PR√ìXIMO PASSO**

- Criar `src/graph/workflow.py`
- Orquestra√ß√£o visual do fluxo multi-agente
- State management e branching condicional
- **Tempo estimado**: 2 dias

3. **Interface Streamlit** üñ•Ô∏è (Fase 1C.11)

- Criar `app/main.py`
- Chat interface web
- Visualiza√ß√£o de perspectivas BSC consultadas
- Display de fontes e scores
- **Tempo estimado**: 2 dias

### üìÖ CURTO PRAZO (Esta Semana)

4. **Testes End-to-End** üß™ (Fase 1D.12)

- Suite completa de testes E2E
- Validar fluxo: query ‚Üí orchestrator ‚Üí synthesis
- M√©tricas de lat√™ncia e qualidade

5. **Documenta√ß√£o Final** üìñ (Fase 1D.13)

- Atualizar README com arquitetura completa
- QUICKSTART.md para onboarding r√°pido
- API Reference dos agentes

---

**√öltima atualiza√ß√£o**: 2025-10-10 (Dataset BSC expandido + Corre√ß√µes t√©cnicas + Logs limpos)
**Status**: Fase 1A e 1B COMPLETAS ‚úÖ | Otimiza√ß√µes ‚úÖ | Dataset BSC ‚úÖ | Fase 1C EM ANDAMENTO ‚è≥
**Progresso MVP**: ~82% (17/20 tarefas conclu√≠das + otimiza√ß√µes cr√≠ticas)
**Dataset**: 2 livros fundamentais indexados (2.881 chunks contextualizados)
**Pr√≥ximo**: LangGraph Workflow ‚Üí Interface Streamlit ‚Üí Testes E2E

### üìã To-dos Consolidados (Atualizado 10/10/2025)

#### ‚úÖ Fase 0 & 1A-1B: CONCLU√çDAS (100%)

- [x] Setup Completo do Ambiente (venv + deps + Docker)
- [x] Implementar m√≥dulo de Embeddings OpenAI
- [x] Implementar Retriever com Hybrid Search
- [x] Implementar Re-ranker Cohere
- [x] Implementar Contextual Retrieval (Anthropic) + Cache + Paraleliza√ß√£o
- [x] Criar Pipeline de Ingest√£o completo + Batch Upload Qdrant
- [x] Avaliar Qdrant vs Weaviate (escolhemos Qdrant)
- [x] Migrar de Redis para Qdrant (com query_points API moderna)
- [x] Criar Ferramentas RAG para Agentes
- [x] Implementar 4 Agentes Especialistas BSC
- [x] Implementar Judge Agent
- [x] Implementar Orchestrator

#### ‚ö° Otimiza√ß√µes Implementadas (09-10/10/2025)

- [x] **Processamento Paralelo no Contextual Chunker** (10 workers, 20% tier 4)
- [x] **Retry Logic com Exponential Backoff** (rate limits Anthropic)
- [x] **Progress Logging Thread-Safe** (visibilidade em tempo real)
- [x] **Batch Upload para Qdrant** (100 docs/batch, resolveu limite 32MB)
- [x] **Migra√ß√£o para API Moderna** (query_points vs search deprecado)
- [x] **Remo√ß√£o de Emojis do C√≥digo** (encoding UTF-8 Windows)
- [x] **Supress√£o de Warnings Pydantic v1** (c√≥digo mais limpo)
- [x] **Corre√ß√£o VectorStoreStats** (num_docs ‚Üí num_documents)

#### ‚è≥ Fase 1C-1D: EM ANDAMENTO (MVP) - 40% completo

- [x] **Expandir Dataset BSC** ‚úÖ (2 livros fundamentais: 2.881 chunks)
- [ ] **Criar LangGraph Workflow** (src/graph/workflow.py) - PR√ìXIMO
- [ ] **Implementar Interface Streamlit** (app/main.py)
- [ ] Criar Testes End-to-End
- [ ] Documentar MVP completo

#### üîÆ Fase 2: RAG Avan√ßado (AP√ìS validar MVP)

- [ ] Implementar Query Decomposition (se necess√°rio)
- [ ] Implementar HyDE (se necess√°rio)
- [ ] Implementar Adaptive Retrieval (se necess√°rio)
- [ ] Implementar Iterative Retrieval (se necess√°rio)
- [ ] Melhorar sistema de re-ranking (se necess√°rio)
- [ ] Testes e valida√ß√£o completa da Fase 2

#### üöÄ Fase 3: Produ√ß√£o (FUTURO)

- [ ] Fine-tune embeddings para dom√≠nio BSC (opcional)
- [ ] Avaliar RAPTOR (opcional)
- [ ] Avaliar Graph RAG (opcional)
- [ ] Avaliar Multi-modal RAG (opcional)
- [ ] Otimiza√ß√µes de performance para produ√ß√£o
- [ ] Documenta√ß√£o final e prepara√ß√£o para deploy 

### To-dos

- [x] Implementar m√≥dulo de Embeddings OpenAI
- [x] Implementar Retriever com Hybrid Search
- [x] Implementar Re-ranker Cohere
- [x] Criar Pipeline de Ingest√£o completo
- [x] Criar Ferramentas RAG para Agentes
- [x] Implementar 4 Agentes Especialistas BSC
- [x] Implementar Judge Agent
- [x] Implementar Orchestrator
- [ ] Criar LangGraph Workflow
- [ ] Criar Dataset BSC de Exemplo
- [ ] Implementar Interface Streamlit
- [ ] Criar Testes End-to-End
- [ ] Documentar MVP completo
- [x] Setup Completo do Ambiente (venv + deps + Docker)
- [x] Implementar m√≥dulo de Embeddings OpenAI
- [x] Implementar Retriever com Hybrid Search
- [x] Implementar Re-ranker Cohere
- [x] Criar Pipeline de Ingest√£o completo
- [x] Criar Ferramentas RAG para Agentes
- [x] Implementar 4 Agentes Especialistas BSC
- [x] Implementar Judge Agent
- [x] Implementar Orchestrator
- [ ] Criar LangGraph Workflow
- [ ] Criar Dataset BSC de Exemplo
- [ ] Implementar Interface Streamlit
- [ ] Criar Testes End-to-End
- [ ] Documentar MVP completo
- [x] Setup Completo do Ambiente (venv + deps + Docker)
- [ ] Avaliar Qdrant vs Weaviate com POC e benchmarks
- [ ] Migrar de Redis para vector DB escolhido
- [ ] Implementar Contextual Retrieval (Anthropic)
- [ ] Implementar Query Decomposition
- [ ] Testes e valida√ß√£o completa da Fase 1
- [ ] Implementar HyDE (Hypothetical Document Embeddings)
- [ ] Implementar Adaptive Retrieval
- [ ] Implementar Iterative Retrieval
- [ ] Melhorar sistema de re-ranking
- [ ] Testes e valida√ß√£o completa da Fase 2
- [ ] Fine-tune embeddings para dom√≠nio BSC
- [ ] Avaliar e decidir sobre implementa√ß√£o de RAPTOR
- [ ] Avaliar e decidir sobre implementa√ß√£o de Graph RAG
- [ ] Otimiza√ß√µes de performance para produ√ß√£o
- [ ] Documenta√ß√£o final e prepara√ß√£o para deploy
- [ ] 