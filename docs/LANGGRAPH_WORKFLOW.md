# LangGraph Workflow - Sistema BSC Multi-Agente

## üìã Vis√£o Geral

O **LangGraph Workflow** √© o componente de orquestra√ß√£o do sistema BSC RAG que coordena a execu√ß√£o de m√∫ltiplos agentes especialistas usando um grafo de estados gerenciado pelo [LangGraph](https://github.com/langchain-ai/langgraph).

### Caracter√≠sticas Principais

- ‚úÖ **Orquestra√ß√£o Visual**: Grafo de estados expl√≠cito e audit√°vel
- ‚úÖ **Refinamento Iterativo**: Loop de melhoria baseado em avalia√ß√£o do Judge
- ‚úÖ **Execu√ß√£o Paralela**: Agentes especialistas executam simultaneamente
- ‚úÖ **State Management**: Estado tipado e validado com Pydantic
- ‚úÖ **Decis√£o Condicional**: Branching baseado em avalia√ß√£o de qualidade
- ‚úÖ **Recupera√ß√£o de Erros**: Fallbacks em cada n√≥

---

## üèóÔ∏è Arquitetura do Grafo

```
START
  ‚Üì
analyze_query
  ‚îÇ Analisa query e determina perspectivas relevantes
  ‚Üì
execute_agents
  ‚îÇ Executa agentes especialistas em paralelo
  ‚Üì
synthesize_response
  ‚îÇ Sintetiza respostas em resposta unificada
  ‚Üì
judge_evaluation
  ‚îÇ Avalia qualidade com Judge Agent
  ‚Üì
decide_next_step (conditional)
  ‚îú‚îÄ [approved] ‚Üí finalize
  ‚îú‚îÄ [needs_refinement] ‚Üí execute_agents (loop)
  ‚îî‚îÄ [default] ‚Üí finalize
       ‚Üì
     END
```

### N√≥s do Grafo

#### 1. `analyze_query`

**Responsabilidade**: Analisar a pergunta do usu√°rio e determinar roteamento

**Input**:

- `query`: Pergunta do usu√°rio
- `session_id`: ID da sess√£o (opcional)

**Output**:

- `relevant_perspectives`: Lista de perspectivas BSC a consultar
- `query_type`: Tipo da query ("general", "specific")
- `complexity`: Complexidade ("simple", "complex")
- `metadata.routing_reasoning`: Justificativa do roteamento

**L√≥gica**:

1. Usa `Orchestrator.route_query()` para determinar agentes
2. Mapeia nomes de agentes para `PerspectiveType` enum
3. Classifica tipo e complexidade da query

---

#### 2. `execute_agents`

**Responsabilidade**: Executar agentes especialistas em paralelo

**Input**:

- `query`: Pergunta do usu√°rio
- `relevant_perspectives`: Perspectivas a consultar
- `metadata.chat_history`: Hist√≥rico de conversa (opcional)

**Output**:

- `agent_responses`: Lista de `AgentResponse` com respostas dos agentes

**L√≥gica**:

1. Mapeia `PerspectiveType` de volta para nomes de agentes
2. Usa `Orchestrator.invoke_agents()` para executar em paralelo
3. Converte respostas para modelo Pydantic `AgentResponse`
4. Extrai fontes e confidence dos `intermediate_steps`

**Nota**: Este n√≥ pode ser executado m√∫ltiplas vezes em caso de refinamento.

---

#### 3. `synthesize_response`

**Responsabilidade**: Sintetizar m√∫ltiplas respostas em uma resposta unificada

**Input**:

- `query`: Pergunta original
- `agent_responses`: Lista de respostas dos agentes

**Output**:

- `aggregated_response`: Resposta sintetizada
- `metadata.synthesis_confidence`: Confian√ßa da s√≠ntese (0-1)
- `metadata.perspectives_covered`: Perspectivas inclu√≠das na s√≠ntese

**L√≥gica**:

1. Formata respostas dos agentes para o Orchestrator
2. Usa `Orchestrator.synthesize_responses()` com LLM
3. Combina insights de m√∫ltiplas perspectivas
4. Mant√©m cita√ß√µes de fontes
5. Calcula confidence score

---

#### 4. `judge_evaluation`

**Responsabilidade**: Avaliar qualidade da resposta sintetizada

**Input**:

- `query`: Pergunta original
- `aggregated_response`: Resposta sintetizada

**Output**:

- `judge_evaluation`: Objeto `JudgeEvaluation` com:
  - `approved`: Boolean (true se aprovado)
  - `score`: Score de qualidade (0-1)
  - `feedback`: Feedback textual
  - `issues`: Lista de problemas encontrados
  - `suggestions`: Lista de sugest√µes de melhoria
- `needs_refinement`: Boolean (true se precisa refinar)

**Crit√©rios de Avalia√ß√£o**:

- ‚úÖ **Aprovado** (`approved=True`): score >= 0.8 e bem fundamentado
- üü° **Precisa Melhoria** (`needs_improvement`): 0.5 <= score < 0.8
- ‚ùå **Rejeitado** (`rejected`): score < 0.5 ou n√£o fundamentado

---

#### 5. `finalize`

**Responsabilidade**: Preparar resposta final para o usu√°rio

**Input**:

- `aggregated_response`: Resposta sintetizada
- `judge_evaluation`: Avalia√ß√£o do Judge
- `refinement_iteration`: N√∫mero de refinamentos realizados

**Output**:

- `final_response`: Resposta final formatada
- `is_complete`: True (marca workflow como completo)
- `metadata.total_refinements`: Total de refinamentos
- `metadata.final_score`: Score final do Judge

**L√≥gica**:

1. Usa `aggregated_response` como base
2. Se reprovado, adiciona aviso de qualidade
3. Marca workflow como completo
4. Registra m√©tricas finais

---

### Edge Condicional: `decide_next_step`

**Responsabilidade**: Decidir pr√≥ximo passo ap√≥s avalia√ß√£o do Judge

**Condi√ß√µes**:

| Condi√ß√£o | A√ß√£o | Pr√≥ximo N√≥ |
|----------|------|------------|
| `judge_evaluation.approved == True` | Finalizar | `finalize` |
| `needs_refinement == True` e `iteration < max` | Refinar | `execute_agents` |
| `iteration >= max_refinement_iterations` | Finalizar (for√ßa) | `finalize` |
| Padr√£o | Finalizar | `finalize` |

**M√°ximo de Refinamentos**: 2 itera√ß√µes (configur√°vel via `BSCState.max_refinement_iterations`)

---

## üíæ Estado do Workflow (`BSCState`)

O estado do workflow √© gerenciado por um modelo Pydantic `BSCState`:

```python
class BSCState(BaseModel):
    # Input
    query: str
    session_id: Optional[str] = None
    
    # An√°lise da query
    relevant_perspectives: List[PerspectiveType] = []
    query_type: Optional[str] = None
    complexity: Optional[str] = None
    
    # Respostas dos agentes
    agent_responses: List[AgentResponse] = []
    
    # Agrega√ß√£o
    aggregated_response: Optional[str] = None
    
    # Valida√ß√£o
    judge_evaluation: Optional[JudgeEvaluation] = None
    
    # Refinamento
    refinement_iteration: int = 0
    max_refinement_iterations: int = 2
    
    # Output final
    final_response: Optional[str] = None
    metadata: Dict[str, Any] = {}
    
    # Controle de fluxo
    needs_refinement: bool = False
    is_complete: bool = False
```

---

## üöÄ Uso B√°sico

### Exemplo 1: Query Simples

```python
from src.graph.workflow import get_workflow

# Obter inst√¢ncia do workflow (singleton)
workflow = get_workflow()

# Executar query
result = workflow.run(
    query="O que √© Balanced Scorecard?",
    session_id="user-123"
)

# Acessar resultado
print(result["final_response"])
print(f"Perspectivas consultadas: {result['perspectives']}")
print(f"Score do Judge: {result['judge_evaluation']['score']}")
```

### Exemplo 2: Query com Hist√≥rico

```python
chat_history = [
    {"role": "user", "content": "O que √© BSC?"},
    {"role": "assistant", "content": "BSC √© uma metodologia..."}
]

result = workflow.run(
    query="Quais s√£o as 4 perspectivas?",
    chat_history=chat_history
)
```

### Exemplo 3: Inspecionar Detalhes

```python
result = workflow.run(query="Como melhorar ROI?")

# Respostas individuais dos agentes
for agent_resp in result["agent_responses"]:
    print(f"Perspectiva: {agent_resp['perspective']}")
    print(f"Confidence: {agent_resp['confidence']}")
    print(f"Resposta: {agent_resp['content'][:100]}...")

# Avalia√ß√£o do Judge
judge = result["judge_evaluation"]
print(f"Aprovado: {judge['approved']}")
print(f"Feedback: {judge['feedback']}")
print(f"Issues: {judge['issues']}")
print(f"Sugest√µes: {judge['suggestions']}")

# M√©tricas
print(f"Refinamentos: {result['refinement_iterations']}")
```

---

## üìä Formato da Resposta

```python
{
    "query": str,                    # Query original
    "final_response": str,           # Resposta final sintetizada
    "perspectives": List[str],       # Perspectivas consultadas
    "agent_responses": [             # Respostas individuais
        {
            "perspective": str,
            "content": str,
            "confidence": float
        }
    ],
    "judge_evaluation": {            # Avalia√ß√£o do Judge
        "approved": bool,
        "score": float,
        "feedback": str,
        "issues": List[str],
        "suggestions": List[str]
    },
    "refinement_iterations": int,    # N√∫mero de refinamentos
    "metadata": dict                 # Metadados adicionais
}
```

---

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# APIs necess√°rias
OPENAI_API_KEY=sk-...          # Para agentes e synthesis
ANTHROPIC_API_KEY=sk-ant-...   # Para contextual retrieval
COHERE_API_KEY=...             # Para re-ranking

# Qdrant (vector store)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=bsc_collection
```

### Par√¢metros Customiz√°veis

No c√≥digo `src/graph/states.py`:

```python
class BSCState(BaseModel):
    max_refinement_iterations: int = 2  # Ajustar m√°ximo de refinamentos
```

No c√≥digo `src/agents/orchestrator.py`:

```python
self.llm = ChatOpenAI(
    model="gpt-4",           # Modelo LLM
    temperature=0.3,         # Criatividade
    max_tokens=2000          # Tamanho da resposta
)
```

---

## üß™ Testes

### Executar Testes Unit√°rios

```bash
# Testes unit√°rios (n√£o requerem APIs)
pytest tests/test_workflow.py -v

# Testes espec√≠ficos
pytest tests/test_workflow.py::TestBSCWorkflow::test_workflow_initialization
```

### Executar Testes de Integra√ß√£o

```bash
# Testes de integra√ß√£o (requerem APIs configuradas + Qdrant rodando)
pytest tests/test_workflow.py::TestBSCWorkflowIntegration -v -s
```

### Executar Exemplo Interativo

```bash
python examples/run_workflow_example.py
```

Op√ß√µes:

1. Executar queries de exemplo
2. Modo interativo (fazer suas pr√≥prias perguntas)
3. Visualizar estrutura do grafo

---

## üìà Performance

### Lat√™ncia Esperada

| Cen√°rio | Lat√™ncia (P95) | Descri√ß√£o |
|---------|----------------|-----------|
| Query simples (1 agente) | ~3-5s | Execu√ß√£o + synthesis + judge |
| Query complexa (4 agentes) | ~5-8s | Execu√ß√£o paralela + synthesis + judge |
| Com refinamento (1 itera√ß√£o) | +3-5s | Re-execu√ß√£o dos agentes |

**Fatores que impactam lat√™ncia**:

- N√∫mero de agentes acionados (1-4)
- Tamanho do knowledge base (retrieval)
- Lat√™ncia das APIs (OpenAI, Anthropic, Cohere)
- Refinamentos iterativos (0-2)

### Otimiza√ß√µes

‚úÖ **J√° Implementadas**:

- Execu√ß√£o paralela de agentes
- Cache de embeddings
- Batch upload para Qdrant
- Contextual caching (Anthropic)

üîÆ **Poss√≠veis Melhorias Futuras**:

- Cache de s√≠nteses similares
- Streaming de respostas (LLM streaming)
- Pr√©-computa√ß√£o de queries frequentes

---

## üêõ Troubleshooting

### Erro: "No linter errors found"

**Problema**: Imports falhando

**Solu√ß√£o**:

```bash
# Adicionar src ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/caminho/para/projeto/src"

# Ou no Windows
set PYTHONPATH=%PYTHONPATH%;C:\caminho\para\projeto\src
```

### Erro: "Qdrant connection refused"

**Problema**: Qdrant n√£o est√° rodando

**Solu√ß√£o**:

```bash
# Iniciar Qdrant com Docker
docker-compose up -d qdrant

# Verificar status
docker ps | grep qdrant
```

### Erro: "Rate limit exceeded"

**Problema**: Muitas chamadas para API

**Solu√ß√£o**:

- Aguardar alguns minutos
- Verificar tier da API (Anthropic, OpenAI, Cohere)
- Reduzir `max_refinement_iterations` para 1

### Aviso: "Judge reprovou mas finalizou"

**Problema**: Resposta n√£o atingiu qualidade ideal

**An√°lise**:

- Verificar `judge_evaluation.feedback` para entender o motivo
- Verificar `judge_evaluation.issues` para problemas espec√≠ficos
- Considerar melhorar prompts dos agentes
- Considerar expandir knowledge base

---

## üìö Refer√™ncias

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [Pydantic Models](https://docs.pydantic.dev/)
- [Balanced Scorecard (Kaplan & Norton)](https://www.balancedscorecard.org/)

---

## üîÑ Pr√≥ximos Passos

### MVP (Conclu√≠do)

- [x] Implementar grafo LangGraph
- [x] Integrar com agentes existentes
- [x] Adicionar loop de refinamento
- [x] Criar testes unit√°rios e de integra√ß√£o
- [x] Documentar workflow

### Melhorias Futuras

- [ ] Visualiza√ß√£o do grafo com Mermaid/Graphviz
- [ ] Streaming de respostas em tempo real
- [ ] Cache de s√≠nteses para queries similares
- [ ] M√©tricas detalhadas de performance
- [ ] Dashboard de observabilidade (traces)
- [ ] Suporte a sess√µes multi-turn completas

---

**√öltima Atualiza√ß√£o**: 2025-10-10  
**Status**: MVP Completo ‚úÖ  
**Vers√£o**: 1.0
