# FASE 4.4 - Advanced Analytics Dashboard: Design T√©cnico

**Data In√≠cio:** 2025-11-19  
**Vers√£o:** 1.0  
**Status:** üìê DESIGN APROVADO - Pronto para implementa√ß√£o

---

## üéØ Objetivos

Implementar dashboard de analytics enterprise-ready para monitoramento da API REST (FASE 4.3):

1. **Coleta Autom√°tica de M√©tricas** - Middleware FastAPI que intercepta todos os requests
2. **Armazenamento Time-Series** - Redis para m√©tricas hist√≥ricas (√∫ltimos 30 dias)
3. **Dashboard Interativo** - UI Streamlit com gr√°ficos e KPIs em tempo real
4. **API de M√©tricas** - Endpoints REST para acesso program√°tico aos dados
5. **Alertas e Notifica√ß√µes** - Thresholds configur√°veis para m√©tricas cr√≠ticas

**Estimativa:** 4-5h (1 sess√£o)  
**Depend√™ncias:** FASE 4.3 completa (Integration APIs) ‚úÖ

---

## üìä Stack Tecnol√≥gico (Decis√µes Fundamentadas - Brightdata Nov 2025)

### **1. Redis Time-Series para M√©tricas**

**Escolha:** Redis Hash Sets com timestamps como keys  
**Alternativas consideradas:** Prometheus, InfluxDB, TimescaleDB

**Raz√µes:**
- ‚úÖ **J√° temos Redis:** Reutilizar infraestrutura existente (rate limiting FASE 4.3)
- ‚úÖ **Performance:** Redis √© extremamente r√°pido para writes/reads (<1ms lat√™ncia)
- ‚úÖ **Simplicidade:** Sem depend√™ncias externas adicionais
- ‚úÖ **Suficiente para MVP:** <1M m√©tricas/dia (Redis suporta milh√µes)

**Estrutura Redis proposta:**
```
# Requests por endpoint (minuto)
metrics:requests:/api/v1/clients:2025-11-19:10:00 ‚Üí {"count": 45, "errors": 2}

# Lat√™ncia por endpoint (minuto)
metrics:latency:/api/v1/clients:2025-11-19:10:00 ‚Üí {"p50": 120, "p95": 250, "p99": 500}

# Uso por API key (hora)
metrics:consumer:bsc_test_engelar:2025-11-19:10 ‚Üí {"requests": 150, "endpoints": 5}

# Rate limit hits (dia)
metrics:ratelimit:2025-11-19 ‚Üí {"hits": 12, "endpoints": ["/api/v1/clients"]}
```

**Fontes:**
- Redis.io (2025): "Time-Series Data Structures Best Practices"
- Medium (Aug 2025): "Building Event-Driven Notification with FastAPI and Webhooks"

---

### **2. Middleware FastAPI para Coleta**

**Escolha:** Custom ASGI middleware  
**Alternativas consideradas:** Prometheus client, OpenTelemetry

**Raz√µes:**
- ‚úÖ **Controle total:** Coletar exatamente as m√©tricas que precisamos
- ‚úÖ **Performance:** Middleware async nativo (zero overhead)
- ‚úÖ **Integra√ß√£o perfeita:** Acesso a request/response objects completos
- ‚úÖ **Customiza√ß√£o:** F√°cil adicionar novas m√©tricas no futuro

**Implementa√ß√£o proposta:**
```python
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
import time

class AnalyticsMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        
        # Executar request
        response = await call_next(request)
        
        # Calcular lat√™ncia
        latency_ms = (time.time() - start_time) * 1000
        
        # Coletar m√©tricas
        await self._record_metrics(
            endpoint=request.url.path,
            method=request.method,
            status_code=response.status_code,
            latency_ms=latency_ms,
            api_key=self._extract_api_key(request)
        )
        
        return response
```

**Fontes:**
- FastAPI Docs (2025): "Custom Middleware"
- TokenMetrics (2025): "FastAPI High Performance & Best Practices"

---

### **3. Dashboard Streamlit**

**Escolha:** Streamlit (j√° usado no projeto)  
**Alternativas consideradas:** Grafana, Plotly Dash, React

**Raz√µes:**
- ‚úÖ **J√° integrado:** Projeto j√° usa Streamlit (app/main.py)
- ‚úÖ **R√°pido desenvolvimento:** Dashboard em 1-2h vs 8-12h React
- ‚úÖ **Python nativo:** Mesma stack do projeto (sem JavaScript)
- ‚úÖ **Gr√°ficos nativos:** st.line_chart, st.bar_chart, st.metric

**Componentes do Dashboard:**
1. **Overview KPIs** - Total requests, taxa de erros, lat√™ncia m√©dia
2. **Traffic Chart** - Requests/min ao longo do tempo (line chart)
3. **Performance Chart** - Lat√™ncia P50/P95/P99 por endpoint (bar chart)
4. **Errors Chart** - Taxa de erros 4xx/5xx por endpoint
5. **Consumers Table** - Top 10 API keys por volume de requests
6. **Endpoints Table** - Top endpoints por volume, lat√™ncia, erros

**Fontes:**
- Streamlit Docs (2025): "Building Dashboards"
- Medium (Oct 2025): "Streamlit Analytics Dashboard Best Practices"

---

## üèóÔ∏è Arquitetura Completa

### **Fluxo de Dados**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI App    ‚îÇ
‚îÇ  (31 endpoints) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Analytics       ‚îÇ
‚îÇ Middleware      ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Intercepta TODOS requests
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MetricsService  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Armazena em Redis (time-series)
‚îÇ (Redis)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ API     ‚îÇ ‚îÇ Dashboard    ‚îÇ
‚îÇ Endpoints‚îÇ ‚îÇ Streamlit    ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Consome dados do Redis
‚îÇ /metrics‚îÇ ‚îÇ /analytics   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### **Componentes Principais**

**1. `api/middleware/analytics.py`** (150 linhas)
- Classe `AnalyticsMiddleware` (BaseHTTPMiddleware)
- Coleta: endpoint, method, status_code, latency, api_key, timestamp
- Chama `MetricsService.record_request()` ass√≠ncrono

**2. `api/services/metrics_service.py`** (300 linhas)
- Classe `MetricsService` (Redis client)
- M√©todos:
  - `record_request()` - Armazena m√©trica em Redis
  - `get_requests_by_endpoint()` - Agrega requests por endpoint (intervalo)
  - `get_latency_percentiles()` - Calcula P50/P95/P99
  - `get_errors_by_endpoint()` - Conta erros 4xx/5xx
  - `get_top_consumers()` - Top API keys por volume
  - `get_top_endpoints()` - Top endpoints por volume/lat√™ncia

**3. `api/routers/analytics.py`** (200 linhas)
- Endpoints REST para m√©tricas:
  - `GET /api/v1/analytics/overview` - KPIs principais
  - `GET /api/v1/analytics/traffic` - Requests/min (time-series)
  - `GET /api/v1/analytics/performance` - Lat√™ncia por endpoint
  - `GET /api/v1/analytics/errors` - Taxa de erros
  - `GET /api/v1/analytics/consumers` - Uso por API key
  - `GET /api/v1/analytics/endpoints` - M√©tricas por endpoint

**4. `app/pages/analytics.py`** (400 linhas)
- Dashboard Streamlit completo
- 6 se√ß√µes com gr√°ficos interativos
- Filtros: per√≠odo, endpoint, API key

**5. `tests/test_api/test_analytics.py`** (250 linhas)
- Testes unit√°rios: MetricsService
- Testes E2E: Middleware coleta m√©tricas
- Testes E2E: Endpoints retornam dados corretos

---

## üìà M√©tricas a Coletar

### **1. Requests (Volume)**

**O que coletar:**
- Total de requests por minuto/hora/dia
- Requests por endpoint (path)
- Requests por m√©todo HTTP (GET, POST, etc)
- Requests por API key (cliente)

**Estrutura Redis:**
```
metrics:requests:{endpoint}:{timestamp} ‚Üí {"count": 45, "errors": 2}
metrics:requests:total:{timestamp} ‚Üí {"count": 1200}
metrics:requests:consumer:{api_key}:{timestamp} ‚Üí {"count": 150}
```

**Uso:** Gr√°fico de tr√°fego ao longo do tempo, identificar picos, tend√™ncias

---

### **2. Lat√™ncia (Performance)**

**O que coletar:**
- Lat√™ncia por endpoint (milissegundos)
- Percentis: P50 (mediana), P95, P99
- Lat√™ncia m√©dia por endpoint

**Estrutura Redis:**
```
metrics:latency:{endpoint}:{timestamp} ‚Üí {
  "p50": 120,
  "p95": 250,
  "p99": 500,
  "mean": 135,
  "max": 1200,
  "samples": 45
}
```

**C√°lculo de percentis:**
- Armazenar todas lat√™ncias em lista Redis (sorted set)
- Calcular percentis via Redis ZRANGE (O(log N))

**Uso:** Identificar endpoints lentos, detectar degrada√ß√£o de performance

---

### **3. Erros (Reliability)**

**O que coletar:**
- Total de erros por endpoint
- Breakdown por status code (4xx vs 5xx)
- Taxa de erro (erros / total requests)

**Estrutura Redis:**
```
metrics:errors:{endpoint}:{timestamp} ‚Üí {
  "4xx": 2,
  "5xx": 0,
  "total": 2,
  "rate": 0.044  // 2/45 = 4.4%
}
```

**Uso:** Alertas quando taxa de erro > 5%, identificar endpoints problem√°ticos

---

### **4. Uso por Cliente (Consumers)**

**O que coletar:**
- Total de requests por API key
- Endpoints mais usados por cliente
- Distribui√ß√£o de uso ao longo do tempo

**Estrutura Redis:**
```
metrics:consumer:{api_key}:{timestamp} ‚Üí {
  "requests": 150,
  "endpoints": ["/api/v1/clients", "/api/v1/tools/swot"],
  "unique_endpoints": 5
}
```

**Uso:** Identificar clientes mais ativos, detectar uso anormal

---

### **5. Rate Limit Hits**

**O que coletar:**
- Total de rate limit hits por dia
- Endpoints mais afetados
- API keys que mais excedem limites

**Estrutura Redis:**
```
metrics:ratelimit:{date} ‚Üí {
  "hits": 12,
  "endpoints": ["/api/v1/clients"],
  "consumers": ["bsc_test_user1"]
}
```

**Uso:** Identificar necessidade de ajustar limites, detectar abuso

---

### **6. Webhook Deliveries**

**O que coletar:**
- Total de webhooks enviados
- Taxa de sucesso vs falha
- Lat√™ncia de entrega

**Estrutura Redis:**
```
metrics:webhooks:{date} ‚Üí {
  "total": 50,
  "success": 48,
  "failed": 2,
  "success_rate": 0.96,
  "avg_latency_ms": 250
}
```

**Uso:** Monitorar sa√∫de do sistema de webhooks, detectar problemas de entrega

---

## üîß Estrutura Redis Detalhada

### **Keys Pattern**

**Formato geral:**
```
metrics:{metric_type}:{dimension}:{timestamp}
```

**Exemplos:**
```
# Requests por endpoint (minuto)
metrics:requests:/api/v1/clients:2025-11-19:10:00

# Lat√™ncia por endpoint (minuto)
metrics:latency:/api/v1/clients:2025-11-19:10:00

# Uso por API key (hora)
metrics:consumer:bsc_test_engelar:2025-11-19:10

# Rate limit hits (dia)
metrics:ratelimit:2025-11-19

# Webhooks (dia)
metrics:webhooks:2025-11-19
```

### **Valores (JSON)**

**Requests:**
```json
{
  "count": 45,
  "errors": 2,
  "methods": {"GET": 30, "POST": 15}
}
```

**Lat√™ncia:**
```json
{
  "p50": 120,
  "p95": 250,
  "p99": 500,
  "mean": 135,
  "max": 1200,
  "samples": 45
}
```

**Consumer:**
```json
{
  "requests": 150,
  "endpoints": ["/api/v1/clients", "/api/v1/tools/swot"],
  "unique_endpoints": 5
}
```

### **TTL (Time To Live)**

**Reten√ß√£o de dados:**
- **Minutos:** 7 dias (m√©tricas detalhadas)
- **Horas:** 30 dias (agrega√ß√µes)
- **Dias:** 90 dias (tend√™ncias longas)

**Implementa√ß√£o:**
```python
# Ao armazenar m√©trica
await redis.setex(
    key,
    ttl=7 * 24 * 60 * 60,  # 7 dias em segundos
    value=json.dumps(data)
)
```

---

## üì± Dashboard Streamlit - Layout Detalhado

### **Se√ß√£o 1: Overview KPIs**

**4 m√©tricas principais:**
- **Total Requests (hoje)** - Contador grande
- **Taxa de Erros (%)** - Com delta vs ontem
- **Lat√™ncia M√©dia (ms)** - Com delta vs ontem
- **API Keys Ativas** - Contador

**Layout:**
```python
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Total Requests", "12,450", delta="+5.2%")
with col2:
    st.metric("Taxa de Erros", "2.1%", delta="-0.3%")
with col3:
    st.metric("Lat√™ncia M√©dia", "145ms", delta="+12ms")
with col4:
    st.metric("API Keys Ativas", "23")
```

---

### **Se√ß√£o 2: Traffic Chart**

**Gr√°fico:** Line chart (requests/min ao longo do tempo)

**Filtros:**
- Per√≠odo: √öltima hora / Dia / Semana / M√™s
- Endpoint espec√≠fico (opcional)

**Dados:**
```python
# Agregar requests por minuto
data = metrics_service.get_requests_by_endpoint(
    endpoint="/api/v1/clients",
    start_time=datetime.now() - timedelta(hours=24),
    interval="minute"
)

# Plotar
st.line_chart(data, x="timestamp", y="count")
```

---

### **Se√ß√£o 3: Performance Chart**

**Gr√°fico:** Bar chart (lat√™ncia P50/P95/P99 por endpoint)

**Dados:**
```python
# Top 10 endpoints por lat√™ncia m√©dia
endpoints = metrics_service.get_top_endpoints(
    metric="latency",
    limit=10,
    period="24h"
)

# Plotar
st.bar_chart(endpoints, x="endpoint", y=["p50", "p95", "p99"])
```

---

### **Se√ß√£o 4: Errors Chart**

**Gr√°fico:** Bar chart (taxa de erros por endpoint)

**Dados:**
```python
# Taxa de erros por endpoint
errors = metrics_service.get_errors_by_endpoint(
    period="24h"
)

# Plotar
st.bar_chart(errors, x="endpoint", y="error_rate")
```

---

### **Se√ß√£o 5: Consumers Table**

**Tabela:** Top 10 API keys por volume de requests

**Colunas:**
- API Key (mascarado: `bsc_test_***`)
- Total Requests
- Endpoints √önicos
- √öltima Requisi√ß√£o

**Dados:**
```python
consumers = metrics_service.get_top_consumers(
    limit=10,
    period="24h"
)

st.dataframe(consumers)
```

---

### **Se√ß√£o 6: Endpoints Table**

**Tabela:** M√©tricas detalhadas por endpoint

**Colunas:**
- Endpoint
- Total Requests
- Lat√™ncia P50/P95/P99
- Taxa de Erros
- M√©todo HTTP Mais Usado

**Dados:**
```python
endpoints = metrics_service.get_endpoints_metrics(
    period="24h"
)

st.dataframe(endpoints)
```

---

## üöÄ Plano de Implementa√ß√£o (5 Etapas)

### **Etapa 1: Middleware de Analytics** (1h)

**Objetivo:** Criar middleware que intercepta requests e coleta m√©tricas b√°sicas

**Arquivos:**
- `api/middleware/__init__.py`
- `api/middleware/analytics.py`

**Implementa√ß√£o:**
1. Criar classe `AnalyticsMiddleware` (BaseHTTPMiddleware)
2. Interceptar request/response
3. Calcular lat√™ncia
4. Extrair API key do header
5. Chamar `MetricsService.record_request()` (mock inicial)

**Valida√ß√£o:**
- Middleware registrado no FastAPI app
- Logs mostram m√©tricas coletadas
- Zero impacto na performance (<1ms overhead)

---

### **Etapa 2: MetricsService (Redis)** (1h 30min)

**Objetivo:** Implementar servi√ßo completo de armazenamento/recupera√ß√£o de m√©tricas

**Arquivos:**
- `api/services/metrics_service.py`

**Implementa√ß√£o:**
1. Classe `MetricsService` com Redis client
2. M√©todo `record_request()` - Armazenar em Redis
3. M√©todo `get_requests_by_endpoint()` - Agregar por intervalo
4. M√©todo `get_latency_percentiles()` - Calcular P50/P95/P99
5. M√©todo `get_errors_by_endpoint()` - Contar erros
6. M√©todo `get_top_consumers()` - Top API keys
7. M√©todo `get_top_endpoints()` - Top endpoints

**Valida√ß√£o:**
- M√©tricas armazenadas corretamente em Redis
- Queries retornam dados agregados corretos
- TTL configurado (7 dias minutos, 30 dias horas)

---

### **Etapa 3: Endpoints API** (1h)

**Objetivo:** Criar endpoints REST para acesso program√°tico √†s m√©tricas

**Arquivos:**
- `api/routers/analytics.py`

**Endpoints:**
- `GET /api/v1/analytics/overview` - KPIs principais
- `GET /api/v1/analytics/traffic` - Requests/min (time-series)
- `GET /api/v1/analytics/performance` - Lat√™ncia por endpoint
- `GET /api/v1/analytics/errors` - Taxa de erros
- `GET /api/v1/analytics/consumers` - Uso por API key
- `GET /api/v1/analytics/endpoints` - M√©tricas por endpoint

**Valida√ß√£o:**
- Endpoints retornam JSON v√°lido
- Filtros funcionam (per√≠odo, endpoint, API key)
- Autentica√ß√£o requerida (API key)

---

### **Etapa 4: Dashboard Streamlit** (1h 30min)

**Objetivo:** Criar UI interativa com gr√°ficos e tabelas

**Arquivos:**
- `app/pages/analytics.py`

**Implementa√ß√£o:**
1. Se√ß√£o Overview (4 KPIs)
2. Se√ß√£o Traffic Chart (line chart)
3. Se√ß√£o Performance Chart (bar chart)
4. Se√ß√£o Errors Chart (bar chart)
5. Se√ß√£o Consumers Table (dataframe)
6. Se√ß√£o Endpoints Table (dataframe)
7. Filtros (per√≠odo, endpoint, API key)

**Valida√ß√£o:**
- Dashboard carrega sem erros
- Gr√°ficos exibem dados corretos
- Filtros funcionam
- UI responsiva e profissional

---

### **Etapa 5: Testes** (30min)

**Objetivo:** Validar implementa√ß√£o completa com testes

**Arquivos:**
- `tests/test_api/test_analytics_middleware.py`
- `tests/test_api/test_metrics_service.py`
- `tests/test_api/test_analytics_endpoints.py`

**Testes:**
- Unit√°rios: MetricsService (10 testes)
- E2E: Middleware coleta m√©tricas (3 testes)
- E2E: Endpoints retornam dados (6 testes)

**Valida√ß√£o:**
- 19 testes passando (100%)
- Coverage >80%

---

## üìñ Refer√™ncias (Brightdata Nov 2025)

### **FastAPI Middleware:**
1. **FastAPI Docs (2025):** "Custom Middleware"
   - BaseHTTPMiddleware, ASGI middleware patterns
2. **TokenMetrics (2025):** "FastAPI High Performance & Best Practices"
   - Middleware performance, async patterns

### **Redis Time-Series:**
3. **Redis.io (2025):** "Time-Series Data Structures Best Practices"
   - Hash sets, sorted sets, TTL strategies
4. **Medium (Aug 2025):** "Building Event-Driven Notification with FastAPI and Webhooks"
   - Redis patterns para m√©tricas

### **Streamlit Dashboards:**
5. **Streamlit Docs (2025):** "Building Dashboards"
   - Charts, metrics, dataframes
6. **Medium (Oct 2025):** "Streamlit Analytics Dashboard Best Practices"
   - Layout, performance, UX

### **API Analytics:**
7. **Apitally.io (2025):** "API monitoring & analytics for FastAPI"
   - M√©tricas essenciais, KPIs, alertas
8. **Speakeasy (Sep 2025):** "Rate Limiting Best Practices in REST API Design"
   - M√©tricas de rate limiting

---

## üéØ Pr√≥ximas Etapas (P√≥s-FASE 4.4)

**Ap√≥s FASE 4.4 completa, considerar:**
1. **Alertas Autom√°ticos:** Email/Slack quando m√©tricas excedem thresholds
2. **Export de Dados:** CSV/JSON para an√°lise externa
3. **Compara√ß√£o Per√≠odos:** Comparar m√©tricas semana vs semana
4. **Anomaly Detection:** Detectar padr√µes anormais automaticamente
5. **Integra√ß√£o Prometheus:** Expor m√©tricas em formato Prometheus (opcional)

---

**√öltima Atualiza√ß√£o:** 2025-11-19  
**Status:** üìê DESIGN APROVADO - Pronto para implementa√ß√£o  
**Pr√≥ximo:** Etapa 1 - Middleware de Analytics

