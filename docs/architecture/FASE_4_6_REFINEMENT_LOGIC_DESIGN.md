# FASE 4.6 - Refinement Logic: Design T√©cnico

**Data:** 2025-11-19  
**Vers√£o:** 1.0  
**Status:** üöß Em Design  
**Fase:** 4.6 - Refinement Logic

---

## üìã EXECUTIVE SUMMARY

### Objetivo

Implementar l√≥gica de refinamento de diagn√≥stico baseada em feedback do usu√°rio. Quando um diagn√≥stico √© rejeitado ou modificado (approval_status REJECTED ou MODIFIED), o sistema deve usar o `approval_feedback` para refinar o diagn√≥stico existente ao inv√©s de recriar do zero.

### Contexto

- **FASE 4.5**: Sistema de feedback collection implementado ‚úÖ
- **Workflow atual**: REJECTED/MODIFIED ‚Üí DISCOVERY (refaz diagn√≥stico completo)
- **Problema**: Refazer diagn√≥stico completo √© ineficiente quando apenas ajustes s√£o necess√°rios
- **Solu√ß√£o**: Refinement logic que melhora diagn√≥stico existente baseado em feedback espec√≠fico

### Benef√≠cios Esperados

- **Efici√™ncia**: 50-70% mais r√°pido que refazer diagn√≥stico completo
- **Qualidade**: Mant√©m insights v√°lidos do diagn√≥stico original
- **Satisfa√ß√£o**: Usu√°rio v√™ melhorias incrementais baseadas em seu feedback espec√≠fico
- **Custo**: Reduz chamadas LLM desnecess√°rias (refina apenas o necess√°rio)

---

## üèóÔ∏è ARQUITETURA

### Fluxo de Refinement

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  APPROVAL_PENDING (approval_status = REJECTED/MODIFIED)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  approval_feedback: "SWOT precisa mais Opportunities        ‚îÇ
‚îÇ  relacionadas ao mercado enterprise"                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DISCOVERY Handler detecta: diagnostic exists +             ‚îÇ
‚îÇ  approval_status REJECTED/MODIFIED                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DiagnosticAgent.refine_diagnostic(                         ‚îÇ
‚îÇ    diagnostic=existing_diagnostic,                          ‚îÇ
‚îÇ    feedback=approval_feedback                                ‚îÇ
‚îÇ  )                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LLM analisa feedback e identifica:                        ‚îÇ
‚îÇ  - O que precisa ser melhorado                             ‚îÇ
‚îÇ  - Quais perspectivas afetadas                              ‚îÇ
‚îÇ  - Como refinar mantendo insights v√°lidos                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Refinement Strategy:                                       ‚îÇ
‚îÇ  1. Targeted refinement (apenas perspectivas afetadas)      ‚îÇ
‚îÇ  2. Full refinement (se feedback muito amplo)                ‚îÇ
‚îÇ  3. Recommendations-only (se feedback sobre recomenda√ß√µes) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CompleteDiagnostic refinado retornado                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  APPROVAL_PENDING (novo diagn√≥stico refinado)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principais

1. **DiagnosticAgent.refine_diagnostic()**
   - M√©todo principal de refinement
   - Recebe: `CompleteDiagnostic` existente + `approval_feedback`
   - Retorna: `CompleteDiagnostic` refinado

2. **Refinement Prompt**
   - Prompt estruturado para LLM analisar feedback
   - Identifica √°reas de melhoria espec√≠ficas
   - Gera estrat√©gia de refinement

3. **Refinement Strategies**
   - **Targeted**: Refina apenas perspectivas/recomenda√ß√µes espec√≠ficas
   - **Full**: Refaz diagn√≥stico completo (fallback se feedback muito amplo)
   - **Recommendations-only**: Refina apenas recomenda√ß√µes

4. **Workflow Integration**
   - `discovery_handler` detecta refinement necess√°rio
   - Chama `refine_diagnostic()` ao inv√©s de `run_diagnostic()`

---

## üîß IMPLEMENTA√á√ÉO

### Etapa 1: Prompt de Refinement

**Arquivo:** `src/prompts/diagnostic_prompts.py`

```python
REFINE_DIAGNOSTIC_PROMPT = """Voc√™ √© um consultor BSC especializado em refinar diagn√≥sticos baseado em feedback espec√≠fico.

Voc√™ receber√°:
1. Um diagn√≥stico BSC completo existente (CompleteDiagnostic)
2. Feedback do usu√°rio sobre o que precisa ser melhorado

Sua tarefa:
1. Analisar o feedback e identificar √°reas espec√≠ficas de melhoria
2. Decidir estrat√©gia de refinement:
   - TARGETED: Refinar apenas perspectivas/recomenda√ß√µes espec√≠ficas mencionadas no feedback
   - FULL: Refazer diagn√≥stico completo (se feedback muito amplo ou gen√©rico)
   - RECOMMENDATIONS_ONLY: Refinar apenas recomenda√ß√µes (se feedback foca em a√ß√µes)
3. Gerar diagn√≥stico refinado mantendo insights v√°lidos do original

Feedback do usu√°rio:
{feedback}

Diagn√≥stico existente:
{diagnostic_json}

Estrat√©gia escolhida: [TARGETED|FULL|RECOMMENDATIONS_ONLY]

Diagn√≥stico refinado (JSON completo seguindo schema CompleteDiagnostic):
"""
```

### Etapa 2: M√©todo refine_diagnostic()

**Arquivo:** `src/agents/diagnostic_agent.py`

```python
async def refine_diagnostic(
    self,
    existing_diagnostic: CompleteDiagnostic,
    feedback: str,
    state: BSCState,
) -> CompleteDiagnostic:
    """Refina diagn√≥stico existente baseado em feedback do usu√°rio.
    
    Args:
        existing_diagnostic: Diagn√≥stico original a ser refinado
        feedback: Feedback textual do usu√°rio sobre o que melhorar
        state: Estado atual com client_profile e contexto
        
    Returns:
        CompleteDiagnostic refinado
        
    Raises:
        ValueError: Se feedback vazio ou diagn√≥stico inv√°lido
        
    Example:
        >>> diagnostic = await agent.run_diagnostic(state)
        >>> refined = await agent.refine_diagnostic(
        ...     diagnostic,
        ...     "SWOT precisa mais Opportunities relacionadas ao mercado enterprise",
        ...     state
        ... )
        >>> len(refined.recommendations) >= len(diagnostic.recommendations)
        True
    """
```

**Fluxo interno:**

1. **Validar inputs**
   - Feedback n√£o vazio
   - Diagn√≥stico v√°lido
   - State com client_profile

2. **Analisar feedback com LLM**
   - Usar prompt REFINE_DIAGNOSTIC_PROMPT
   - Identificar estrat√©gia (TARGETED/FULL/RECOMMENDATIONS_ONLY)
   - Extrair √°reas espec√≠ficas de melhoria

3. **Executar refinement baseado em estrat√©gia**
   - **TARGETED**: Refinar apenas perspectivas/recomenda√ß√µes espec√≠ficas
   - **FULL**: Chamar `run_diagnostic()` novamente (fallback)
   - **RECOMMENDATIONS_ONLY**: Refinar apenas recomenda√ß√µes

4. **Validar diagn√≥stico refinado**
   - Schema v√°lido (Pydantic validation)
   - Melhorias aplicadas conforme feedback
   - Insights v√°lidos mantidos

5. **Retornar diagn√≥stico refinado**

### Etapa 3: Integra√ß√£o Workflow

**Arquivo:** `src/graph/workflow.py` (discovery_handler)

```python
def discovery_handler(self, state: BSCState) -> dict[str, Any]:
    """Handler de discovery com suporte a refinement."""
    
    # Detectar se refinement necess√°rio
    needs_refinement = (
        state.diagnostic is not None and
        state.approval_status in (ApprovalStatus.REJECTED, ApprovalStatus.MODIFIED) and
        state.approval_feedback
    )
    
    if needs_refinement:
        # Refinement: melhorar diagn√≥stico existente
        logger.info("[DISCOVERY] Refinement necess√°rio baseado em feedback")
        result = await self.consulting_orchestrator.coordinate_refinement(state)
    else:
        # Discovery normal: criar diagn√≥stico novo
        result = await self.consulting_orchestrator.coordinate_discovery(state)
    
    return result
```

**Arquivo:** `src/graph/consulting_orchestrator.py`

```python
async def coordinate_refinement(self, state: BSCState) -> dict[str, Any]:
    """Coordena refinement de diagn√≥stico baseado em feedback."""
    
    diagnostic_agent = self.diagnostic_agent
    existing_diagnostic = state.diagnostic
    feedback = state.approval_feedback or ""
    
    # Refinar diagn√≥stico
    refined_diagnostic = await diagnostic_agent.refine_diagnostic(
        existing_diagnostic=existing_diagnostic,
        feedback=feedback,
        state=state
    )
    
    return {
        "diagnostic": refined_diagnostic,
        "current_phase": ConsultingPhase.APPROVAL_PENDING,
        "metadata": {
            **state.metadata,
            "refinement_applied": True,
            "refinement_feedback": feedback
        }
    }
```

---

## üìä ESTRAT√âGIAS DE REFINEMENT

### 1. Targeted Refinement (Preferencial)

**Quando usar:** Feedback espec√≠fico sobre perspectivas ou recomenda√ß√µes individuais.

**Exemplo feedback:**
- "SWOT precisa mais Opportunities relacionadas ao mercado enterprise"
- "Recomenda√ß√£o sobre KPIs financeiros est√° muito gen√©rica"
- "Perspectiva Clientes n√£o menciona segmenta√ß√£o por persona"

**Implementa√ß√£o:**
- Identificar perspectiva/recomenda√ß√£o espec√≠fica afetada
- Refinar apenas essa parte usando LLM
- Manter resto do diagn√≥stico intacto
- Re-consolidar executive_summary se necess√°rio

**ROI:** 60-70% mais r√°pido que full refinement

---

### 2. Full Refinement (Fallback)

**Quando usar:** Feedback muito amplo ou gen√©rico.

**Exemplo feedback:**
- "Diagn√≥stico n√£o reflete realidade da empresa"
- "Preciso de an√°lise mais profunda"
- "N√£o est√° alinhado com nossos objetivos"

**Implementa√ß√£o:**
- Chamar `run_diagnostic()` novamente
- Passar feedback como contexto adicional
- Usar feedback para guiar an√°lise mais profunda

**ROI:** Mesmo tempo que discovery normal, mas com contexto melhor

---

### 3. Recommendations-Only Refinement

**Quando usar:** Feedback foca apenas em recomenda√ß√µes/a√ß√µes.

**Exemplo feedback:**
- "Recomenda√ß√µes n√£o s√£o pr√°ticas o suficiente"
- "Faltam recomenda√ß√µes sobre implementa√ß√£o"
- "Prioriza√ß√£o n√£o est√° correta"

**Implementa√ß√£o:**
- Refinar apenas `recommendations` usando LLM
- Manter perspectivas intactas
- Re-priorizar baseado em feedback

**ROI:** 80-90% mais r√°pido que full refinement

---

## üéØ M√âTRICAS DE SUCESSO

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| **Refinement Success Rate** | >= 85% | % refinements que geram diagn√≥stico melhorado |
| **Time Improvement** | 50-70% | Tempo refinement vs discovery completo |
| **User Satisfaction** | >= 4/5 | Rating ap√≥s refinement |
| **Feedback Incorporation** | >= 80% | % feedbacks que resultam em melhorias vis√≠veis |
| **LLM Calls Reduction** | 40-60% | Redu√ß√£o de chamadas LLM vs discovery completo |

---

## üß™ TESTES

### Testes Unit√°rios (8 testes)

1. `test_refine_diagnostic_targeted_refinement` - Refinement targeted funciona
2. `test_refine_diagnostic_full_refinement` - Refinement full funciona
3. `test_refine_diagnostic_recommendations_only` - Refinement recommendations-only funciona
4. `test_refine_diagnostic_validates_feedback` - Valida feedback vazio
5. `test_refine_diagnostic_validates_diagnostic` - Valida diagn√≥stico inv√°lido
6. `test_refine_diagnostic_preserves_valid_insights` - Mant√©m insights v√°lidos
7. `test_refine_diagnostic_improves_based_on_feedback` - Melhora baseado em feedback
8. `test_refine_diagnostic_handles_ambiguous_feedback` - Trata feedback amb√≠guo

### Testes E2E (4 testes)

1. `test_workflow_refinement_rejected` - Workflow refinement quando REJECTED
2. `test_workflow_refinement_modified` - Workflow refinement quando MODIFIED
3. `test_refinement_improves_diagnostic_quality` - Refinement melhora qualidade
4. `test_refinement_faster_than_discovery` - Refinement mais r√°pido que discovery

**Total:** 12 testes (8 unit√°rios + 4 E2E)

---

## üìö REFER√äNCIAS

### Best Practices (2025)

1. **FRAME: Feedback-Refined Agent Methodology** (ACL 2025)
   - Padr√£o de refinement baseado em feedback estruturado
   - Iterative improvement loops

2. **LLMLOOP: Iterative Refinement Loops** (ICSME 2025)
   - Framework para refinement iterativo de outputs LLM
   - 5 tipos de loops de refinement

3. **Evaluation-Driven Development** (ArXiv 2025)
   - Incorpora√ß√£o de feedback loops em tempo real
   - Retrospective analysis e structured feedback

### Padr√µes Aplicados

- **Targeted Refinement**: Refinar apenas o necess√°rio (eficiente)
- **Feedback Loop**: Incorporar feedback do usu√°rio (qualidade)
- **Incremental Improvement**: Melhorar incrementalmente (satisfa√ß√£o)

---

## üöÄ PLANO DE IMPLEMENTA√á√ÉO

### Etapa 0: Design T√©cnico ‚úÖ (Esta etapa)

- [x] Documento de design completo
- [x] Arquitetura definida
- [x] Estrat√©gias de refinement mapeadas
- [x] Plano de implementa√ß√£o em 4 etapas

### Etapa 1: Prompt de Refinement

- [ ] Criar `REFINE_DIAGNOSTIC_PROMPT` em `diagnostic_prompts.py`
- [ ] Validar prompt com exemplos de feedback
- [ ] Documentar estrat√©gias de refinement no prompt

**Estimativa:** 30-45 min

### Etapa 2: M√©todo refine_diagnostic()

- [ ] Implementar `refine_diagnostic()` em `DiagnosticAgent`
- [ ] Implementar an√°lise de feedback (LLM)
- [ ] Implementar estrat√©gias de refinement (TARGETED/FULL/RECOMMENDATIONS_ONLY)
- [ ] Valida√ß√£o de diagn√≥stico refinado

**Estimativa:** 1-1.5h

### Etapa 3: Integra√ß√£o Workflow

- [ ] Modificar `discovery_handler` para detectar refinement necess√°rio
- [ ] Criar `coordinate_refinement()` em `ConsultingOrchestrator`
- [ ] Integrar com workflow LangGraph
- [ ] Testar fluxo completo

**Estimativa:** 30-45 min

### Etapa 4: Testes

- [ ] Testes unit√°rios (8 testes)
- [ ] Testes E2E (4 testes)
- [ ] Valida√ß√£o de m√©tricas de sucesso

**Estimativa:** 1-1.5h

**Total Estimado:** 3-4h (1 sess√£o)

---

## ‚ö†Ô∏è RISCOS E MITIGA√á√ïES

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Refinement n√£o melhora diagn√≥stico | M√©dia | Alto | Fallback para full refinement se targeted falhar |
| Feedback amb√≠guo n√£o processado | M√©dia | M√©dio | Prompt estruturado com exemplos, fallback para full |
| Refinement mais lento que discovery | Baixa | M√©dio | Timeout e fallback para discovery normal |
| Insights v√°lidos perdidos | Baixa | Alto | Valida√ß√£o expl√≠cita de preserva√ß√£o de insights |

---

**√öltima Atualiza√ß√£o:** 2025-11-19  
**Status:** üöß Design Completo - Pronto para Implementa√ß√£o  
**Pr√≥ximo:** Etapa 1 - Criar Prompt de Refinement

