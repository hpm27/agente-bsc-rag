# ‚ùå ANTIPADR√ïES RAG - BSC Project

**Data:** 2025-10-14  
**Fonte:** Li√ß√µes aprendidas Fase 2A (Query Decomposition, Adaptive Re-ranking, Router)  
**Objetivo:** Documentar armadilhas evitadas para acelerar Fase 2B e projetos futuros

---

## üéØ COMO USAR ESTE DOCUMENTO

**Checklist antes de implementar qualquer t√©cnica RAG:**

1. ‚úÖ Revisar se√ß√£o relevante (Query Enhancement, Retrieval, Re-ranking, Testing)
2. ‚úÖ Verificar se antipadr√£o se aplica √† t√©cnica
3. ‚úÖ Implementar solu√ß√£o recomendada
4. ‚úÖ Validar que antipadr√£o foi evitado

**ROI:** Evitar 1 antipadr√£o = economia de 2-8h debugging/refactoring

---

## üìã √çNDICE DE ANTIPADR√ïES

1. [Query Enhancement](#1-query-enhancement)
2. [Retrieval e Busca](#2-retrieval-e-busca)
3. [Re-ranking e Diversidade](#3-re-ranking-e-diversidade)
4. [Metadados e Ground Truth](#4-metadados-e-ground-truth)
5. [Testing e Valida√ß√£o](#5-testing-e-valida√ß√£o)
6. [Performance e Custos](#6-performance-e-custos)
7. [Arquitetura e Integra√ß√£o](#7-arquitetura-e-integra√ß√£o)
8. [LLMs e APIs](#8-llms-e-apis)

---

## 1. QUERY ENHANCEMENT

### ‚ùå ANTIPADR√ÉO 1.1: Usar GPT-4o para Tarefas Simples

**Problema:**
- Usar GPT-4o/GPT-5 para decomposi√ß√£o, classifica√ß√£o, extra√ß√£o

**Por qu√™ √© ruim:**
- ‚ùå **Custo 100x maior** ($0.01 vs $0.0001 GPT-4o-mini)
- ‚ùå **Lat√™ncia +40%** (~2s vs ~1.2s)
- ‚ùå **Qualidade similar** (n√£o justifica custo)

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
decomposer = QueryDecomposer(llm="gpt-4o")  # Caro!

# ‚úÖ USAR
decomposer = QueryDecomposer(llm="gpt-4o-mini")  # 100x mais barato

# Reservar GPT-4o/GPT-5 para:
# - Synthesis complexa
# - Generation final de respostas
# - Reasoning multi-step avan√ßado
```

**Economia:** $9.90/dia em 1000 queries

**Fonte:** lesson-query-decomposition (Aprendizado #3)

---

### ‚ùå ANTIPADR√ÉO 1.2: Regex Sem Word Boundaries

**Problema:**
- Regex `"e" in query` detecta falsos positivos ("√©", "presente", "mente")

**Por qu√™ √© ruim:**
- ‚ùå **-8% accuracy** em classifica√ß√£o
- ‚ùå **Falsos positivos** abundantes
- ‚ùå **Heur√≠stica n√£o-confi√°vel**

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
if "e" in query.lower():
    score += 1  # Detecta "√©", "presente", "mente"!

# ‚úÖ USAR
import re
if re.search(r'\be\b', query.lower()):  # Word boundaries!
    score += 1  # S√≥ detecta " e " isolado
```

**Melhoria:** +8% accuracy

**Fonte:** lesson-query-decomposition (Aprendizado #4), lesson-router (Aprendizado #4)

---

### ‚ùå ANTIPADR√ÉO 1.3: Sub-Queries Sem Contexto

**Problema:**
- Sub-queries isoladas perdem especificidade da query original

**Exemplo:**

```python
# ‚ùå EVITAR
Query original: "Como implementar BSC em manufatura?"
Sub-queries isoladas:
- "Quais KPIs financeiros?" ‚Üê Perdeu "manufatura"!
- "Como medir processos?" ‚Üê Perdeu "manufatura"!

# ‚úÖ USAR
Sub-queries contextualizadas:
- "Quais KPIs financeiros em manufatura?"
- "Como medir processos em manufatura?"
```

**Impacto:** +15% precision

**Fonte:** lesson-query-decomposition (O Que N√£o Funcionou #2)

---

### ‚ùå ANTIPADR√ÉO 1.4: Thresholds Altos Sem Valida√ß√£o

**Problema:**
- Definir thresholds arbitrariamente sem testar com dataset

**Exemplo:**

```python
# ‚ùå EVITAR
DECOMPOSITION_SCORE_THRESHOLD=2  # Arbitr√°rio!
# Resultado: Coverage 40% (queries v√°lidas n√£o decompostas)

# ‚úÖ USAR
DECOMPOSITION_SCORE_THRESHOLD=1  # Testado com dataset
# Resultado: Coverage 100%
```

**Regra:**
- ‚úÖ Come√ßar com thresholds **BAIXOS** e aumentar se necess√°rio
- ‚úÖ Validar coverage com dataset variado (50+ queries)
- ‚úÖ A/B testing com thresholds diferentes

**Fonte:** lesson-query-decomposition (O Que N√£o Funcionou #4)

---

## 2. RETRIEVAL E BUSCA

### ‚ùå ANTIPADR√ÉO 2.1: Reimplementar Funcionalidades Existentes

**Problema:**
- Implementar RRF do zero quando j√° existe

**Por qu√™ √© ruim:**
- ‚ùå **+1 dia desenvolvimento** desnecess√°rio
- ‚ùå **Bugs novos** (n√£o validado)
- ‚ùå **Duplica√ß√£o de c√≥digo**

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
def my_own_rrf(results_list):  # Reimplementar RRF
    # ... 100 linhas de c√≥digo novo (n√£o testado)

# ‚úÖ USAR
from src.rag.retriever import BSCRetriever

retriever = BSCRetriever()
fused = retriever.reciprocal_rank_fusion(results_list)  # Reutilizar!
```

**Economia:** 8h (1 dia de trabalho)

**Fonte:** lesson-query-decomposition (O Que Funcionou #2)

---

### ‚ùå ANTIPADR√ÉO 2.2: Retrieval Sem Metadados

**Problema:**
- N√£o usar metadados (title, authors, year, perspectives) para ground truth e filtros

**Por qu√™ √© ruim:**
- ‚ùå **M√©tricas n√£o-valid√°veis** (Recall/Precision 0%)
- ‚ùå **Filtros avan√ßados imposs√≠veis**
- ‚ùå **UI pobre** (filenames longos vs t√≠tulos)

**Solu√ß√£o:**

```python
# ‚úÖ IMPLEMENTAR
# 1. Criar index.json com metadados
# 2. Auto-gera√ß√£o com LLM para docs novos
# 3. document_title SEMPRE presente
# 4. Usar filtros em retrieval
```

**Benef√≠cios:**
- ‚úÖ Ground truth valid√°vel
- ‚úÖ Filtros por autor/ano/tipo/perspectiva
- ‚úÖ UI profissional

**Fonte:** Se√ß√£o "MELHORIAS DE INFRAESTRUTURA" do plano

---

## 3. RE-RANKING E DIVERSIDADE

### ‚ùå ANTIPADR√ÉO 3.1: Embeddings N√£o-Normalizados

**Problema:**
- Usar embeddings raw em MMR ou similaridade cosseno

**Por qu√™ √© ruim:**
- ‚ùå **Erros num√©ricos** (underflow, overflow)
- ‚ùå **Similaridade incorreta** (valores fora de 0-1)
- ‚ùå **MMR inst√°vel**

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
similarity = cosine_similarity(emb1, emb2)  # Embeddings raw

# ‚úÖ USAR
emb1_norm = emb1 / np.linalg.norm(emb1)  # Normalizar!
emb2_norm = emb2 / np.linalg.norm(emb2)
similarity = cosine_similarity(emb1_norm, emb2_norm)

# OU usar sklearn (j√° normaliza internamente)
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity([emb1], [emb2])[0][0]
```

**Benef√≠cio:** C√°lculos est√°veis e corretos

**Fonte:** lesson-adaptive-reranking (O Que Funcionou #2)

---

### ‚ùå ANTIPADR√ÉO 3.2: Float Comparisons com `==`

**Problema:**
- Usar `assert similarity == 0.96` em testes

**Por qu√™ √© ruim:**
- ‚ùå **Falhas spurias** (0.9599999... ‚â† 0.96)
- ‚ùå **Testes n√£o-determin√≠sticos**
- ‚ùå **Debugging frustrante**

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
assert similarity == 0.96  # Vai falhar!

# ‚úÖ USAR
import numpy as np
assert np.allclose(similarity, 0.96, atol=1e-6)

# OU
from pytest import approx
assert similarity == approx(0.96, abs=1e-6)
```

**Regra:** **NUNCA** use `==` para floats. **SEMPRE** use `allclose()` ou `approx()`.

**Fonte:** lesson-adaptive-reranking (O Que N√£o Funcionou #1)

---

## 4. METADADOS E GROUND TRUTH

### ‚ùå ANTIPADR√ÉO 4.1: Ground Truth Sem document_title

**Problema:**
- Criar benchmark sem campo rastre√°vel (source, title, doc_id)

**Por qu√™ √© ruim:**
- ‚ùå **Recall@10 n√£o-valid√°vel** (imposs√≠vel saber se doc correto foi recuperado)
- ‚ùå **Precision@5 n√£o-valid√°vel**
- ‚ùå **Benchmark in√∫til** (m√©tricas 0%)

**Solu√ß√£o:**

```python
# ‚úÖ IMPLEMENTAR ANTES de benchmarks
# 1. Adicionar document_title ao Qdrant payload
# 2. Ground truth usa document_title para match
# 3. Valida√ß√£o objetiva funciona

# Exemplo ground truth
{
  "query_id": "Q001",
  "expected_documents": [
    "The Balanced Scorecard: Translating Strategy into Action",  // title rastre√°vel!
    "Strategy Maps"
  ]
}
```

**Benef√≠cio:** M√©tricas objetivas funcionam

**Fonte:** lesson-query-decomposition (O Que N√£o Funcionou #3)

---

### ‚ùå ANTIPADR√ÉO 4.2: Metadados Manuais Apenas

**Problema:**
- Exigir edi√ß√£o manual de index.json para cada documento novo

**Por qu√™ √© ruim:**
- ‚ùå **5-10 min manuten√ß√£o** por documento
- ‚ùå **Erro humano** (esquecimento, typos)
- ‚ùå **Barreira de entrada** (usu√°rio n√£o t√©cnico n√£o consegue)

**Solu√ß√£o:**

```python
# ‚úÖ IMPLEMENTAR auto-gera√ß√£o
# 1. GPT-4o-mini extrai metadados automaticamente
# 2. Salva em index.json (cache)
# 3. Zero manuten√ß√£o manual

# Custo: ~$0.002/documento (irris√≥rio)
# ROI: 5-10 min economizados/documento
```

**Economia:** 50-100 min em 10-20 docs futuros

**Fonte:** Se√ß√£o "Auto-Gera√ß√£o de Metadados" do plano

---

## 5. TESTING E VALIDA√á√ÉO

### ‚ùå ANTIPADR√ÉO 5.1: Testes Depois da Implementa√ß√£o

**Problema:**
- Implementar funcionalidade completa, DEPOIS criar testes

**Por qu√™ √© ruim:**
- ‚ùå **Coverage baixa** (60-80% t√≠pico vs 100% TDD)
- ‚ùå **Bugs descobertos tarde** (produ√ß√£o vs desenvolvimento)
- ‚ùå **Design pobre** (c√≥digo dif√≠cil de testar)

**Solu√ß√£o:**

```python
# ‚úÖ TEST-DRIVEN DEVELOPMENT

# 1. Escrever teste PRIMEIRO
def test_calculate_similarity():
    vec1 = np.array([1.0, 0.0])
    vec2 = np.array([1.0, 0.0])
    
    similarity = reranker._calculate_similarity(vec1, vec2)
    
    assert np.allclose(similarity, 1.0)

# 2. Implementar fun√ß√£o (teste falha ‚Üí implementa ‚Üí teste passa)
def _calculate_similarity(self, vec1, vec2):
    from sklearn.metrics.pairwise import cosine_similarity
    return cosine_similarity([vec1], [vec2])[0][0]

# 3. Coverage naturalmente alto!
```

**Benef√≠cios:**
- ‚úÖ **Coverage 90-100%** (vs 60-80% t√≠pico)
- ‚úÖ **Zero bugs** em produ√ß√£o (tudo validado)
- ‚úÖ **Design modular** (c√≥digo test√°vel)

**ROI:** +4-6h economizadas (debugging evitado)

**Fonte:** lesson-adaptive-reranking (Aprendizado #1)

---

### ‚ùå ANTIPADR√ÉO 5.2: Testes Sem Mocking de APIs

**Problema:**
- Chamar Cohere API, OpenAI API, Qdrant real em testes

**Por qu√™ √© ruim:**
- ‚ùå **Testes lentos** (500ms-1s por API call)
- ‚ùå **Custo $$$** (38 testes = $0.38 se usar API real)
- ‚ùå **Depend√™ncia externa** (falha se API offline)
- ‚ùå **N√£o-reprodut√≠vel** (resultados variam)

**Solu√ß√£o:**

```python
# ‚úÖ MOCKAR APIs externas

from unittest.mock import Mock, patch

@patch('cohere.Client')
def test_rerank(mock_cohere_client):
    # Mock response
    mock_client = Mock()
    mock_response = Mock()
    mock_response.results = [Mock(index=0, relevance_score=0.95)]
    mock_client.rerank.return_value = mock_response
    
    # Teste r√°pido! (~0.1s vs ~1s real)
    reranker = CohereReranker()
    results = reranker.rerank(query, docs)
    
    assert len(results) > 0
```

**Benef√≠cios:**
- ‚úÖ **Testes 2-10x mais r√°pidos**
- ‚úÖ **Custo $0** (sem API calls)
- ‚úÖ **Reprodut√≠vel** (sempre mesmo resultado)

**Fonte:** lesson-adaptive-reranking (Aprendizado #4)

---

### ‚ùå ANTIPADR√ÉO 5.3: Assumir C√≥digo Quebrado Antes de Verificar Testes

**Problema:**
- "Heur√≠stica n√£o funciona!" ‚Üí modificar c√≥digo ‚Üí ainda quebrado ‚Üí debugging profundo

**Exemplo Real:**
- should_decompose() reportava 0% accuracy
- Problema: TESTES estavam errados (tupla vs bool), N√ÉO o c√≥digo!

**Solu√ß√£o:**

```python
# ‚úÖ WORKFLOW CORRETO

# 1. Teste falha
assert heuristic_accuracy == 100%  # Resultado: 0%

# 2. ANTES de modificar c√≥digo: VERIFICAR TESTE
# Descoberta: should_decompose() retorna (bool, int) mas teste usa como bool
# Tupla sempre √© True em Python!

# 3. Corrigir TESTE (n√£o c√≥digo)
should_decompose_decision, score = self.decomposer.should_decompose(query)
if should_decompose_decision:  # Correto!
    decompose()

# 4. Teste passa! C√≥digo estava correto.
```

**Li√ß√£o:**
- ‚úÖ **Sempre verificar testes PRIMEIRO** antes de modificar c√≥digo
- ‚úÖ **Criar scripts de diagn√≥stico** (diagnose_heuristics.py)
- ‚úÖ **Type hints estritos** evitam bugs (tupla vs bool)

**Economia:** 2h de debugging evitadas

**Fonte:** lesson-query-decomposition (O Que N√£o Funcionou #5)

---

## 6. PERFORMANCE E CUSTOS

### ‚ùå ANTIPADR√ÉO 6.1: Retrieval Sequencial para M√∫ltiplas Queries

**Problema:**
- Executar 4 sub-queries sequencialmente

**Por qu√™ √© ruim:**
- ‚ùå **Lat√™ncia 4x maior** (4 √ó 3s = 12s vs 3-4s paralelo)
- ‚ùå **N√£o aproveita concorr√™ncia**

**Solu√ß√£o:**

```python
# ‚ùå EVITAR
sub_results = []
for sq in sub_queries:
    results = retriever.retrieve(sq)  # Sequencial!
    sub_results.append(results)

# ‚úÖ USAR
sub_results = await asyncio.gather(*[
    retriever.retrieve_async(sq) for sq in sub_queries
])  # Paralelo!
```

**Melhoria:** 3-4x mais r√°pido

**Fonte:** lesson-query-decomposition (O Que Funcionou #5), MVP AsyncIO (3.34x speedup)

---

### ‚ùå ANTIPADR√ÉO 6.2: LLM para Classifica√ß√£o Sempre

**Problema:**
- Usar LLM para classificar TODAS queries (n√£o apenas amb√≠guas)

**Por qu√™ √© ruim:**
- ‚ùå **Custo:** $0.0001 √ó 1000 queries = $0.10/dia = **$3/m√™s desnecess√°rios**
- ‚ùå **Lat√™ncia:** ~500ms todas queries vs ~50ms heur√≠sticas

**Solu√ß√£o:**

```python
# ‚úÖ H√çBRIDO: Heur√≠sticas (80%) + LLM Fallback (20%)

def classify(self, query):
    # Tentar heur√≠sticas PRIMEIRO
    category, confidence = self._heuristic_classify(query)
    
    # SE confian√ßa baixa (<0.8), usar LLM
    if confidence < 0.8:
        return self._llm_classify(query)  # 20% casos
    
    return category  # 80% casos
```

**Economia:** ~$2.40/m√™s + lat√™ncia -70%

**Fonte:** lesson-router (O Que Funcionou #2, Aprendizado #2)

---

## 7. ARQUITETURA E INTEGRA√á√ÉO

### ‚ùå ANTIPADR√ÉO 7.1: Integra√ß√£o Invasiva (Modificar MVP)

**Problema:**
- Modificar m√©todos existentes do MVP para adicionar feature nova

**Por qu√™ √© ruim:**
- ‚ùå **Alto risco** de quebrar funcionalidade validada
- ‚ùå **Rollback dif√≠cil** (c√≥digo entrela√ßado)
- ‚ùå **Testing complexo** (n√£o sabe se bug √© MVP ou feature nova)

**Solu√ß√£o:**

```python
# ‚ùå EVITAR - Modificar m√©todo existente
class Orchestrator:
    def invoke(self, state):  # M√©todo MVP
        # MODIFICAR c√≥digo MVP aqui ‚Üê RISCO!
        routing = self.router.route(...)  # Novo c√≥digo misturado
        ...

# ‚úÖ USAR - Adicionar novo m√©todo
class Orchestrator:
    def invoke(self, state):  # M√©todo MVP INTOCADO
        # MVP code inalterado
        ...
    
    def get_retrieval_strategy_metadata(self):  # NOVO m√©todo
        # Feature nova isolada
        if self.router:
            return self.router.route(...)
        return {}  # Fallback
```

**Benef√≠cios:**
- ‚úÖ **MVP preservado** 100%
- ‚úÖ **Rollback f√°cil** (desabilitar flag)
- ‚úÖ **Zero risco** de quebrar MVP
- ‚úÖ **Testing isolado**

**Fonte:** lesson-router (O Que Funcionou #3)

---

### ‚ùå ANTIPADR√ÉO 7.2: Feature Sem Feature Flag

**Problema:**
- Implementar feature nova sem toggle de habilita√ß√£o/desabilita√ß√£o

**Por qu√™ √© ruim:**
- ‚ùå **Rollback requer redeploy** (n√£o pode desabilitar em produ√ß√£o)
- ‚ùå **A/B testing imposs√≠vel**
- ‚ùå **Gradual rollout imposs√≠vel** (0% ou 100%, n√£o 10%‚Üí50%‚Üí100%)

**Solu√ß√£o:**

```python
# ‚úÖ SEMPRE implementar feature flag

# config/settings.py
enable_query_router: bool = True

# .env
ENABLE_QUERY_ROUTER=True  # Toggle f√°cil!

# C√≥digo
if settings.enable_query_router:
    # Feature nova
else:
    # Fallback (MVP ou padr√£o)
```

**Benef√≠cios:**
- ‚úÖ Rollback instant√¢neo (mudar .env)
- ‚úÖ A/B testing (50% users com flag True)
- ‚úÖ Gradual rollout (10% ‚Üí 100%)
- ‚úÖ Debugging (comparar com/sem feature)

**Fonte:** lesson-router (O Que Funcionou #4)

---

## 8. LLMs E APIS

### ‚ùå ANTIPADR√ÉO 8.1: AsyncIO Event Loop Duplo

**Problema:**
- `asyncio.run()` dentro de event loop ativo (pytest-asyncio, Jupyter)

**Erro:**
```
RuntimeError: asyncio.run() cannot be called from a running event loop
```

**Solu√ß√£o:**

```python
# ‚úÖ DETECTAR loop e usar ThreadPoolExecutor

import asyncio
import concurrent.futures

def execute_async_safely(coro):
    try:
        loop = asyncio.get_running_loop()
        # Loop ativo! Usar thread separada
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, coro)
            return future.result()
    except RuntimeError:
        # Sem loop, criar novo
        return asyncio.run(coro)
```

**Aplica√ß√£o:**
- ‚úÖ DecompositionStrategy (resolvido)
- ‚úÖ Self-RAG (itera√ß√µes ass√≠ncronas)
- ‚úÖ CRAG (re-retrieval ass√≠ncrono)

**Fonte:** lesson-router (O Que Funcionou #2, O Que N√£o Funcionou #2)

---

### ‚ùå ANTIPADR√ÉO 8.2: Timeout Sem Fallback

**Problema:**
- LLM call sem timeout ou sem fallback se timeout

**Por qu√™ √© ruim:**
- ‚ùå **Query travada** (aguarda forever)
- ‚ùå **UX ruim** (loading infinito)
- ‚ùå **Sistema quebrado** por 1 LLM lento

**Solu√ß√£o:**

```python
# ‚úÖ TIMEOUT + FALLBACK

try:
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[...],
        timeout=30  # 30s timeout
    )
    metadata = parse_response(response)
except TimeoutError:
    logger.warning("[TIMEOUT] LLM timeout, usando fallback")
    metadata = {}  # Fallback: metadados vazios (graceful degradation)
```

**Regra:**
- ‚úÖ **Sempre timeout** em LLM calls (10-30s t√≠pico)
- ‚úÖ **Sempre fallback** (dict vazio, default, MVP)
- ‚úÖ **Graceful degradation** (sistema continua funcionando)

**Fonte:** Auto-gera√ß√£o metadados (Error Handling)

---

## 9. DOCUMENTA√á√ÉO E ORGANIZA√á√ÉO

### ‚ùå ANTIPADR√ÉO 9.1: Documentar Tudo no Final

**Problema:**
- Implementar 3 t√©cnicas ‚Üí Documentar tudo de uma vez

**Por qu√™ √© ruim:**
- ‚ùå **Esquece detalhes** (implementou h√° 2 semanas)
- ‚ùå **Docs incompletas** (decis√µes arquiteturais perdidas)
- ‚ùå **Bloqueio de tempo** (8h cont√≠nuas de docs)

**Solu√ß√£o:**

```
# ‚úÖ DOCUMENTA√á√ÉO PARALELA

Implementa√ß√£o Router:
‚îú‚îÄ Hora 1-2: C√≥digo core
‚îú‚îÄ Hora 2.5: Docs parciais (arquitetura, como funciona)  ‚Üê Paralelo!
‚îú‚îÄ Hora 3-4: Strategies
‚îú‚îÄ Hora 4.5: Atualizar docs (strategies, exemplos)  ‚Üê Paralelo!
‚îú‚îÄ Hora 5-6: Testes + integration
‚îî‚îÄ Hora 6: Finalizar docs  ‚Üê Quick!
```

**Benef√≠cios:**
- ‚úÖ **C√≥digo fresco** (f√°cil documentar)
- ‚úÖ **Docs precisas** (n√£o esquece decis√µes)
- ‚úÖ **Economia -0.5 dias** vs doc big bang

**Fonte:** lesson-router (O Que Funcionou #5)

---

### ‚ùå ANTIPADR√ÉO 9.2: Sem √çndice de Documenta√ß√£o

**Problema:**
- 30+ documentos sem √≠ndice naveg√°vel

**Por qu√™ √© ruim:**
- ‚ùå **Busca lenta** (Ctrl+F em m√∫ltiplos arquivos)
- ‚ùå **Descoberta dif√≠cil** ("onde est√° doc sobre X?")
- ‚ùå **Duplica√ß√£o** (n√£o sabe que doc j√° existe)

**Solu√ß√£o:**

```markdown
# ‚úÖ CRIAR DOCS_INDEX.md (TIER 3)

- Tags A-Z (retrieval, reranking, agents, etc)
- Docs por categoria (Techniques, Patterns, History)
- Quick Search Matrix ("Preciso de X" ‚Üí "Consulte Y")
```

**ROI:** 3-8 min economizados por busca √ó 15-25 buscas = **45-200 min**

**Fonte:** TIER 3 Organiza√ß√£o (este documento!)

---

## 10. PADR√ïES GERAIS RAG

### ‚ùå ANTIPADR√ÉO 10.1: Over-Engineering (Implementar Tudo)

**Problema:**
- Implementar Graph RAG, Multi-modal RAG, HyDE sem validar necessidade

**Por qu√™ √© ruim:**
- ‚ùå **Weeks de trabalho** sem benef√≠cio
- ‚ùå **Complexidade** sem ROI
- ‚ùå **Manuten√ß√£o** de c√≥digo n√£o-usado

**Solu√ß√£o:**

```
# ‚úÖ DECIS√ÉO DATA-DRIVEN

1. Benchmark baseline
2. Identificar gap (recall <70%? hallucination >10%?)
3. SE gap existe ‚Üí implementar t√©cnica espec√≠fica
4. SE n√£o existe ‚Üí SKIP (n√£o implementar)
```

**Exemplo Validado:**
- Graph RAG: **SKIP agora** (dataset inadequado, ROI zero)
- HyDE: **Avaliar SE** recall <70% (condicional Fase 2C)
- Self-RAG: **Implementar SE** faithfulness <0.85 (decis√£o baseada em benchmark)

**Fonte:** Decis√£o Arquitetural #2 do plano (Por qu√™ N√ÉO Graph RAG agora)

---

### ‚ùå ANTIPADR√ÉO 10.2: Todas Queries Usam Mesma Estrat√©gia

**Problema:**
- Query simples "O que √© BSC?" usa workflow completo (4 agents + synthesis + judge)

**Por qu√™ √© ruim:**
- ‚ùå **Lat√™ncia desnecess√°ria** (70s vs <5s ideal)
- ‚ùå **Custo desnecess√°rio** ($0.05 vs $0.000015)
- ‚ùå **UX ruim** (usu√°rio espera 70s para resposta trivial)

**Solu√ß√£o:**

```python
# ‚úÖ QUERY ROUTER (TECH-003)

# Classify query ‚Üí Choose optimal strategy
if query_category == SIMPLE_FACTUAL:
    return DirectAnswerStrategy()  # <5s, cache
elif query_category == COMPLEX_MULTI_PART:
    return DecompositionStrategy()  # ~70s, melhor qualidade
else:
    return HybridSearchStrategy()  # Padr√£o MVP
```

**Benef√≠cios:**
- ‚úÖ **-85% lat√™ncia** queries simples (70s ‚Üí 5s)
- ‚úÖ **-99.7% custo** queries simples ($0.05 ‚Üí $0.000015)
- ‚úÖ **UX melhorado** (respostas r√°pidas para queries simples)

**Fonte:** lesson-router (Descoberta Extraordin√°ria)

---

## üìä RESUMO - ANTIPADR√ïES EVITADOS

### Fase 2A Completa (3 T√©cnicas)

| Antipadr√£o | Economia | Fonte |
|------------|----------|-------|
| **GPT-4o para tarefas simples** | $3/m√™s | Query Decomp |
| **Regex sem word boundaries** | +8% accuracy | Query Decomp + Router |
| **Sub-queries sem contexto** | +15% precision | Query Decomp |
| **Thresholds altos** | Coverage 40% ‚Üí 100% | Query Decomp |
| **Reimplementar RRF** | -8h (1 dia) | Query Decomp |
| **Testes depois** | +4-6h (bugs evitados) | Adaptive Re-rank |
| **Embeddings n√£o-normalizados** | Estabilidade num√©rica | Adaptive Re-rank |
| **Float `==`** | Testes est√°veis | Adaptive Re-rank |
| **Sem mocking APIs** | Testes 2-10x r√°pidos | Adaptive Re-rank |
| **Integra√ß√£o invasiva** | MVP preservado | Router |
| **Sem feature flags** | Rollback f√°cil | Router |
| **AsyncIO event loop duplo** | -2h debugging | Router |
| **Reutiliza√ß√£o <50%** | -5 dias (70% reuso) | Router |

**Total Economia Estimada:** 6-8 dias de trabalho (48-64h)

---

## üéì TOP 10 REGRAS DE OURO RAG

**Checklist antes de implementar qualquer t√©cnica:**

1. ‚úÖ **Heur√≠sticas PRIMEIRO, LLM fallback** (80% accuracy, custo $0)
2. ‚úÖ **Reutilizar componentes** agressivamente (70% reuso = -5 dias)
3. ‚úÖ **Test-Driven Development** (testes durante, n√£o depois)
4. ‚úÖ **Mockar APIs externas** em testes (2-10x mais r√°pido)
5. ‚úÖ **Word boundaries em regex** (`\b` sempre)
6. ‚úÖ **AsyncIO paralelo** quando poss√≠vel (3-4x speedup)
7. ‚úÖ **Feature flags** em todas features (rollback f√°cil)
8. ‚úÖ **Integra√ß√£o n√£o-invasiva** (preservar MVP)
9. ‚úÖ **Documenta√ß√£o paralela** (durante implementa√ß√£o)
10. ‚úÖ **Decis√£o data-driven** (benchmark ‚Üí implementar SE necess√°rio)

---

## üìö REFER√äNCIAS

### Li√ß√µes Aprendidas

- `docs/lessons/lesson-query-decomposition-2025-10-14.md`
- `docs/lessons/lesson-adaptive-reranking-2025-10-14.md`
- `docs/lessons/lesson-router-2025-10-14.md`
- `docs/lessons/lesson-e2e-validation-corrections-2025-10-14.md`

### T√©cnicas

- `docs/techniques/QUERY_DECOMPOSITION.md`
- `docs/techniques/ADAPTIVE_RERANKING.md`
- `docs/techniques/ROUTER.md`

### Plano

- `.cursor/plans/fase-2-rag-avancado.plan.md` - Decis√µes Arquiteturais

### Rules

- `.cursor/rules/rag-bsc-core.mdc` - Workflow 7 steps
- `.cursor/rules/rag-techniques-catalog.mdc` - Cat√°logo t√©cnicas

---

## üìù PR√ìXIMOS PASSOS

### Usar em Fase 2B:

1. ‚úÖ Revisar este doc ANTES de implementar Self-RAG
2. ‚úÖ Checklist de antipadr√µes antes de merge
3. ‚úÖ Adicionar novos antipadr√µes descobertos (documento vivo)

### Adicionar Futuramente:

- Antipadr√£o: CRAG sem web search (quando adicionar CRAG)
- Antipadr√£o: Self-RAG sem max_iterations (quando adicionar Self-RAG)
- Antipadr√£o: [Novos descobertos na Fase 2B]

---

**Criado:** 2025-10-14  
**Autor:** Claude Sonnet 4.5 (via Cursor)  
**Tipo:** Documento Vivo (atualizar com novas descobertas)


